--- 
title: "Introduction to Data Science"
author: 
- Tiffany-Anne Timbers
- Melissa Lee
- Trevor Campbell
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [sources.bib]
biblio-style: apalike
link-citations: yes
description: "This is an open source textbook for teaching introductory data science."
output:
  bookdown::gitbook:
    css: style.css
    config:
      toc:
        before: |
          <li><a href="./">Introduction to Data Science</a></li>
        after: |
          <li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
      edit: https://github.com/rstudio/bookdown-demo/edit/master/%s
      download: ["pdf", "epub"]
  bookdown::pdf_book:
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    keep_tex: yes
  bookdown::epub_book: default
---

# Introduction to Data Science

This is an open source textbook aimed at introducing undergraduate students to Data Science. It was originally written for the University of British Columbia's [DSCI 100 - Introduction to Data Science course](https://ubc-dsci.github.io/dsci-100/). In this book and course we define data science as the processes used to obtain value (i.e., insight) from data through reproducible and auditable processes.

This course uses Jupyter and the R programming language to illustrate how to solve 4 common problems in Data Science:

1. Predicting a class/category for a new observation/measurement (e.g., cancerous or benign tumour)
2. Predicting a value for a new observation/measurement (e.g., 10 km race time for 20 year old females with a BMI of 25).
3. Finding previously unknown/unlabelled subgroups in your data (e.g., products commonly bought together on Amazon)
4. Estimating an average or a proportion from a sample (e.g., the proportion of undergraduate students that own an iphone)

This book/course is structured so that learners spend the first four chapters learning how to use R to load, wrangle/clean and visualize data. The remaining chapters cover solutions to the four problems discussed above. 

## Chapter learning objectives

By the end of the chapter, students will be able to:

* use a Jupyter notebook to execute provided R code
* edit code and markdown cells in a Jupyter notebook
* create new code and markdown cells in a Jupyter notebook
* load the `tidyverse` library into R
* create new variables and objects in R using the assignment symbol
* use the help and documentation tools in R
* match the names of the following functions from the `tidyverse` library to their documentation descriptions: 
    - `read_csv` 
    - `select`
    - `mutate`
    - `filter`
    - `ggplot`
    - `aes`

## Jupyter notebooks

Jupyter Notebooks are documents that contain a mix of computer code (and its output) and formattable text. Given that they can mix these two things in a single document (code is not separate from the output or written report), they are one of the leading tools to create reproducible data analysis. A reproducible data analysis is one where you can reliably and easily recreate the same results when reanalyzing the same data. This sounds like this is something that should always happen with any data analysis, but in reality this is not often the case and one needs to make concious effort in the way they do their data analysis to ensure that it is reproducible.

The name Jupyter came from combining the names of the three programming language that it was initially targeted for (Julia, Python, and R), and now many other languages can be used with Jupyter notebooks. 

A notebook looks like this:

<img src="img/jupyter.png">

We have created a short demo video to help you get started and introduce you to Jupyter: 

<iframe width="840" height="473" src="https://www.youtube.com/embed/2yv4pEmFgnw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

However, the best way to learn how to write and run code and formattable text in a Jupyter notebook is to do it. So we have also created this worksheet as a step-by-step guide through it: https://github.com/UBC-DSCI/dsci-100/blob/master/materials/worksheet_01/worksheet_01.ipynb


## Loading a spreadsheet-like dataset

Often, the first thing we need to do in data analysis is to load a dataset into R. When we bring spreadsheet-like (think Microsof Excel tables) data, generally shaped like a rectangle, into R it is represented as what we call a "data frame" object. It is very similar to a spreadsheet where the rows are the observations collected/measured and the columns are the variables. 

<img src="img/spreadsheet_vs_dataframe.PNG" width="850"/>

The first data set we will learn how to load into R is in particular spreadsheet format called comma-separated file, or `.csv` for short. These files end in `.csv` and can be opened open and saved from common spreadsheet programs like Microsoft Excel and Google sheets. 

To load a data set into R, and then to do anything else to it afterwards, we will need to use something called a function. A function is a special word in R that takes in instructions (we call these arguments) and does something. The function we will use to read a `.csv` file into R is called `read_csv`.

In it's most basic use case, `read_csv` expects that the data file:

- has column names,
- uses a comma (`,`) to separate the columns, and
- does not have row names.

Let's explore how to do this! We will load a `.csv` file named "state_property_vote.csv" that is in the same folder as the file that contains this code. This data file is from https://datausa.io/ and has US state-level property, income, population and voting data from 2015 and 2016. If we were to open this data in a plain text editor, it would look like this:

```
state,med_income,med_prop_val,population,mean_commute_minutes,party
AK,64222,197300,733375,10.46830207,republican
AL,36924,94800,4830620,25.30990746,republican
AR,35833,83300,2958208,22.40108933,republican
AZ,44748,128700,6641928,20.58786,republican
CA,53075,252100,38421464,23.38085172,democrat
CO,48098,198900,5278906,19.50792188,democrat
CT,69228,246450,3593222,24.349675,democrat
DC,70848,475800,647484,28.2534,democrat
DE,54976,228500,926454,24.45553333,democrat
```

Below we demonstrate the code used to load the data into R. To do this, we first need to load the `tidyverse` library. We have to do this because the `read_csv` function was not included in the base installation of R, and so to be able to use it we have to load it from somewhere else - an R library called the `tidyverse` (more on this later). We do this using the library function. 

Next we call the `read_csv` function and pass it a single argument, the name of the file - "state_property_data.csv". We have to put quotes around filenames and other letters and words that we use in our code to distinguish it from the special words that make up R programming language.  This is the only argument we need to provide for this file because our file satifies everthing else the `read_csv` function expects of files in the default use case (which we just discussed). Later in the course, we'll learn more about how to deal with files where the default arguments are not appropriate, for example files that use spaces or tabs to separate the columns, or with no column names (headers).

```{r load state property data, warning=FALSE, message=FALSE}
library(tidyverse)
read_csv("state_property_vote.csv")
```


> **In case you have used R before and might be interested...** 
> Why the `read_csv` function from the `tidyverse` instead of the base R function `read.csv`? This is because `read_csv` is faster than `read.csv` and it creates a nicer variant of the base R data frame, called a tibble, that has several helpful properties we'll discuss in further detail later in the course.

## Assigning value to a data frame

When we loaded the US state-level property, income, population and voting data in R above using `read_csv`, we did not give this data frame a name, so it was merely printed to the screen and we cannot do anything else with it. This is not that useful - what we would like to do is give the output of the `read_csv` function, a data frame, a name so that we can use it later for analysis and visualization. 

To assign name to something in R, there are two possible ways - using either the assignment symbol (`<-`) or the equals symbol (`=`). From a style perspective, the assignment symbol is prefered and is what we will use in this course. When we name something in R using the assignment symbol, `<-`, we do not need to surround it with quotes like the filename. This is because we are formally telling R about this word and giving it a value. Only characters and words that act as values need to be surrounded by quotes.

Let's now use the assignment symbol to name the US state-level property, income, population and voting data frame, that we get from `read_csv`, `us_data`.

```{r load data with name}
us_data <- read_csv("state_property_vote.csv")
```


Wait a minute! Nothing happened this time! Or at least it looks like that. But actually something did happen, the data was read in and now has the name `us_data` associated with it. And we can use that name to access the data frame and do things with it. First we will type the name of the data frame to print it to the screen.


```{r print}
us_data
```

## Subsetting data frames with `select` & `filter`

Now, we are going to learn how to subset parts of data from a data frame in R using two other `tidyverse` functions named `select` and `filter`. `select()` allows you to subset columns of a data frame, while `filter()` allows you to subset rows with specific values.

Before we start using `select` and `filter`, let's take a look at the US state-level property, income and population data again to familiarize ourselves with it. We will do this by printing the data we loaded earlier in the chapter to the screen. 

```{r print data again}
us_data
```


When we look at the data frame we see there are 6 columns: 
1. US state abbreviation
2. Median household income
3. Median property value
4. US state population
5. Mean communte time in minutes
6. The party each state voted for in the 2016 US presidential election

There are 52 rows in this dataset (corresponding to the 51 US states and the US territory, Puerto Rico). 

Now let's use `select` to subset the state column from this data frame. To use `select` to subset the state column, we'll provide the function with two arguments. The first argument is the name of the data frame object, here `us_data`. The second argument is the column name that we want to subset, here `state`. `select` returns a single column (the state column that we asked for) as a data frame.


```{r}
state_column <- select(us_data, state)
state_column
```


### Using `select` to subset multiple columns

We can also use `select()` to subset multiple columns. Again, the first argument is the name of the data frame. Then we list all the columns we want as arguments separated by commas. Here the list was three columns: state, median property value and mean commute time in minutes.

```{r}
three_columns <- select(us_data, state, med_prop_val, mean_commute_minutes)
three_columns
```


### Using `select` to subset a range of columns

We can also use `select` to subest a range of columns using the colon. For example, to get all the columns from state to med_prop_val we provide the second arugument to `select` as `state:med_prop_val`.

```{r}
column_range <- select(us_data, state:med_prop_val)
column_range
```

### Using `filter` to subset a single row

We can use the `filter` function to subset rows with desired values from a data frame of interest. Again, our first argument is the name of the data frame object, `us_data`. The second argument is a logical statement to filter the rows, here we say that we are interested in rows where state equals NY (for New York). To make this comparison we use the equivalency operator `==` to compare the values of the `state` column with the value "NY". Similar to when we loaded the data file and put quotes around the filename, here we need to put quotes around "NY" to tell R that this is a character value and not one of the special words that make up R programming language, nor one of the names we have given to data frames in the code we have already written.

Filter returns a data frame that has all the columns of the input data frame but with only the rows we asked for in our filter statement. 

```{r}
new_york <- filter(us_data, state == "NY")
new_york
```

### Using `filter` to get rows with values above a threshold


If we are interested in finding information about the states who have a longer mean commute time than New York, whose mean commute time is 21.5 minutes, then we can provide an expression to filter to obtain rows where the value of mean_commute_minutes is greater than 21.5.

We see that `filter()` returns to use a data frame with 33 rows indicating that there are 33 states with longer commute times on average than New York.

```{r}
long_commutes <- filter(us_data, mean_commute_minutes > 21.5)
long_commutes
```


## Creating Visualizations in R

Creating data visualizations is an essential piece to any data analysis. For the remainder of Chapter 1, we will learn how we can use some of the `tidyverse` functions to make visualizations to explore the relationship between median household income and median propery value across US states, as well as how this relates to which party each state voted for in the 2016 US election. 

### Using `ggplot` to create a scatter plot

First, take another look at the dataset we have been focusing on - the US state-level property, income and population data from 2015. We can see that there is a row (which corresponds to an observation) for each state. And the two columns (which correspond to variables) we are interested in visualizing, median household income and median property value, are each in separate columns - thus the data are what we call a tidy data format. This is really important for `ggplot()` and many of the other `tidyverse` functions (as you will learn more in later chapters). 


```{r}
print(us_data)
```

### Using `ggplot` to create a scatter plot

To create a scatter plot of these two variables using the `ggplot` function, we would do the following: 

1. call the `ggplot` function
2. provide the name of the data frame as the first argument
3. call the aesthetic function, `aes`, to specify which column will correspond to the x-axis and which will correspond to the y-axis
4. add a "+" symbol at the end of the `ggplot` call to add a layer to the plot
5. call the `geom_point` function to tell R that we want to represent the data points as dots/points to create a scatter plot.

```{r prop_val_vs_income, fig.width=4.75, fig.height=4, warning=FALSE}
ggplot(us_data, aes(x = med_income, y = med_prop_val)) +
    geom_point()
``` 


### Formatting ggplot objects

One common and easy way to format, or change an aspect of your `ggplot` visualization is to add additional layers to your plot object using the `+` symbol. Here we use the `xlab` and `ylab` functions to add layers where we specify human readable labels for the x and y axis, respectively. There are many more layers we can add to format the plot further, and we will explore these in later chapters.

```{r prop_val_vs_income_human_labs, fig.width=4.75, fig.height=4, warning=FALSE}
ggplot(us_data, aes(x = med_income, y = med_prop_val)) +
    geom_point() +
    xlab("Income (USD)") +
    ylab("Median property value (USD)")    
```

### Coloring points by group
Another common thing to do with scatter plots is to colour points by a group/category in the dataset. For example,
given that we have the party each state voted for in the 2016 US Presidential election in the column named `party`, we can colour the points in our previous scatter plot to represent who each stated voted for. 


To do this we modify our scatter plot code above, specifically we add a colour argument to the `aes` function and we give that the value of the column we would like to colour the points by, here party:

```{r scatter colour by party, fig.width=4.75, fig.height=4, warning=FALSE}
ggplot(us_data, aes(x = med_income, y = med_prop_val, color = party)) +
  geom_point() +
  xlab("Income (USD)") +
  ylab("Median property value (USD)")
```

From making this data visualization we see that one data point has the label of "not applicable" instead of "democrat" or "republican". Let's use filter to look at the row that contains the "not applicable" value in the party column:

```{r}
missing_party <- filter(us_data, party == "not applicable")
missing_party
```


Ah, this explains it! That row in the dataset is actually not a US state, it is the US territory of Peurto Rico. Similar to other US territories, Puerto Rico resident's cannot vote for the US President. Hence the "not applicable" label. Let's remove this row from the data frame and rename the data frame `vote_data`. To do this we use the opposite of the equivalency operator, `==`, for our filter statement, the not equivalent operator, `!=` .

```{r}
vote_data <- filter(us_data, party != "not applicable")
vote_data
```

Now we see that the data frame has 51 rows, these correspond to the 50 states and the District of Columbia - all regions where residents can vote in the US presidential election. Let's now recreate the scatter plot we created above using this data frame:

```{r scatter colour by party no PR, fig.width=4.75, fig.height=4, warning=FALSE}
ggplot(vote_data, aes(x = med_income, y = med_prop_val, color = party)) +
  geom_point() +
  xlab("Income (USD)") +
  ylab("Median property value (USD)")
```


### Putting it all together

Below, we put it all together in one code chunk, and you can see here that in relatively few lines of R code we are able to create an entire data science workflow:

```{r nachos to cheesecake, fig.width=4.75, fig.height=4, warning=FALSE, message=FALSE}
library(tidyverse)

us_data <- read_csv("state_property_vote.csv")

vote_data <- filter(us_data, party != "not applicable")

ggplot(vote_data, aes(x = med_income, y = med_prop_val, color = party)) +
  geom_point() +
  xlab("Income (USD)") +
  ylab("Median property value (USD)")
```


### What's next?

In the next chapter we are going to dig in and spend more time learning how to load various differently formatted spreadsheet-like data sets into R, as well as how to scrape data from the web!
