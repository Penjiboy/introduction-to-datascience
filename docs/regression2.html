<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Regression II: Linear regression | Introduction to Data Science</title>
  <meta name="description" content="This is an open source textbook for teaching introductory data science." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Regression II: Linear regression | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source textbook for teaching introductory data science." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Regression II: Linear regression | Introduction to Data Science" />
  
  <meta name="twitter:description" content="This is an open source textbook for teaching introductory data science." />
  

<meta name="author" content="Tiffany-Anne Timbers" />
<meta name="author" content="Trevor Campbell" />
<meta name="author" content="Melissa Lee" />


<meta name="date" content="2020-03-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression1.html">
<link rel="next" href="clustering.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data Science</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#jupyter-notebooks"><i class="fa fa-check"></i><b>1.2</b> Jupyter notebooks</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#loading-a-spreadsheet-like-dataset"><i class="fa fa-check"></i><b>1.3</b> Loading a spreadsheet-like dataset</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#assigning-value-to-a-data-frame"><i class="fa fa-check"></i><b>1.4</b> Assigning value to a data frame</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#creating-subsets-of-data-frames-with-select-filter"><i class="fa fa-check"></i><b>1.5</b> Creating subsets of data frames with <code>select</code> &amp; <code>filter</code></a><ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#using-select-to-extract-multiple-columns"><i class="fa fa-check"></i><b>1.5.1</b> Using <code>select</code> to extract multiple columns</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#using-select-to-extract-a-range-of-columns"><i class="fa fa-check"></i><b>1.5.2</b> Using <code>select</code> to extract a range of columns</a></li>
<li class="chapter" data-level="1.5.3" data-path="index.html"><a href="index.html#using-filter-to-extract-a-single-row"><i class="fa fa-check"></i><b>1.5.3</b> Using <code>filter</code> to extract a single row</a></li>
<li class="chapter" data-level="1.5.4" data-path="index.html"><a href="index.html#using-filter-to-extract-rows-with-values-above-a-threshold"><i class="fa fa-check"></i><b>1.5.4</b> Using <code>filter</code> to extract rows with values above a threshold</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#exploring-data-with-visualizations"><i class="fa fa-check"></i><b>1.6</b> Exploring data with visualizations</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot"><i class="fa fa-check"></i><b>1.6.1</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot-1"><i class="fa fa-check"></i><b>1.6.2</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.3" data-path="index.html"><a href="index.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.6.3</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.6.4" data-path="index.html"><a href="index.html#coloring-points-by-group"><i class="fa fa-check"></i><b>1.6.4</b> Coloring points by group</a></li>
<li class="chapter" data-level="1.6.5" data-path="index.html"><a href="index.html#putting-it-all-together"><i class="fa fa-check"></i><b>1.6.5</b> Putting it all together</a></li>
<li class="chapter" data-level="1.6.6" data-path="index.html"><a href="index.html#whats-next"><i class="fa fa-check"></i><b>1.6.6</b> What’s next?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a><ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-plain-text-file-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data from a plain text file into R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#skipping-rows-when-reading-in-data"><i class="fa fa-check"></i><b>2.4.1</b> Skipping rows when reading in data</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.2</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.3</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.4" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.4</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#reading-data-from-an-microsoft-excel-file"><i class="fa fa-check"></i><b>2.5</b> Reading data from an Microsoft Excel file</a></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#reading-data-from-a-database"><i class="fa fa-check"></i><b>2.6</b> Reading data from a database</a><ul>
<li class="chapter" data-level="2.6.1" data-path="reading.html"><a href="reading.html#reading-data-from-a-sqlite-database"><i class="fa fa-check"></i><b>2.6.1</b> Reading data from a SQLite database</a></li>
<li class="chapter" data-level="2.6.2" data-path="reading.html"><a href="reading.html#reading-data-from-a-postgresql-database"><i class="fa fa-check"></i><b>2.6.2</b> Reading data from a PostgreSQL database</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="reading.html"><a href="reading.html#writing-data-from-r-to-a-.csv-file"><i class="fa fa-check"></i><b>2.7</b> Writing data from R to a <code>.csv</code> file</a></li>
<li class="chapter" data-level="2.8" data-path="reading.html"><a href="reading.html#scraping-data-off-the-web-using-r"><i class="fa fa-check"></i><b>2.8</b> Scraping data off the web using R</a><ul>
<li class="chapter" data-level="2.8.1" data-path="reading.html"><a href="reading.html#html-and-css-selectors"><i class="fa fa-check"></i><b>2.8.1</b> HTML and CSS selectors</a></li>
<li class="chapter" data-level="2.8.2" data-path="reading.html"><a href="reading.html#are-you-allowed-to-scrape-that-website"><i class="fa fa-check"></i><b>2.8.2</b> Are you allowed to scrape that website?</a></li>
<li class="chapter" data-level="2.8.3" data-path="reading.html"><a href="reading.html#using-rvest"><i class="fa fa-check"></i><b>2.8.3</b> Using <code>rvest</code></a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="reading.html"><a href="reading.html#additional-readingsresources"><i class="fa fa-check"></i><b>2.9</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a><ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#vectors-and-data-frames"><i class="fa fa-check"></i><b>3.3</b> Vectors and Data frames</a><ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#how-are-vectors-different-from-a-list"><i class="fa fa-check"></i><b>3.3.3</b> How are vectors different from a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.4</b> Tidy Data</a><ul>
<li class="chapter" data-level="3.4.1" data-path="wrangling.html"><a href="wrangling.html#what-is-tidy-data"><i class="fa fa-check"></i><b>3.4.1</b> What is tidy data?</a></li>
<li class="chapter" data-level="3.4.2" data-path="wrangling.html"><a href="wrangling.html#why-is-tidy-data-important-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Why is tidy data important in R?</a></li>
<li class="chapter" data-level="3.4.3" data-path="wrangling.html"><a href="wrangling.html#going-from-wide-to-long-or-tidy-using-gather"><i class="fa fa-check"></i><b>3.4.3</b> Going from wide to long (or tidy!) using <code>gather</code></a></li>
<li class="chapter" data-level="3.4.4" data-path="wrangling.html"><a href="wrangling.html#using-separate-to-deal-with-multiple-delimiters"><i class="fa fa-check"></i><b>3.4.4</b> Using separate to deal with multiple delimiters</a></li>
<li class="chapter" data-level="3.4.5" data-path="wrangling.html"><a href="wrangling.html#notes-on-defining-tidy-data"><i class="fa fa-check"></i><b>3.4.5</b> Notes on defining tidy data</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#combining-functions-using-the-pipe-operator"><i class="fa fa-check"></i><b>3.5</b> Combining functions using the pipe operator, <code>%&gt;%</code>:</a><ul>
<li class="chapter" data-level="3.5.1" data-path="wrangling.html"><a href="wrangling.html#using-to-combine-filter-and-select"><i class="fa fa-check"></i><b>3.5.1</b> Using <code>%&gt;%</code> to combine <code>filter</code> and <code>select</code></a></li>
<li class="chapter" data-level="3.5.2" data-path="wrangling.html"><a href="wrangling.html#using-with-more-than-two-functions"><i class="fa fa-check"></i><b>3.5.2</b> Using <code>%&gt;%</code> with more than two functions</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#iterating-over-data-with-group_by-summarize"><i class="fa fa-check"></i><b>3.6</b> Iterating over data with <code>group_by</code> + <code>summarize</code></a><ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics"><i class="fa fa-check"></i><b>3.6.1</b> Calculating summary statistics:</a></li>
<li class="chapter" data-level="3.6.2" data-path="wrangling.html"><a href="wrangling.html#calculating-group-summary-statistics"><i class="fa fa-check"></i><b>3.6.2</b> Calculating group summary statistics:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#additional-reading-on-the-dplyr-functions"><i class="fa fa-check"></i><b>3.7</b> Additional reading on the <code>dplyr</code> functions</a></li>
<li class="chapter" data-level="3.8" data-path="wrangling.html"><a href="wrangling.html#using-purrrs-map-functions-to-iterate"><i class="fa fa-check"></i><b>3.8</b> Using <code>purrr</code>’s <code>map*</code> functions to iterate</a><ul>
<li class="chapter" data-level="3.8.1" data-path="wrangling.html"><a href="wrangling.html#a-bit-more-about-the-map_-functions"><i class="fa fa-check"></i><b>3.8.1</b> A bit more about the <code>map_*</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="wrangling.html"><a href="wrangling.html#additional-readingsresources-1"><i class="fa fa-check"></i><b>3.9</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a><ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-2"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#choosing-the-visualization"><i class="fa fa-check"></i><b>4.3</b> Choosing the visualization</a></li>
<li class="chapter" data-level="4.4" data-path="viz.html"><a href="viz.html#refining-the-visualization"><i class="fa fa-check"></i><b>4.4</b> Refining the visualization</a></li>
<li class="chapter" data-level="4.5" data-path="viz.html"><a href="viz.html#creating-visualizations-with-ggplot2"><i class="fa fa-check"></i><b>4.5</b> Creating visualizations with <code>ggplot2</code></a><ul>
<li class="chapter" data-level="4.5.1" data-path="viz.html"><a href="viz.html#the-mauna-loa-co2-data-set"><i class="fa fa-check"></i><b>4.5.1</b> The Mauna Loa CO2 data set</a></li>
<li class="chapter" data-level="4.5.2" data-path="viz.html"><a href="viz.html#the-island-landmass-data-set"><i class="fa fa-check"></i><b>4.5.2</b> The island landmass data set</a></li>
<li class="chapter" data-level="4.5.3" data-path="viz.html"><a href="viz.html#the-old-faithful-eruption-waiting-time-data-set"><i class="fa fa-check"></i><b>4.5.3</b> The Old Faithful eruption / waiting time data set</a></li>
<li class="chapter" data-level="4.5.4" data-path="viz.html"><a href="viz.html#the-michelson-speed-of-light-data-set"><i class="fa fa-check"></i><b>4.5.4</b> The Michelson speed of light data set</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="viz.html"><a href="viz.html#explaining-the-visualization"><i class="fa fa-check"></i><b>4.6</b> Explaining the visualization</a></li>
<li class="chapter" data-level="4.7" data-path="viz.html"><a href="viz.html#saving-the-visualization"><i class="fa fa-check"></i><b>4.7</b> Saving the visualization</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="GitHub.html"><a href="GitHub.html"><i class="fa fa-check"></i><b>5</b> Version control with GitHub</a><ul>
<li class="chapter" data-level="5.1" data-path="GitHub.html"><a href="GitHub.html#overview-3"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="GitHub.html"><a href="GitHub.html#videos-to-learn-about-version-control-with-github-and-git"><i class="fa fa-check"></i><b>5.2</b> Videos to learn about version control with GitHub and Git</a><ul>
<li class="chapter" data-level="5.2.1" data-path="GitHub.html"><a href="GitHub.html#creating-a-github-repository"><i class="fa fa-check"></i><b>5.2.1</b> Creating a GitHub repository</a></li>
<li class="chapter" data-level="5.2.2" data-path="GitHub.html"><a href="GitHub.html#exploring-a-github-repository"><i class="fa fa-check"></i><b>5.2.2</b> Exploring a GitHub repository</a></li>
<li class="chapter" data-level="5.2.3" data-path="GitHub.html"><a href="GitHub.html#directly-editing-files-on-github"><i class="fa fa-check"></i><b>5.2.3</b> Directly editing files on GitHub</a></li>
<li class="chapter" data-level="5.2.4" data-path="GitHub.html"><a href="GitHub.html#logging-changes-and-pushing-them-to-github"><i class="fa fa-check"></i><b>5.2.4</b> Logging changes and pushing them to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="GitHub.html"><a href="GitHub.html#git-command-cheatsheet"><i class="fa fa-check"></i><b>5.3</b> Git command cheatsheet</a><ul>
<li class="chapter" data-level="5.3.1" data-path="GitHub.html"><a href="GitHub.html#getting-a-repository-from-github-onto-the-server-for-the-first-time"><i class="fa fa-check"></i><b>5.3.1</b> Getting a repository from GitHub onto the server for the first time</a></li>
<li class="chapter" data-level="5.3.2" data-path="GitHub.html"><a href="GitHub.html#logging-changes"><i class="fa fa-check"></i><b>5.3.2</b> Logging changes</a></li>
<li class="chapter" data-level="5.3.3" data-path="GitHub.html"><a href="GitHub.html#sending-your-changes-back-to-github"><i class="fa fa-check"></i><b>5.3.3</b> Sending your changes back to GitHub</a></li>
<li class="chapter" data-level="5.3.4" data-path="GitHub.html"><a href="GitHub.html#getting-changes"><i class="fa fa-check"></i><b>5.3.4</b> Getting changes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="GitHub.html"><a href="GitHub.html#terminal-cheatsheet"><i class="fa fa-check"></i><b>5.4</b> Terminal cheatsheet</a><ul>
<li class="chapter" data-level="5.4.1" data-path="GitHub.html"><a href="GitHub.html#see-where-you-are"><i class="fa fa-check"></i><b>5.4.1</b> See where you are:</a></li>
<li class="chapter" data-level="5.4.2" data-path="GitHub.html"><a href="GitHub.html#see-what-is-inside-the-directory-where-you-are"><i class="fa fa-check"></i><b>5.4.2</b> See what is inside the directory where you are:</a></li>
<li class="chapter" data-level="5.4.3" data-path="GitHub.html"><a href="GitHub.html#move-to-a-different-directory"><i class="fa fa-check"></i><b>5.4.3</b> Move to a different directory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>6</b> Classification I: Training &amp; predicting</a><ul>
<li class="chapter" data-level="6.1" data-path="classification.html"><a href="classification.html#overview-4"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification.html"><a href="classification.html#chapter-learning-objectives-4"><i class="fa fa-check"></i><b>6.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification.html"><a href="classification.html#the-classification-problem"><i class="fa fa-check"></i><b>6.3</b> The classification problem</a></li>
<li class="chapter" data-level="6.4" data-path="classification.html"><a href="classification.html#exploring-a-labelled-data-set"><i class="fa fa-check"></i><b>6.4</b> Exploring a labelled data set</a></li>
<li class="chapter" data-level="6.5" data-path="classification.html"><a href="classification.html#classification-with-k-nearest-neighbours"><i class="fa fa-check"></i><b>6.5</b> Classification with K-nearest neighbours</a></li>
<li class="chapter" data-level="6.6" data-path="classification.html"><a href="classification.html#k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>6.6</b> K-nearest neighbours in R</a></li>
<li class="chapter" data-level="6.7" data-path="classification.html"><a href="classification.html#data-preprocessing"><i class="fa fa-check"></i><b>6.7</b> Data preprocessing</a><ul>
<li class="chapter" data-level="6.7.1" data-path="classification.html"><a href="classification.html#shifting-and-scaling"><i class="fa fa-check"></i><b>6.7.1</b> Shifting and scaling</a></li>
<li class="chapter" data-level="6.7.2" data-path="classification.html"><a href="classification.html#balancing"><i class="fa fa-check"></i><b>6.7.2</b> Balancing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-continued.html"><a href="classification-continued.html"><i class="fa fa-check"></i><b>7</b> Classification II: Evaluation &amp; tuning</a><ul>
<li class="chapter" data-level="7.1" data-path="classification-continued.html"><a href="classification-continued.html#overview-5"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="classification-continued.html"><a href="classification-continued.html#chapter-learning-objectives-5"><i class="fa fa-check"></i><b>7.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="classification-continued.html"><a href="classification-continued.html#evaluating-accuracy"><i class="fa fa-check"></i><b>7.3</b> Evaluating accuracy</a></li>
<li class="chapter" data-level="7.4" data-path="classification-continued.html"><a href="classification-continued.html#tuning-the-classifier"><i class="fa fa-check"></i><b>7.4</b> Tuning the classifier</a><ul>
<li class="chapter" data-level="7.4.1" data-path="classification-continued.html"><a href="classification-continued.html#cross-validation"><i class="fa fa-check"></i><b>7.4.1</b> Cross-validation</a></li>
<li class="chapter" data-level="7.4.2" data-path="classification-continued.html"><a href="classification-continued.html#parameter-value-selection"><i class="fa fa-check"></i><b>7.4.2</b> Parameter value selection</a></li>
<li class="chapter" data-level="7.4.3" data-path="classification-continued.html"><a href="classification-continued.html#underoverfitting"><i class="fa fa-check"></i><b>7.4.3</b> Under/overfitting</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="classification-continued.html"><a href="classification-continued.html#splitting-data"><i class="fa fa-check"></i><b>7.5</b> Splitting data</a></li>
<li class="chapter" data-level="7.6" data-path="classification-continued.html"><a href="classification-continued.html#summary"><i class="fa fa-check"></i><b>7.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>8</b> Regression I: K-nearest neighbours</a><ul>
<li class="chapter" data-level="8.1" data-path="regression1.html"><a href="regression1.html#overview-6"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression1.html"><a href="regression1.html#chapter-learning-objectives-6"><i class="fa fa-check"></i><b>8.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression1.html"><a href="regression1.html#regression"><i class="fa fa-check"></i><b>8.3</b> Regression</a></li>
<li class="chapter" data-level="8.4" data-path="regression1.html"><a href="regression1.html#sacremento-real-estate-example"><i class="fa fa-check"></i><b>8.4</b> Sacremento real estate example</a></li>
<li class="chapter" data-level="8.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbours-regression"><i class="fa fa-check"></i><b>8.5</b> K-nearest neighbours regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression1.html"><a href="regression1.html#assessing-a-nearest-neighbours-regression-model"><i class="fa fa-check"></i><b>8.6</b> Assessing a nearest neighbours regression model</a><ul>
<li class="chapter" data-level="8.6.1" data-path="regression1.html"><a href="regression1.html#rmspe-versus-rmse"><i class="fa fa-check"></i><b>8.6.1</b> RMSPE versus RMSE</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="regression1.html"><a href="regression1.html#how-do-different-ks-affect-k-nn-regression-predictions"><i class="fa fa-check"></i><b>8.7</b> How do different k’s affect k-nn regression predictions</a></li>
<li class="chapter" data-level="8.8" data-path="regression1.html"><a href="regression1.html#assessing-how-well-the-model-predicts-on-unseen-data-with-the-test-set"><i class="fa fa-check"></i><b>8.8</b> Assessing how well the model predicts on unseen data with the test set</a></li>
<li class="chapter" data-level="8.9" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9</b> Strengths and limitations of k-nn regression</a></li>
<li class="chapter" data-level="8.10" data-path="regression1.html"><a href="regression1.html#multivariate-k-nn-regression"><i class="fa fa-check"></i><b>8.10</b> Multivariate k-nn regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>9</b> Regression II: Linear regression</a><ul>
<li class="chapter" data-level="9.1" data-path="regression2.html"><a href="regression2.html#overview-7"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="regression2.html"><a href="regression2.html#chapter-learning-objectives-7"><i class="fa fa-check"></i><b>9.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="regression2.html"><a href="regression2.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.3</b> Simple linear regression</a></li>
<li class="chapter" data-level="9.4" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r-using-caret"><i class="fa fa-check"></i><b>9.4</b> Linear regression in R using <code>caret</code></a></li>
<li class="chapter" data-level="9.5" data-path="regression2.html"><a href="regression2.html#comparing-simple-linear-and-k-nn-regression"><i class="fa fa-check"></i><b>9.5</b> Comparing simple linear and k-nn regression</a></li>
<li class="chapter" data-level="9.6" data-path="regression2.html"><a href="regression2.html#multivariate-linear-regression"><i class="fa fa-check"></i><b>9.6</b> Multivariate linear regression</a></li>
<li class="chapter" data-level="9.7" data-path="regression2.html"><a href="regression2.html#the-other-side-of-regression"><i class="fa fa-check"></i><b>9.7</b> The other side of regression</a></li>
<li class="chapter" data-level="9.8" data-path="regression2.html"><a href="regression2.html#additional-readingsresources-2"><i class="fa fa-check"></i><b>9.8</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>10</b> Clustering</a><ul>
<li class="chapter" data-level="10.1" data-path="clustering.html"><a href="clustering.html#overview-8"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="clustering.html"><a href="clustering.html#chapter-learning-objectives-8"><i class="fa fa-check"></i><b>10.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="clustering.html"><a href="clustering.html#clustering"><i class="fa fa-check"></i><b>10.3</b> Clustering</a></li>
<li class="chapter" data-level="10.4" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>10.4</b> K-means</a><ul>
<li class="chapter" data-level="10.4.1" data-path="clustering.html"><a href="clustering.html#measuring-cluster-quality"><i class="fa fa-check"></i><b>10.4.1</b> Measuring cluster quality</a></li>
<li class="chapter" data-level="10.4.2" data-path="clustering.html"><a href="clustering.html#the-clustering-algorithm"><i class="fa fa-check"></i><b>10.4.2</b> The clustering algorithm</a></li>
<li class="chapter" data-level="10.4.3" data-path="clustering.html"><a href="clustering.html#random-restarts"><i class="fa fa-check"></i><b>10.4.3</b> Random restarts</a></li>
<li class="chapter" data-level="10.4.4" data-path="clustering.html"><a href="clustering.html#choosing-k"><i class="fa fa-check"></i><b>10.4.4</b> Choosing K</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="clustering.html"><a href="clustering.html#k-means-in-r"><i class="fa fa-check"></i><b>10.5</b> K-means in R</a></li>
<li class="chapter" data-level="10.6" data-path="clustering.html"><a href="clustering.html#additional-readings"><i class="fa fa-check"></i><b>10.6</b> Additional readings:</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression2" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Regression II: Linear regression</h1>
<div id="overview-7" class="section level2">
<h2><span class="header-section-number">9.1</span> Overview</h2>
<p>Introduction to linear regression models. We will also begin to compare k-nn to linear models in the context of regression.</p>
</div>
<div id="chapter-learning-objectives-7" class="section level2">
<h2><span class="header-section-number">9.2</span> Chapter learning objectives</h2>
<p>By the end of the chapter, students will be able to:</p>
<ul>
<li>Perform ordinary least squares regression in R using <code>caret</code>’s <code>train</code> with <code>method = &quot;lm&quot;</code> to predict the values for a test dataset.</li>
<li>Compare and contrast predictions obtained from k-nearest neighbour regression to those obtained using simple ordinary least squares regression from the same dataset.</li>
<li>In R, overlay the ordinary least squares regression lines from <code>geom_smooth</code> on a single plot.</li>
</ul>
</div>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">9.3</span> Simple linear regression</h2>
<p>k-nn is not the only type of regression, there are many, and one common and quite useful type of regression is called simple linear regression. Simple linear regression is similar to k-nn regression in that the target/response variable is expected to be quantitative, however, one way it varies quite differently is how the training data is used to predict a value for a new observation. Instead of looking at the <span class="math inline">\(k\)</span>-nearest neighbours and averaging over their values for a prediction, in simple linear regression all the training data points are used to create a straight line of “best fit”, and then the line is used to “look-up” the predicted value. <em>Note - for simple linear regression there is only one response variable and only one predictor. Later in this chapter we introduce the more general linear regression case where more than one predictor can be used.</em></p>
<p>For example, let’s revisit the smaller version of the Sacramento housing data set and the prediction case where we come across a new house we are interested in purchasing, and it is 2000 square feet! Its advertised list price is $350,000 should we give them what they are asking? Or is that overpriced and we should offer less?</p>
<p>To answer this question using simple linear regression, we use the data we have to draw the straight line of “best fit” through our existing data points:</p>
<p><img src="_main_files/figure-html/08-lin-reg1-1.png" width="480" /></p>
<p>Then we can use this line to “look up” the predicted price given the value we have for the predictor/explanatory variable (here 2000 square feet).</p>
<p><img src="_main_files/figure-html/08-lin-reg2-1.png" width="480" /></p>
<pre><code>## [1] 305551.8</code></pre>
<p>Using simple linear regression on this small data set to predict the sale price for a 2000 square foot house we get a predicted value of $305552. But wait a minute… How exactly does simple linear regression choose the line of “best fit”? Many different lines could be drawn through the data points, we show some examples below:</p>
<p><img src="_main_files/figure-html/08-several-lines-1.png" width="480" /></p>
<p>Simple linear regression chooses the straight line of “best fit” by choosing the line that minimzes the <strong>average</strong> vertical distance between itself and each of the observed data points. From the lines shown above, that is the blue line. What exactly do we mean by the vertical distance between the predicted values (which fall along the line of “best fit”) and the observed data points? We illustrate these distances in the plot below with a red line:</p>
<p><img src="_main_files/figure-html/08-verticalDistToMin-1.png" width="480" /></p>
<p>How do we assess the predictive accuracy of a simple linear regression model? We use the same measure of predictive performance we used with k-nn regression, <span class="math inline">\(RMPSE\)</span>.</p>
</div>
<div id="linear-regression-in-r-using-caret" class="section level2">
<h2><span class="header-section-number">9.4</span> Linear regression in R using <code>caret</code></h2>
<p>We can perform simple linear regression in R using the <code>caret</code> package in a very similar manner to how we performed k-nn regression, using the <code>train</code> function. To do this, instead of setting <code>method = &quot;knn&quot;</code> we instead set <code>method = &quot;lm&quot;</code>. Another difference is that we do not need to choose <span class="math inline">\(k\)</span> in the context of linear regression and so we do not need to perform cross validation. Below we illustrate how we can use the <code>caret</code> package to predict house sale price given house size using a simple linear regression approach using the full Sacramento real estate data set:</p>
<p>As usual, we should start by putting some test data away in a lock box that we can come back to after we choose our final model, so let’s take care of that business now.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2019</span>) <span class="co"># makes the random selection of rows reproducible</span>
training_rows &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(price) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># converts Class from a tibble to a vector</span>
<span class="st">  </span><span class="kw">createDataPartition</span>(<span class="dt">p =</span> <span class="fl">0.6</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)

X_train &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(sqft) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>()

Y_train &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(price) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unlist</span>()

X_test &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(sqft) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="op">-</span>training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>()

Y_test &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(price) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="op">-</span>training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unlist</span>()</code></pre></div>
<p>Now that we have our training data, we fit our simple linear regression model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_model &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> X_train, 
                      <span class="dt">y =</span> Y_train, 
                      <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) </code></pre></div>
<p>And finally, we predict on the test data set to assess how well our model does:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_pred &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_model, X_test)
lm_modelvalues &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">obs =</span> Y_test, <span class="dt">pred =</span> test_pred)
lm_test_results &lt;-<span class="st"> </span><span class="kw">defaultSummary</span>(lm_modelvalues)
lm_test_results</code></pre></div>
<pre><code>##         RMSE     Rsquared          MAE 
## 8.668847e+04 6.152298e-01 6.232425e+04</code></pre>
<p>Our final model’s test error as assessed by <span class="math inline">\(RMSPE\)</span> is 86688.47. Remember that this is in units of the target/response variable, and here that is US Dollars (USD). Does this mean our model is “good” at predicting house sale price based off of the predictor of home size? Again answering this is tricky to answer and requires to use domain knowledge and think about the application you are using the prediction for.</p>
<p>And what does our final simple linear regression model look like when we predict across all possible house sizes we might encounter in the Sacremento area? There is a plotting function in the <code>tidyverse</code>, <code>geom_smooth</code>, that allows us to do this easily by adding a layer on our plot with the simple linear regression predicted line of “best fit”. The default for this adds a plausible range to this line that we are not interested in at this point, so to avoid plotting it, we provide the argument <code>se = FALSE</code> in our call to <code>geom_smooth</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_data &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(X_train, <span class="kw">data.frame</span>(<span class="dt">price =</span> Y_train))

lm_plot_final &lt;-<span class="st"> </span><span class="kw">ggplot</span>(train_data, <span class="kw">aes</span>(<span class="dt">x =</span> sqft, <span class="dt">y =</span> price)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;House size (square footage)&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Price (USD)&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> <span class="kw">dollar_format</span>())  <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) 
lm_plot_final</code></pre></div>
<p><img src="_main_files/figure-html/08-lm-predict-all-1.png" width="480" /></p>
</div>
<div id="comparing-simple-linear-and-k-nn-regression" class="section level2">
<h2><span class="header-section-number">9.5</span> Comparing simple linear and k-nn regression</h2>
<p>Now that we have a general understanding of both simple linear and k-nn regression, we can start to compare and contrast these methods as well as the predictions made by them. To start, let’s look at the visualization of the simple linear regression model predictions for the Sacramento real estate data (predicting price from house size) and the “best” k-nn regression model obtained from the same problem:</p>
<p><img src="_main_files/figure-html/08-compareRegression-1.png" width="960" /></p>
<p>What differences do we observe from the visualization above? One obvious difference is the shape of the blue lines. In simple linear regression we are restricted to a straight line, whereas in k-nn regression our line is much more flexible and can be quite wiggly. There can be an advantage to limiting the model to a straight line, as simple linear regression does, in that a straight line model is quite interpretable and can be defined by two numbers, the y-intercept and the slope. The slope is particularly meaningful for interpretation, as it tells us what unit increase in the target/response variable we predict given a unit increase in the predictor/explanatory variable. Additionally, because our model is restricted to a straight line, we can even use the mathematical equation for a straight line as a basis to write a mathematical expression of our model.</p>
<p>Remembering that the equation for a straight line is:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1X\]</span> Where:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> is the y-intercept of the line (the value where the line cuts the y-axis)</li>
<li><span class="math inline">\(\beta_1\)</span> is the slope of the line</li>
</ul>
<p>We can then write:</p>
<p><span class="math display">\[house\: price = \beta_0 + \beta_1house\: size\]</span></p>
<p>And finally, fill in the values for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> from the straight line. We can get these values from our model by accessing the <code>finalModel$coefficients</code> attribute of our simple linear regression model object <code>lm_model</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_model<span class="op">$</span>finalModel<span class="op">$</span>coefficients</code></pre></div>
<pre><code>## (Intercept)        sqft 
##  19835.2677    134.7796</code></pre>
<p>Which we can then plug into the equation:</p>
<p><span class="math display">\[house\: price = 19835.27 + 135*house\: size\]</span></p>
<p>k-nn regression, as simple as it is to implement and understand, has no such interpretability from it’s wiggly line.</p>
<p>There can however also be a disadvantage to using a simple linear regression model in some cases, particularly when the relationship between the target and the predictor is not linear, but instead some other shape, such as curved or circular. In these cases the prediction model from a simple linear regression will underfit (have high bias), meaning that model/predicted values does not match the actual observed values very well. Such a model would probably have a quite high <span class="math inline">\(RMSE\)</span> when assessing model goodness of fit on the training data and a quite high <span class="math inline">\(RMPSE\)</span> when assessing model prediction quality on a test data set. On such a data set, k-nn regression may fare better. Additionally, there are other types of regression you can learn about in future courses that may do even better at predicting with such data.</p>
<p>How do these two models compare on this data set? On the visualizations above we also printed the <span class="math inline">\(RMPSE\)</span> as calculated from predicting on the test data set that was not used to train/fit the models. The <span class="math inline">\(RMPSE\)</span> for the simple linear regression model is less than the <span class="math inline">\(RMPSE\)</span> for the k-nn regression model, and thus if were were comparing these in practice we would choose to use the simple linear regression model to make our predictions because of this (in addition to the fact the the simple linear regression model is more interpretable).</p>
</div>
<div id="multivariate-linear-regression" class="section level2">
<h2><span class="header-section-number">9.6</span> Multivariate linear regression</h2>
<p>As in k-nn classification and k-nn regression, we can move beyond the simple case of one response variable and only one predictor and perform multivariate linear regression where we can have multiple predictors. In this case we fit a plane to the data, as opposed to a straight line.</p>
<p>To do this, we follow a very similar approach to what we did using <code>caret</code> for k-nn regression, however, we do not need to use cross-validation to choose <span class="math inline">\(k\)</span>. We also do not need to scale the data for linear regression as it does not use a distance between points calculation in its algorithm. We demonstrate how to do this below using the Sacramento real estate data with both house size (measured in square feet) as well as number of bathrooms as our predictors, and continue to use house sale price as our outcome/target variable that we are trying to predict.</p>
<p>We will start by splitting our data into a trained and test set as we did before:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2019</span>) <span class="co"># makes the random selection of rows reproducible</span>
training_rows &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(price) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># converts Class from a tibble to a vector</span>
<span class="st">  </span><span class="kw">createDataPartition</span>(<span class="dt">p =</span> <span class="fl">0.6</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)

lm_X_train &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(sqft, baths) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>()

lm_Y_train &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(price) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unlist</span>()

lm_X_test &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(sqft, baths) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="op">-</span>training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>()

lm_Y_test &lt;-<span class="st"> </span>Sacramento <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(price) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="op">-</span>training_rows) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unlist</span>()</code></pre></div>
<p>Now we can fit the model on the training set using the <code>method = &quot;lm&quot;</code> argument in the train function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_mult_reg_final &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> lm_X_train, <span class="dt">y =</span> lm_Y_train, <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</code></pre></div>
<p>What does our model predictions look like in the case of linear regression when we have two predictors? We illustrate this below:</p>
<p><div id="htmlwidget-5e4fd7548806fff8b244" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-5e4fd7548806fff8b244">{"x":{"visdat":{"268e4738b655":["function () ","plotlyVisDat"]},"cur_data":"268e4738b655","attrs":{"268e4738b655":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","marker":{"size":5,"opacity":0.4,"color":"red"},"inherit":true},"268e4738b655.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"z":{},"type":"surface","x":{},"y":{},"colorbar":{"title":"Price (USD)"},"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"House size (square feet)"},"zaxis":{"title":"Price (USD)"},"yaxis":{"title":"Number of bathrooms"}},"hovermode":"closest","showlegend":true,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[1167,796,1104,1177,941,1146,1289,871,1022,844,795,588,1356,1118,1329,1601,901,1088,963,1119,1380,1248,1039,1116,1039,1418,1082,1472,1146,760,1304,1056,1043,1587,1120,1656,1590,1463,1406,1943,1172,1152,1215,1603,1420,1586,2162,1266,1820,936,1665,1511,1590,1596,1616,1478,1277,1448,2235,2093,2163,1269,1473,958,1305,1326,1921,2790,1541,1018,1713,1380,1284,3009,3612,2056,1857,1126,2213,2494,1843,1520,2367,3516,2536,1914,2725,2354,1842,1961,3134,1873,2734,3164,3599,2054,1627,2846,2052,3433,3615,3714,3508,2462,2900,3705,795,1099,746,1316,1337,924,1516,1220,1643,722,1051,1050,1110,1120,1080,1211,1266,994,1448,1320,1364,1310,810,1123,904,1321,1392,1439,1159,1671,1265,1007,1685,1829,1555,1120,1137,1174,1415,2126,1289,1799,1308,723,1376,948,1317,1360,1522,1605,1475,1315,1567,2187,1291,1129,2491,1456,1574,2085,1595,1567,1253,1980,2030,1531,1750,1653,2056,2169,1527,1401,1411,2990,1284,1329,1829,1665,1258,2575,1108,1595,2159,2295,1900,3389,2190,2607,2724,2829,3577,1247,2581,2068,3992,3397,3881,3167,1598,1929,3070,2272,2222,3059,2846,2484,840,623,932,796,834,924,795,984,1013,1012,918,964,625,888,1120,1014,966,779,1174,1207,1995,1366,901,696,1104,972,1390,780,1245,1300,1120,1590,1407,1516,1676,1370,1370,990,1162,1112,1100,1039,1159,1917,1204,1451,1000,1152,1154,1353,1329,1505,1144,930,1766,1258,1872,1856,1939,998,1758,950,1739,1516,1555,1212,1871,2026,1375,1250,1058,1187,1936,1427,1678,1816,3076,1844,1306,2447,1176,1160,1830,1724,2175,1808,1457,1847,1468,2550,1922,1343,1510,1559,2992,1524,1248,2489,1851,2218,1394,1410,3468,2346,2590,1810,2789,1606,3499,1871,1800,2752,1596,1179,1697,2085,2548,1744,2730,2376,1788,2002,4246,2274,3056,3332,1905,1320,1873,3741,2660,3357,1166,838,904,1032,904,990,900,906,1011,1089,832,800,1292,810,1064,911,846,1169,1164,1341,1219,1253,1118,1260,1400,1264,1060,1466,1092,960,2475,1410,1483,1140,1549,1410,1669,1103,2161,1650,1200,1170,1199,1695,1157,1174,1770,1436,1638,1273,1578,796,1386,1452,1232,1578,1498,1473,1150,1127,1479,1040,1430,1953,1120,2329,1376,1566,1115,1032,1776,2254,1441,2126,1094,2111,1915,2367,1962,1789,1876,2504,1676,1367,1899,1636,1451,1506,2605,1196,1621,1811,2647,1910,2494,1650,1582,1735,2096,1282,1721,1328,1982,1623,1457,2555,1577,2048,2169,2264,2004,2212,1360,1951,2962,1888,2155,1548,1322,2484,2258,2212,1616,2606,2877,1704,2172,2100,1795,1924,2295,2616,1727,1485,1655,3179,2049,2875,2199,2242,2278,1493,1944,3913,3151,2787,3261,2480,1704,2418,4091,1348,4090,3229,2346,2356,3220,3579,3885,3782,1011,1158,1139,1354,1051,1229,1005,1188,1093,1089,1127,1309,1144,1065,1206,1285,1543,1019,1392,1302,1488,1381,1265,881,1608,1104,1859,1638,1177,904,1204,1477,960,1194,1428,1892,1073,1416,936,1358,1089,795,1371,1310,1450,1882,1302,1418,1770,1627,1665,1040,1450,1358,1329,1715,1362],"y":[1,1,2,1,2,2,2,1,2,1,1,1,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,1,2,2,2,2,2,2,1,2,2,2,2,4,2,2,1,3,2,2,2,2,2,2,2,3,2,2,2,3,1,2,2,2,3,2,1,2,2,2,3,4,2,2,1,4,3,2,2,3,4,3,3,3,3,3,3,2,3,3,3,3,2,3,2,3,3,3,4,4,2,3,4,1,2,1,2,1,1,2,1,1,1,1,1,2,2,2,2,2,2,2,1,2,2,1,2,1,1,2,2,2,2,2,2,2,2,2,2,2,1,1.5,2,2,2,2,1,1.5,1,2,1,2,2,2,2,2,2,1,2,3,2,2,4,2,2,2,2.5,3,2,3,3,2,2,2,2,2,4,1,2,2.5,2,2,2,1,2,2,3,2,3,2,2,3,3,3,1,2,1,3,4,3,4,2,3,3,2.5,2,3.5,5,2,1,1,1,1,1,1,1,1,1,1,2,1,1,1,2,1,1,1,1,2,4,2,2,1,2,1,2,1,2,2,2,2,2,2,2,2,2,1,2,2,2,1,2,2,2,2,2,1,2,2,2,2,2,1,2,1,2,2,3,1,2,1,3,2,2,2,2,3,2,2,1,2,3,2,2,2,3,2,2,3,2,1,2,2,3,2,2,2,2,3,3,2,2,2,3,2,2,3,3,2,2,2,3,3,3,2,2,2,3.5,2,2,3,2,2,2,3,2,2,3,2,3,2,3,2,4,3.5,2,2,2,2,3,3,2,1,1,1,1,2,1,1,1,2,1,1,2,1,2,1,1,2,2,2,2,2,2,2,2,1,1,2,2,2,4,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,2.5,1,1,2,2,1,2,2,2,2,1,2,1,1,2,2,2,3,2,2,3,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2.5,2.5,3,2,2,2,3,2,2,2,2,2,2,3,2,2,2,2.5,2,3,2,2.5,3,2,3,2,2,2,3,3,2,3,3,2,2,2,2,2.5,2,3,1,2,2,4.5,2,3,2,3,3,1,2,4,3,3,3,2.5,2,2,4,1,3.5,3,3,3,2.5,3,3.5,3.5,1,2,2,2,1,1,2,2,2,2,2,2,2,1.5,2,1,2,1,2,2,2,2,2,1,2,2,2,1,2,2,2,2,1,1.5,2,3,1,2,1,2,2,1,2,1,2,2,2,2,2,2,2,1,2,2,2,2,2],"z":[68212,68880,90895,91002,94905,98937,106250,106852,108750,113263,116250,120000,121630,122000,122682,124100,125000,126640,127281,129000,131200,132000,133000,138750,141000,146250,147308,148750,149593,150000,152000,156896,161250,161500,164000,166357,173000,174250,178760,179580,181000,181872,182716,183200,189000,194000,195000,198000,200000,200000,206000,208000,212864,221000,227887,231477,235000,236000,236685,237800,242638,244000,244500,244960,250000,250134,254200,258000,260000,260014,263500,265000,280908,280987,282400,285000,291000,292024,297000,297000,298000,299000,315537,320000,320000,328360,335750,335750,339500,347029,347650,352000,370500,375000,381300,381942,391000,395000,415000,425000,430000,445000,510000,539000,585000,600000,69000,70000,78400,89000,90000,92000,97750,98000,99000,100000,111000,123225,123750,125000,126000,135000,140000,142500,145000,148500,150000,150000,156000,156000,157788,161829,165000,168000,169000,175000,179000,180000,182000,184500,185000,189000,194000,195000,201000,202500,205000,205000,205000,207000,210000,211500,215000,222381,225000,228000,229665,230000,230000,235000,236250,240000,245000,250000,255000,256054,260000,261000,264469,270000,270000,270000,270000,275000,275000,292000,293993,294000,296769,297500,300000,300000,306500,312500,330000,331000,339000,339000,345000,350000,361745,370000,380000,402000,406026,433500,438700,445000,450000,460000,460000,465000,471750,480000,484000,485000,495000,500500,582000,614000,680000,699000,40000,62050,65000,65000,68000,77000,82732,84675,85000,90000,91000,97500,100000,101000,102750,113000,114000,114750,116100,119250,120000,120108,121500,121725,123000,125000,125573,127000,139500,140800,145000,147000,149600,150000,155000,155435,155500,160000,164000,165000,167000,168000,170000,170000,174000,180000,182000,188325,191500,192000,192700,197654,200345,203000,207000,212000,213675,215000,215000,215100,217500,220000,221000,222900,225500,228327,230000,231200,232000,232500,233641,234000,235000,236073,238000,240000,240000,241000,245000,246000,247234,249862,254172,258000,261000,262500,270000,274500,275336,277980,284686,284893,285000,285000,295000,296056,297359,304000,305000,311328,313138,316630,320000,320000,331500,345746,351000,353767,355000,360552,362305,368500,370000,378000,400000,408431,413000,416767,420000,423000,427500,445000,452000,470000,475000,488750,500000,506688,512000,579093,636000,668365,30000,55422,63000,65000,65000,66500,71000,77000,85000,95625,96140,104250,105000,108000,109000,115000,115000,122000,122500,123000,124000,125000,131750,137760,138000,140000,145000,150000,150000,155000,159900,160000,161600,162000,165000,165000,168750,170000,170250,173000,176095,176250,178000,179000,180000,180000,182587,185074,187000,190000,190000,190000,191250,193000,194818,195000,195000,195000,198000,199900,205000,205000,205878,207744,209000,213750,215000,220000,220000,220000,221250,222750,225000,228750,229000,233500,240000,240000,240971,243450,243500,246750,247000,249000,249000,250000,255000,255000,257200,260000,260000,263500,267750,271000,276000,276500,280000,288000,289000,294000,294173,295000,298000,300000,300000,300000,300567,306000,311518,313000,315000,315000,315000,315000,322000,325000,325500,328370,330000,331200,332000,334000,335000,346375,349000,350000,350000,350000,351000,356200,360000,375000,380000,380578,386222,389000,395500,397000,400000,412500,420454,425000,425000,433500,438000,441000,446000,460000,475000,490000,508000,545000,560000,575000,600000,600000,600000,610000,680000,879000,70000,80000,93600,104000,105000,110000,119000,123675,127059,129500,130000,131750,134000,138000,142000,143012,145846,148750,150000,157500,160000,161250,164000,165000,165750,170000,170000,170725,171750,173056,174250,176850,185000,188000,188700,189836,198000,200000,200100,201528,205000,207973,208250,208318,213000,219000,219794,220000,220000,223000,224000,224000,228000,229027,229500,230000,235738],"type":"scatter3d","mode":"markers","marker":{"color":"red","size":5,"opacity":0.4,"line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"Price (USD)","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"z":[[100636.728647256,111106.991983401,121577.255319546,132047.51865569,142517.781991835,152988.045327979,163458.308664124,173928.572000268,184398.835336413,194869.098672558,205339.362008702,215809.625344847,226279.888680991,236750.152017136,247220.41535328,257690.678689425,268160.94202557,278631.205361714,289101.468697859,299571.732034003,310041.995370148,320512.258706292,330982.522042437,341452.785378581,351923.048714726,362393.312050871,372863.575387015,383333.83872316,393804.102059304,404274.365395449,414744.628731593,425214.892067738,435685.155403883,446155.418740027,456625.682076172,467095.945412316,477566.208748461,488036.472084605,498506.73542075,508976.998756895,519447.262093039,529917.525429184,540387.788765328,550858.052101473,561328.315437617,571798.578773762,582268.842109907,592739.105446051,603209.368782196,613679.63211834],[100055.834236485,110526.09757263,120996.360908775,131466.624244919,141936.887581064,152407.150917208,162877.414253353,173347.677589497,183817.940925642,194288.204261787,204758.467597931,215228.730934076,225698.99427022,236169.257606365,246639.520942509,257109.784278654,267580.047614799,278050.310950943,288520.574287088,298990.837623232,309461.100959377,319931.364295521,330401.627631666,340871.890967811,351342.154303955,361812.4176401,372282.680976244,382752.944312389,393223.207648533,403693.470984678,414163.734320823,424633.997656967,435104.260993112,445574.524329256,456044.787665401,466515.051001545,476985.31433769,487455.577673835,497925.841009979,508396.104346124,518866.367682268,529336.631018413,539806.894354557,550277.157690702,560747.421026847,571217.684362991,581687.947699136,592158.21103528,602628.474371425,613098.737707569],[99474.9398257145,109945.203161859,120415.466498004,130885.729834148,141355.993170293,151826.256506437,162296.519842582,172766.783178727,183237.046514871,193707.309851016,204177.57318716,214647.836523305,225118.099859449,235588.363195594,246058.626531738,256528.889867883,266999.153204028,277469.416540172,287939.679876317,298409.943212461,308880.206548606,319350.46988475,329820.733220895,340290.99655704,350761.259893184,361231.523229329,371701.786565473,382172.049901618,392642.313237762,403112.576573907,413582.839910052,424053.103246196,434523.366582341,444993.629918485,455463.89325463,465934.156590774,476404.419926919,486874.683263064,497344.946599208,507815.209935353,518285.473271497,528755.736607642,539225.999943786,549696.263279931,560166.526616076,570636.78995222,581107.053288365,591577.316624509,602047.579960654,612517.843296799],[98894.0454149436,109364.308751088,119834.572087233,130304.835423377,140775.098759522,151245.362095666,161715.625431811,172185.888767956,182656.1521041,193126.415440245,203596.678776389,214066.942112534,224537.205448678,235007.468784823,245477.732120968,255947.995457112,266418.258793257,276888.522129401,287358.785465546,297829.04880169,308299.312137835,318769.575473979,329239.838810124,339710.102146269,350180.365482413,360650.628818558,371120.892154702,381591.155490847,392061.418826992,402531.682163136,413001.945499281,423472.208835425,433942.47217157,444412.735507714,454882.998843859,465353.262180004,475823.525516148,486293.788852293,496764.052188437,507234.315524582,517704.578860726,528174.842196871,538645.105533015,549115.36886916,559585.632205305,570055.895541449,580526.158877594,590996.422213738,601466.685549883,611936.948886028],[98313.1510041726,108783.414340317,119253.677676462,129723.941012606,140194.204348751,150664.467684895,161134.73102104,171604.994357185,182075.257693329,192545.521029474,203015.784365618,213486.047701763,223956.311037907,234426.574374052,244896.837710197,255367.101046341,265837.364382486,276307.62771863,286777.891054775,297248.154390919,307718.417727064,318188.681063208,328658.944399353,339129.207735498,349599.471071642,360069.734407787,370539.997743931,381010.261080076,391480.524416221,401950.787752365,412421.05108851,422891.314424654,433361.577760799,443831.841096943,454302.104433088,464772.367769233,475242.631105377,485712.894441522,496183.157777666,506653.421113811,517123.684449955,527593.9477861,538064.211122244,548534.474458389,559004.737794534,569475.001130678,579945.264466823,590415.527802967,600885.791139112,611356.054475257],[97732.2565934017,108202.519929546,118672.783265691,129143.046601835,139613.30993798,150083.573274125,160553.836610269,171024.099946414,181494.363282558,191964.626618703,202434.889954847,212905.153290992,223375.416627137,233845.679963281,244315.943299426,254786.20663557,265256.469971715,275726.733307859,286196.996644004,296667.259980149,307137.523316293,317607.786652438,328078.049988582,338548.313324727,349018.576660871,359488.839997016,369959.10333316,380429.366669305,390899.63000545,401369.893341594,411840.156677739,422310.420013883,432780.683350028,443250.946686172,453721.210022317,464191.473358462,474661.736694606,485132.000030751,495602.263366895,506072.52670304,516542.790039184,527013.053375329,537483.316711474,547953.580047618,558423.843383763,568894.106719907,579364.370056052,589834.633392196,600304.896728341,610775.160064486],[97151.3621826307,107621.625518775,118091.88885492,128562.152191064,139032.415527209,149502.678863354,159972.942199498,170443.205535643,180913.468871787,191383.732207932,201853.995544076,212324.258880221,222794.522216366,233264.78555251,243735.048888655,254205.312224799,264675.575560944,275145.838897088,285616.102233233,296086.365569378,306556.628905522,317026.892241667,327497.155577811,337967.418913956,348437.6822501,358907.945586245,369378.208922389,379848.472258534,390318.735594679,400788.998930823,411259.262266968,421729.525603112,432199.788939257,442670.052275401,453140.315611546,463610.578947691,474080.842283835,484551.10561998,495021.368956124,505491.632292269,515961.895628413,526432.158964558,536902.422300703,547372.685636847,557842.948972992,568313.212309136,578783.475645281,589253.738981426,599724.00231757,610194.265653715],[96570.4677718598,107040.731108004,117510.994444149,127981.257780294,138451.521116438,148921.784452583,159392.047788727,169862.311124872,180332.574461016,190802.837797161,201273.101133305,211743.36446945,222213.627805595,232683.891141739,243154.154477884,253624.417814028,264094.681150173,274564.944486317,285035.207822462,295505.471158607,305975.734494751,316445.997830896,326916.26116704,337386.524503185,347856.78783933,358327.051175474,368797.314511619,379267.577847763,389737.841183908,400208.104520052,410678.367856197,421148.631192341,431618.894528486,442089.157864631,452559.421200775,463029.68453692,473499.947873064,483970.211209209,494440.474545353,504910.737881498,515381.001217643,525851.264553787,536321.527889932,546791.791226076,557262.054562221,567732.317898365,578202.58123451,588672.844570655,599143.107906799,609613.371242944],[95989.5733610889,106459.836697233,116930.100033378,127400.363369523,137870.626705667,148340.890041812,158811.153377956,169281.416714101,179751.680050245,190221.94338639,200692.206722535,211162.470058679,221632.733394824,232102.996730968,242573.260067113,253043.523403257,263513.786739402,273984.050075547,284454.313411691,294924.576747836,305394.84008398,315865.103420125,326335.366756269,336805.630092414,347275.893428559,357746.156764703,368216.420100848,378686.683436992,389156.946773137,399627.210109281,410097.473445426,420567.73678157,431038.000117715,441508.26345386,451978.526790004,462448.790126149,472919.053462293,483389.316798438,493859.580134582,504329.843470727,514800.106806872,525270.370143016,535740.633479161,546210.896815305,556681.16015145,567151.423487594,577621.686823739,588091.950159884,598562.213496028,609032.476832173],[95408.6789503179,105878.942286462,116349.205622607,126819.468958752,137289.732294896,147759.995631041,158230.258967185,168700.52230333,179170.785639474,189641.048975619,200111.312311764,210581.575647908,221051.838984053,231522.102320197,241992.365656342,252462.628992486,262932.892328631,273403.155664776,283873.41900092,294343.682337065,304813.945673209,315284.209009354,325754.472345498,336224.735681643,346694.999017788,357165.262353932,367635.525690077,378105.789026221,388576.052362366,399046.31569851,409516.579034655,419986.8423708,430457.105706944,440927.369043089,451397.632379233,461867.895715378,472338.159051522,482808.422387667,493278.685723812,503748.949059956,514219.212396101,524689.475732245,535159.73906839,545630.002404534,556100.265740679,566570.529076823,577040.792412968,587511.055749113,597981.319085257,608451.582421402],[94827.784539547,105298.047875692,115768.311211836,126238.574547981,136708.837884125,147179.10122027,157649.364556414,168119.627892559,178589.891228704,189060.154564848,199530.417900993,210000.681237137,220470.944573282,230941.207909426,241411.471245571,251881.734581715,262351.99791786,272822.261254005,283292.524590149,293762.787926294,304233.051262438,314703.314598583,325173.577934727,335643.841270872,346114.104607017,356584.367943161,367054.631279306,377524.89461545,387995.157951595,398465.421287739,408935.684623884,419405.947960029,429876.211296173,440346.474632318,450816.737968462,461287.001304607,471757.264640751,482227.527976896,492697.791313041,503168.054649185,513638.31798533,524108.581321474,534578.844657619,545049.107993763,555519.371329908,565989.634666053,576459.898002197,586930.161338342,597400.424674486,607870.688010631],[94246.890128776,104717.153464921,115187.416801065,125657.68013721,136127.943473354,146598.206809499,157068.470145643,167538.733481788,178008.996817933,188479.260154077,198949.523490222,209419.786826366,219890.050162511,230360.313498655,240830.5768348,251300.840170945,261771.103507089,272241.366843234,282711.630179378,293181.893515523,303652.156851667,314122.420187812,324592.683523957,335062.946860101,345533.210196246,356003.47353239,366473.736868535,376944.000204679,387414.263540824,397884.526876969,408354.790213113,418825.053549258,429295.316885402,439765.580221547,450235.843557691,460706.106893836,471176.370229981,481646.633566125,492116.89690227,502587.160238414,513057.423574559,523527.686910703,533997.950246848,544468.213582992,554938.476919137,565408.740255282,575879.003591426,586349.266927571,596819.530263715,607289.79359986],[93665.9957180051,104136.25905415,114606.522390294,125076.785726439,135547.049062583,146017.312398728,156487.575734873,166957.839071017,177428.102407162,187898.365743306,198368.629079451,208838.892415595,219309.15575174,229779.419087884,240249.682424029,250719.945760174,261190.209096318,271660.472432463,282130.735768607,292600.999104752,303071.262440896,313541.525777041,324011.789113186,334482.05244933,344952.315785475,355422.579121619,365892.842457764,376363.105793908,386833.369130053,397303.632466198,407773.895802342,418244.159138487,428714.422474631,439184.685810776,449654.94914692,460125.212483065,470595.47581921,481065.739155354,491536.002491499,502006.265827643,512476.529163788,522946.792499932,533417.055836077,543887.319172222,554357.582508366,564827.845844511,575298.109180655,585768.3725168,596238.635852945,606708.899189089],[93085.1013072341,103555.364643379,114025.627979523,124495.891315668,134966.154651812,145436.417987957,155906.681324102,166376.944660246,176847.207996391,187317.471332535,197787.73466868,208257.998004824,218728.261340969,229198.524677114,239668.788013258,250139.051349403,260609.314685547,271079.578021692,281549.841357836,292020.104693981,302490.368030126,312960.63136627,323430.894702415,333901.158038559,344371.421374704,354841.684710848,365311.948046993,375782.211383138,386252.474719282,396722.738055427,407193.001391571,417663.264727716,428133.52806386,438603.791400005,449074.054736149,459544.318072294,470014.581408439,480484.844744583,490955.108080728,501425.371416872,511895.634753017,522365.898089161,532836.161425306,543306.424761451,553776.688097595,564246.95143374,574717.214769884,585187.478106029,595657.741442174,606128.004778318],[92504.2068964632,102974.470232608,113444.733568752,123914.996904897,134385.260241041,144855.523577186,155325.786913331,165796.050249475,176266.31358562,186736.576921764,197206.840257909,207677.103594053,218147.366930198,228617.630266343,239087.893602487,249558.156938632,260028.420274776,270498.683610921,280968.946947065,291439.21028321,301909.473619355,312379.736955499,322850.000291644,333320.263627788,343790.526963933,354260.790300077,364731.053636222,375201.316972367,385671.580308511,396141.843644656,406612.1069808,417082.370316945,427552.633653089,438022.896989234,448493.160325379,458963.423661523,469433.686997668,479903.950333812,490374.213669957,500844.477006101,511314.740342246,521785.003678391,532255.267014535,542725.53035068,553195.793686824,563666.057022969,574136.320359113,584606.583695258,595076.847031403,605547.110367547],[91923.3124856922,102393.575821837,112863.839157981,123334.102494126,133804.365830271,144274.629166415,154744.89250256,165215.155838704,175685.419174849,186155.682510993,196625.945847138,207096.209183283,217566.472519427,228036.735855572,238506.999191716,248977.262527861,259447.525864005,269917.78920015,280388.052536295,290858.315872439,301328.579208584,311798.842544728,322269.105880873,332739.369217017,343209.632553162,353679.895889306,364150.159225451,374620.422561596,385090.68589774,395560.949233885,406031.212570029,416501.475906174,426971.739242318,437442.002578463,447912.265914608,458382.529250752,468852.792586897,479323.055923041,489793.319259186,500263.58259533,510733.845931475,521204.10926762,531674.372603764,542144.635939909,552614.899276053,563085.162612198,573555.425948342,584025.689284487,594495.952620632,604966.215956776],[91342.4180749213,101812.681411066,112282.94474721,122753.208083355,133223.4714195,143693.734755644,154163.998091789,164634.261427933,175104.524764078,185574.788100222,196045.051436367,206515.314772512,216985.578108656,227455.841444801,237926.104780945,248396.36811709,258866.631453234,269336.894789379,279807.158125524,290277.421461668,300747.684797813,311217.948133957,321688.211470102,332158.474806246,342628.738142391,353099.001478536,363569.26481468,374039.528150825,384509.791486969,394980.054823114,405450.318159258,415920.581495403,426390.844831548,436861.108167692,447331.371503837,457801.634839981,468271.898176126,478742.16151227,489212.424848415,499682.68818456,510152.951520704,520623.214856849,531093.478192993,541563.741529138,552034.004865282,562504.268201427,572974.531537571,583444.794873716,593915.058209861,604385.321546005],[90761.5236641503,101231.787000295,111702.050336439,122172.313672584,132642.577008729,143112.840344873,153583.103681018,164053.367017162,174523.630353307,184993.893689451,195464.157025596,205934.420361741,216404.683697885,226874.94703403,237345.210370174,247815.473706319,258285.737042463,268756.000378608,279226.263714753,289696.527050897,300166.790387042,310637.053723186,321107.317059331,331577.580395475,342047.84373162,352518.107067765,362988.370403909,373458.633740054,383928.897076198,394399.160412343,404869.423748487,415339.687084632,425809.950420777,436280.213756921,446750.477093066,457220.74042921,467691.003765355,478161.267101499,488631.530437644,499101.793773789,509572.057109933,520042.320446078,530512.583782222,540982.847118367,551453.110454511,561923.373790656,572393.637126801,582863.900462945,593334.16379909,603804.427135234],[90180.6292533794,100650.892589524,111121.155925669,121591.419261813,132061.682597958,142531.945934102,153002.209270247,163472.472606391,173942.735942536,184412.999278681,194883.262614825,205353.52595097,215823.789287114,226294.052623259,236764.315959403,247234.579295548,257704.842631693,268175.105967837,278645.369303982,289115.632640126,299585.895976271,310056.159312415,320526.42264856,330996.685984705,341466.949320849,351937.212656994,362407.475993138,372877.739329283,383348.002665427,393818.266001572,404288.529337717,414758.792673861,425229.056010006,435699.31934615,446169.582682295,456639.846018439,467110.109354584,477580.372690729,488050.636026873,498520.899363018,508991.162699162,519461.426035307,529931.689371451,540401.952707596,550872.216043741,561342.479379885,571812.74271603,582283.006052174,592753.269388319,603223.532724463],[89599.7348426084,100069.998178753,110540.261514898,121010.524851042,131480.788187187,141951.051523331,152421.314859476,162891.57819562,173361.841531765,183832.10486791,194302.368204054,204772.631540199,215242.894876343,225713.158212488,236183.421548632,246653.684884777,257123.948220922,267594.211557066,278064.474893211,288534.738229355,299005.0015655,309475.264901644,319945.528237789,330415.791573934,340886.054910078,351356.318246223,361826.581582367,372296.844918512,382767.108254656,393237.371590801,403707.634926946,414177.89826309,424648.161599235,435118.424935379,445588.688271524,456058.951607668,466529.214943813,476999.478279958,487469.741616102,497940.004952247,508410.268288391,518880.531624536,529350.79496068,539821.058296825,550291.32163297,560761.584969114,571231.848305259,581702.111641403,592172.374977548,602642.638313692],[89018.8404318375,99489.1037679821,109959.367104127,120429.630440271,130899.893776416,141370.15711256,151840.420448705,162310.683784849,172780.947120994,183251.210457139,193721.473793283,204191.737129428,214662.000465572,225132.263801717,235602.527137861,246072.790474006,256543.053810151,267013.317146295,277483.58048244,287953.843818584,298424.107154729,308894.370490873,319364.633827018,329834.897163163,340305.160499307,350775.423835452,361245.687171596,371715.950507741,382186.213843885,392656.47718003,403126.740516175,413597.003852319,424067.267188464,434537.530524608,445007.793860753,455478.057196897,465948.320533042,476418.583869187,486888.847205331,497359.110541476,507829.37387762,518299.637213765,528769.900549909,539240.163886054,549710.427222199,560180.690558343,570650.953894488,581121.217230632,591591.480566777,602061.743902921],[88437.9460210666,98908.2093572111,109378.472693356,119848.7360295,130318.999365645,140789.262701789,151259.526037934,161729.789374079,172200.052710223,182670.316046368,193140.579382512,203610.842718657,214081.106054801,224551.369390946,235021.632727091,245491.896063235,255962.15939938,266432.422735524,276902.686071669,287372.949407813,297843.212743958,308313.476080102,318783.739416247,329254.002752392,339724.266088536,350194.529424681,360664.792760825,371135.05609697,381605.319433115,392075.582769259,402545.846105404,413016.109441548,423486.372777693,433956.636113837,444426.899449982,454897.162786127,465367.426122271,475837.689458416,486307.95279456,496778.216130705,507248.479466849,517718.742802994,528189.006139138,538659.269475283,549129.532811428,559599.796147572,570070.059483717,580540.322819861,591010.586156006,601480.84949215],[87857.0516102956,98327.3149464402,108797.578282585,119267.841618729,129738.104954874,140208.368291018,150678.631627163,161148.894963308,171619.158299452,182089.421635597,192559.684971741,203029.948307886,213500.21164403,223970.474980175,234440.73831632,244911.001652464,255381.264988609,265851.528324753,276321.791660898,286792.054997042,297262.318333187,307732.581669331,318202.845005476,328673.108341621,339143.371677765,349613.63501391,360083.898350054,370554.161686199,381024.425022344,391494.688358488,401964.951694633,412435.215030777,422905.478366922,433375.741703066,443846.005039211,454316.268375356,464786.5317115,475256.795047645,485727.058383789,496197.321719934,506667.585056078,517137.848392223,527608.111728368,538078.375064512,548548.638400657,559018.901736801,569489.165072946,579959.42840909,590429.691745235,600899.95508138],[87276.1571995247,97746.4205356692,108216.683871814,118686.947207958,129157.210544103,139627.473880248,150097.737216392,160568.000552537,171038.263888681,181508.527224826,191978.79056097,202449.053897115,212919.317233259,223389.580569404,233859.843905549,244330.107241693,254800.370577838,265270.633913982,275740.897250127,286211.160586272,296681.423922416,307151.687258561,317621.950594705,328092.21393085,338562.477266994,349032.740603139,359503.003939283,369973.267275428,380443.530611573,390913.793947717,401384.057283862,411854.320620006,422324.583956151,432794.847292295,443265.11062844,453735.373964585,464205.637300729,474675.900636874,485146.163973018,495616.427309163,506086.690645307,516556.953981452,527027.217317597,537497.480653741,547967.743989886,558438.00732603,568908.270662175,579378.53399832,589848.797334464,600319.060670609],[86695.2627887537,97165.5261248983,107635.789461043,118106.052797187,128576.316133332,139046.579469477,149516.842805621,159987.106141766,170457.36947791,180927.632814055,191397.896150199,201868.159486344,212338.422822489,222808.686158633,233278.949494778,243749.212830922,254219.476167067,264689.739503211,275160.002839356,285630.266175501,296100.529511645,306570.79284779,317041.056183934,327511.319520079,337981.582856223,348451.846192368,358922.109528512,369392.372864657,379862.636200802,390332.899536946,400803.162873091,411273.426209235,421743.68954538,432213.952881524,442684.216217669,453154.479553814,463624.742889958,474095.006226103,484565.269562247,495035.532898392,505505.796234536,515976.059570681,526446.322906826,536916.58624297,547386.849579115,557857.112915259,568327.376251404,578797.639587549,589267.902923693,599738.166259838],[86114.3683779828,96584.6317141273,107054.895050272,117525.158386417,127995.421722561,138465.685058706,148935.94839485,159406.211730995,169876.475067139,180346.738403284,190817.001739428,201287.265075573,211757.528411718,222227.791747862,232698.055084007,243168.318420151,253638.581756296,264108.84509244,274579.108428585,285049.37176473,295519.635100874,305989.898437019,316460.161773163,326930.425109308,337400.688445452,347870.951781597,358341.215117741,368811.478453886,379281.741790031,389752.005126175,400222.26846232,410692.531798464,421162.795134609,431633.058470753,442103.321806898,452573.585143043,463043.848479187,473514.111815332,483984.375151476,494454.638487621,504924.901823765,515395.16515991,525865.428496055,536335.691832199,546805.955168344,557276.218504488,567746.481840633,578216.745176778,588687.008512922,599157.271849067],[85533.4739672118,96003.7373033564,106474.000639501,116944.263975646,127414.52731179,137884.790647935,148355.053984079,158825.317320224,169295.580656368,179765.843992513,190236.107328658,200706.370664802,211176.634000947,221646.897337091,232117.160673236,242587.42400938,253057.687345525,263527.95068167,273998.214017814,284468.477353959,294938.740690103,305409.004026248,315879.267362392,326349.530698537,336819.794034682,347290.057370826,357760.320706971,368230.584043115,378700.84737926,389171.110715404,399641.374051549,410111.637387693,420581.900723838,431052.164059983,441522.427396127,451992.690732272,462462.954068416,472933.217404561,483403.480740705,493873.74407685,504344.007412995,514814.270749139,525284.534085284,535754.797421428,546225.060757573,556695.324093717,567165.587429862,577635.850766007,588106.114102151,598576.377438296],[84952.5795564409,95422.8428925855,105893.10622873,116363.369564875,126833.632901019,137303.896237164,147774.159573308,158244.422909453,168714.686245597,179184.949581742,189655.212917887,200125.476254031,210595.739590176,221066.00292632,231536.266262465,242006.529598609,252476.792934754,262947.056270899,273417.319607043,283887.582943188,294357.846279332,304828.109615477,315298.372951621,325768.636287766,336238.899623911,346709.162960055,357179.4262962,367649.689632344,378119.952968489,388590.216304633,399060.479640778,409530.742976922,420001.006313067,430471.269649212,440941.532985356,451411.796321501,461882.059657645,472352.32299379,482822.586329934,493292.849666079,503763.113002224,514233.376338368,524703.639674513,535173.903010657,545644.166346802,556114.429682947,566584.693019091,577054.956355236,587525.21969138,597995.483027525],[84371.68514567,94841.9484818145,105312.211817959,115782.475154104,126252.738490248,136723.001826393,147193.265162537,157663.528498682,168133.791834827,178604.055170971,189074.318507116,199544.58184326,210014.845179405,220485.108515549,230955.371851694,241425.635187838,251895.898523983,262366.161860128,272836.425196272,283306.688532417,293776.951868561,304247.215204706,314717.47854085,325187.741876995,335658.00521314,346128.268549284,356598.531885429,367068.795221573,377539.058557718,388009.321893862,398479.585230007,408949.848566152,419420.111902296,429890.375238441,440360.638574585,450830.90191073,461301.165246874,471771.428583019,482241.691919164,492711.955255308,503182.218591453,513652.481927597,524122.745263742,534593.008599886,545063.271936031,555533.535272176,566003.79860832,576474.061944465,586944.325280609,597414.588616754],[83790.790734899,94261.0540710436,104731.317407188,115201.580743333,125671.844079477,136142.107415622,146612.370751766,157082.634087911,167552.897424056,178023.1607602,188493.424096345,198963.687432489,209433.950768634,219904.214104778,230374.477440923,240844.740777067,251315.004113212,261785.267449357,272255.530785501,282725.794121646,293196.05745779,303666.320793935,314136.584130079,324606.847466224,335077.110802369,345547.374138513,356017.637474658,366487.900810802,376958.164146947,387428.427483091,397898.690819236,408368.954155381,418839.217491525,429309.48082767,439779.744163814,450250.007499959,460720.270836103,471190.534172248,481660.797508393,492131.060844537,502601.324180682,513071.587516826,523541.850852971,534012.114189115,544482.37752526,554952.640861405,565422.904197549,575893.167533694,586363.430869838,596833.694205983],[83209.8963241281,93680.1596602726,104150.422996417,114620.686332562,125090.949668706,135561.213004851,146031.476340995,156501.73967714,166972.003013285,177442.266349429,187912.529685574,198382.793021718,208853.056357863,219323.319694007,229793.583030152,240263.846366297,250734.109702441,261204.373038586,271674.63637473,282144.899710875,292615.163047019,303085.426383164,313555.689719309,324025.953055453,334496.216391598,344966.479727742,355436.743063887,365907.006400031,376377.269736176,386847.533072321,397317.796408465,407788.05974461,418258.323080754,428728.586416899,439198.849753043,449669.113089188,460139.376425333,470609.639761477,481079.903097622,491550.166433766,502020.429769911,512490.693106055,522960.9564422,533431.219778345,543901.483114489,554371.746450634,564842.009786778,575312.273122923,585782.536459067,596252.799795212],[82629.0019133571,93099.2652495017,103569.528585646,114039.791921791,124510.055257935,134980.31859408,145450.581930225,155920.845266369,166391.108602514,176861.371938658,187331.635274803,197801.898610947,208272.161947092,218742.425283237,229212.688619381,239682.951955526,250153.21529167,260623.478627815,271093.741963959,281564.005300104,292034.268636248,302504.531972393,312974.795308538,323445.058644682,333915.321980827,344385.585316971,354855.848653116,365326.11198926,375796.375325405,386266.63866155,396736.901997694,407207.165333839,417677.428669983,428147.692006128,438617.955342272,449088.218678417,459558.482014562,470028.745350706,480499.008686851,490969.272022995,501439.53535914,511909.798695284,522380.062031429,532850.325367574,543320.588703718,553790.852039863,564261.115376007,574731.378712152,585201.642048297,595671.905384441],[82048.1075025862,92518.3708387307,102988.634174875,113458.89751102,123929.160847164,134399.424183309,144869.687519454,155339.950855598,165810.214191743,176280.477527887,186750.740864032,197221.004200176,207691.267536321,218161.530872466,228631.79420861,239102.057544755,249572.320880899,260042.584217044,270512.847553188,280983.110889333,291453.374225478,301923.637561622,312393.900897767,322864.164233911,333334.427570056,343804.6909062,354274.954242345,364745.21757849,375215.480914634,385685.744250779,396156.007586923,406626.270923068,417096.534259212,427566.797595357,438037.060931502,448507.324267646,458977.587603791,469447.850939935,479918.11427608,490388.377612224,500858.640948369,511328.904284513,521799.167620658,532269.430956803,542739.694292947,553209.957629092,563680.220965236,574150.484301381,584620.747637526,595091.01097367],[81467.2130918152,91937.4764279598,102407.739764104,112878.003100249,123348.266436394,133818.529772538,144288.793108683,154759.056444827,165229.319780972,175699.583117116,186169.846453261,196640.109789405,207110.37312555,217580.636461695,228050.899797839,238521.163133984,248991.426470128,259461.689806273,269931.953142417,280402.216478562,290872.479814707,301342.743150851,311813.006486996,322283.26982314,332753.533159285,343223.796495429,353694.059831574,364164.323167719,374634.586503863,385104.849840008,395575.113176152,406045.376512297,416515.639848441,426985.903184586,437456.166520731,447926.429856875,458396.69319302,468866.956529164,479337.219865309,489807.483201453,500277.746537598,510748.009873743,521218.273209887,531688.536546032,542158.799882176,552629.063218321,563099.326554465,573569.58989061,584039.853226755,594510.116562899],[80886.3186810443,91356.5820171888,101826.845353333,112297.108689478,122767.372025623,133237.635361767,143707.898697912,154178.162034056,164648.425370201,175118.688706345,185588.95204249,196059.215378635,206529.478714779,216999.742050924,227470.005387068,237940.268723213,248410.532059357,258880.795395502,269351.058731647,279821.322067791,290291.585403936,300761.84874008,311232.112076225,321702.375412369,332172.638748514,342642.902084659,353113.165420803,363583.428756948,374053.692093092,384523.955429237,394994.218765381,405464.482101526,415934.74543767,426405.008773815,436875.27210996,447345.535446104,457815.798782249,468286.062118393,478756.325454538,489226.588790682,499696.852126827,510167.115462972,520637.378799116,531107.642135261,541577.905471405,552048.16880755,562518.432143694,572988.695479839,583458.958815984,593929.222152128],[80305.4242702733,90775.6876064179,101245.950942562,111716.214278707,122186.477614852,132656.740950996,143127.004287141,153597.267623285,164067.53095943,174537.794295574,185008.057631719,195478.320967864,205948.584304008,216418.847640153,226889.110976297,237359.374312442,247829.637648586,258299.900984731,268770.164320876,279240.42765702,289710.690993165,300180.954329309,310651.217665454,321121.481001598,331591.744337743,342062.007673888,352532.271010032,363002.534346177,373472.797682321,383943.061018466,394413.32435461,404883.587690755,415353.8510269,425824.114363044,436294.377699189,446764.641035333,457234.904371478,467705.167707622,478175.431043767,488645.694379912,499115.957716056,509586.221052201,520056.484388345,530526.74772449,540997.011060634,551467.274396779,561937.537732924,572407.801069068,582878.064405213,593348.327741357],[79724.5298595024,90194.793195647,100665.056531792,111135.319867936,121605.583204081,132075.846540225,142546.10987637,153016.373212514,163486.636548659,173956.899884804,184427.163220948,194897.426557093,205367.689893237,215837.953229382,226308.216565526,236778.479901671,247248.743237816,257719.00657396,268189.269910105,278659.533246249,289129.796582394,299600.059918538,310070.323254683,320540.586590828,331010.849926972,341481.113263117,351951.376599261,362421.639935406,372891.90327155,383362.166607695,393832.429943839,404302.693279984,414772.956616129,425243.219952273,435713.483288418,446183.746624562,456654.009960707,467124.273296851,477594.536632996,488064.799969141,498535.063305285,509005.32664143,519475.589977574,529945.853313719,540416.116649864,550886.379986008,561356.643322153,571826.906658297,582297.169994442,592767.433330586],[79143.6354487315,89613.898784876,100084.162121021,110554.425457165,121024.68879331,131494.952129454,141965.215465599,152435.478801743,162905.742137888,173376.005474033,183846.268810177,194316.532146322,204786.795482466,215257.058818611,225727.322154755,236197.5854909,246667.848827045,257138.112163189,267608.375499334,278078.638835478,288548.902171623,299019.165507767,309489.428843912,319959.692180057,330429.955516201,340900.218852346,351370.48218849,361840.745524635,372311.008860779,382781.272196924,393251.535533069,403721.798869213,414192.062205358,424662.325541502,435132.588877647,445602.852213791,456073.115549936,466543.378886081,477013.642222225,487483.90555837,497954.168894514,508424.432230659,518894.695566803,529364.958902948,539835.222239093,550305.485575237,560775.748911382,571246.012247526,581716.275583671,592186.538919815],[78562.7410379605,89033.0043741051,99503.2677102496,109973.531046394,120443.794382539,130914.057718683,141384.321054828,151854.584390972,162324.847727117,172795.111063262,183265.374399406,193735.637735551,204205.901071695,214676.16440784,225146.427743985,235616.691080129,246086.954416274,256557.217752418,267027.481088563,277497.744424707,287968.007760852,298438.271096996,308908.534433141,319378.797769286,329849.06110543,340319.324441575,350789.587777719,361259.851113864,371730.114450008,382200.377786153,392670.641122298,403140.904458442,413611.167794587,424081.431130731,434551.694466876,445021.95780302,455492.221139165,465962.48447531,476432.747811454,486903.011147599,497373.274483743,507843.537819888,518313.801156032,528784.064492177,539254.327828322,549724.591164466,560194.854500611,570665.117836755,581135.3811729,591605.644509044],[77981.8466271896,88452.1099633341,98922.3732994787,109392.636635623,119862.899971768,130333.163307912,140803.426644057,151273.689980202,161743.953316346,172214.216652491,182684.479988635,193154.74332478,203625.006660924,214095.269997069,224565.533333214,235035.796669358,245506.060005503,255976.323341647,266446.586677792,276916.850013936,287387.113350081,297857.376686225,308327.64002237,318797.903358515,329268.166694659,339738.430030804,350208.693366948,360678.956703093,371149.220039238,381619.483375382,392089.746711527,402560.010047671,413030.273383816,423500.53671996,433970.800056105,444441.06339225,454911.326728394,465381.590064539,475851.853400683,486322.116736828,496792.380072972,507262.643409117,517732.906745261,528203.170081406,538673.433417551,549143.696753695,559613.96008984,570084.223425984,580554.486762129,591024.750098274],[77400.9522164186,87871.2155525632,98341.4788887077,108811.742224852,119282.005560997,129752.268897141,140222.532233286,150692.795569431,161163.058905575,171633.32224172,182103.585577864,192573.848914009,203044.112250153,213514.375586298,223984.638922443,234454.902258587,244925.165594732,255395.428930876,265865.692267021,276335.955603165,286806.21893931,297276.482275455,307746.745611599,318217.008947744,328687.272283888,339157.535620033,349627.798956177,360098.062292322,370568.325628467,381038.588964611,391508.852300756,401979.1156369,412449.378973045,422919.642309189,433389.905645334,443860.168981479,454330.432317623,464800.695653768,475270.958989912,485741.222326057,496211.485662201,506681.748998346,517152.01233449,527622.275670635,538092.53900678,548562.802342924,559033.065679069,569503.329015213,579973.592351358,590443.855687503],[76820.0578056477,87290.3211417922,97760.5844779368,108230.847814081,118701.111150226,129171.374486371,139641.637822515,150111.90115866,160582.164494804,171052.427830949,181522.691167093,191992.954503238,202463.217839383,212933.481175527,223403.744511672,233874.007847816,244344.271183961,254814.534520105,265284.79785625,275755.061192395,286225.324528539,296695.587864684,307165.851200828,317636.114536973,328106.377873117,338576.641209262,349046.904545406,359517.167881551,369987.431217696,380457.69455384,390927.957889985,401398.221226129,411868.484562274,422338.747898418,432809.011234563,443279.274570708,453749.537906852,464219.801242997,474690.064579141,485160.327915286,495630.59125143,506100.854587575,516571.11792372,527041.381259864,537511.644596009,547981.907932153,558452.171268298,568922.434604443,579392.697940587,589862.961276732],[76239.1633948767,86709.4267310213,97179.6900671658,107649.95340331,118120.216739455,128590.4800756,139060.743411744,149531.006747889,160001.270084033,170471.533420178,180941.796756322,191412.060092467,201882.323428612,212352.586764756,222822.850100901,233293.113437045,243763.37677319,254233.640109334,264703.903445479,275174.166781624,285644.430117768,296114.693453913,306584.956790057,317055.220126202,327525.483462346,337995.746798491,348466.010134635,358936.27347078,369406.536806925,379876.800143069,390347.063479214,400817.326815358,411287.590151503,421757.853487647,432228.116823792,442698.380159937,453168.643496081,463638.906832226,474109.17016837,484579.433504515,495049.696840659,505519.960176804,515990.223512949,526460.486849093,536930.750185238,547401.013521382,557871.276857527,568341.540193672,578811.803529816,589282.066865961],[75658.2689841058,86128.5323202503,96598.7956563949,107069.058992539,117539.322328684,128009.585664829,138479.849000973,148950.112337118,159420.375673262,169890.639009407,180360.902345551,190831.165681696,201301.429017841,211771.692353985,222241.95569013,232712.219026274,243182.482362419,253652.745698563,264123.009034708,274593.272370853,285063.535706997,295533.799043142,306004.062379286,316474.325715431,326944.589051576,337414.85238772,347885.115723865,358355.379060009,368825.642396154,379295.905732298,389766.169068443,400236.432404587,410706.695740732,421176.959076877,431647.222413021,442117.485749166,452587.74908531,463058.012421455,473528.275757599,483998.539093744,494468.802429889,504939.065766033,515409.329102178,525879.592438322,536349.855774467,546820.119110611,557290.382446756,567760.645782901,578230.909119045,588701.17245519],[75077.3745733348,85547.6379094794,96017.901245624,106488.164581769,116958.427917913,127428.691254058,137898.954590202,148369.217926347,158839.481262491,169309.744598636,179780.007934781,190250.271270925,200720.53460707,211190.797943214,221661.061279359,232131.324615503,242601.587951648,253071.851287792,263542.114623937,274012.377960082,284482.641296226,294952.904632371,305423.167968515,315893.43130466,326363.694640805,336833.957976949,347304.221313094,357774.484649238,368244.747985383,378715.011321527,389185.274657672,399655.537993816,410125.801329961,420596.064666106,431066.32800225,441536.591338395,452006.854674539,462477.118010684,472947.381346828,483417.644682973,493887.908019118,504358.171355262,514828.434691407,525298.698027551,535768.961363696,546239.22469984,556709.488035985,567179.75137213,577650.014708274,588120.278044419],[74496.4801625639,84966.7434987084,95437.006834853,105907.270170998,116377.533507142,126847.796843287,137318.060179431,147788.323515576,158258.58685172,168728.850187865,179199.11352401,189669.376860154,200139.640196299,210609.903532443,221080.166868588,231550.430204732,242020.693540877,252490.956877022,262961.220213166,273431.483549311,283901.746885455,294372.0102216,304842.273557744,315312.536893889,325782.800230034,336253.063566178,346723.326902323,357193.590238467,367663.853574612,378134.116910756,388604.380246901,399074.643583046,409544.90691919,420015.170255335,430485.433591479,440955.696927624,451425.960263768,461896.223599913,472366.486936058,482836.750272202,493307.013608347,503777.276944491,514247.540280636,524717.80361678,535188.066952925,545658.330289069,556128.593625214,566598.856961359,577069.120297503,587539.383633648],[73915.5857517929,84385.8490879375,94856.1124240821,105326.375760227,115796.639096371,126266.902432516,136737.16576866,147207.429104805,157677.692440949,168147.955777094,178618.219113239,189088.482449383,199558.745785528,210029.009121672,220499.272457817,230969.535793961,241439.799130106,251910.062466251,262380.325802395,272850.58913854,283320.852474684,293791.115810829,304261.379146973,314731.642483118,325201.905819263,335672.169155407,346142.432491552,356612.695827696,367082.959163841,377553.222499985,388023.48583613,398493.749172275,408964.012508419,419434.275844564,429904.539180708,440374.802516853,450845.065852997,461315.329189142,471785.592525287,482255.855861431,492726.119197576,503196.38253372,513666.645869865,524136.909206009,534607.172542154,545077.435878298,555547.699214443,566017.962550588,576488.225886732,586958.489222877],[73334.691341022,83804.9546771666,94275.2180133111,104745.481349456,115215.7446856,125686.008021745,136156.271357889,146626.534694034,157096.798030179,167567.061366323,178037.324702468,188507.588038612,198977.851374757,209448.114710901,219918.378047046,230388.64138319,240858.904719335,251329.16805548,261799.431391624,272269.694727769,282739.958063913,293210.221400058,303680.484736202,314150.748072347,324621.011408492,335091.274744636,345561.538080781,356031.801416925,366502.06475307,376972.328089214,387442.591425359,397912.854761504,408383.118097648,418853.381433793,429323.644769937,439793.908106082,450264.171442226,460734.434778371,471204.698114516,481674.96145066,492145.224786805,502615.488122949,513085.751459094,523556.014795238,534026.278131383,544496.541467528,554966.804803672,565437.068139817,575907.331475961,586377.594812106],[72753.796930251,83224.0602663956,93694.3236025402,104164.586938685,114634.850274829,125105.113610974,135575.376947118,146045.640283263,156515.903619408,166986.166955552,177456.430291697,187926.693627841,198396.956963986,208867.22030013,219337.483636275,229807.74697242,240278.010308564,250748.273644709,261218.536980853,271688.800316998,282159.063653142,292629.326989287,303099.590325432,313569.853661576,324040.116997721,334510.380333865,344980.64367001,355450.907006154,365921.170342299,376391.433678444,386861.697014588,397331.960350733,407802.223686877,418272.487023022,428742.750359166,439213.013695311,449683.277031456,460153.5403676,470623.803703745,481094.067039889,491564.330376034,502034.593712178,512504.857048323,522975.120384468,533445.383720612,543915.647056757,554385.910392901,564856.173729046,575326.437065191,585796.700401335],[72172.9025194801,82643.1658556247,93113.4291917692,103583.692527914,114053.955864058,124524.219200203,134994.482536348,145464.745872492,155935.009208637,166405.272544781,176875.535880926,187345.79921707,197816.062553215,208286.32588936,218756.589225504,229226.852561649,239697.115897793,250167.379233938,260637.642570082,271107.905906227,281578.169242371,292048.432578516,302518.695914661,312988.959250805,323459.22258695,333929.485923094,344399.749259239,354870.012595383,365340.275931528,375810.539267673,386280.802603817,396751.065939962,407221.329276106,417691.592612251,428161.855948395,438632.11928454,449102.382620685,459572.645956829,470042.909292974,480513.172629118,490983.435965263,501453.699301407,511923.962637552,522394.225973697,532864.489309841,543334.752645986,553805.01598213,564275.279318275,574745.54265442,585215.805990564]],"type":"surface","x":[588,662.65306122449,737.30612244898,811.959183673469,886.612244897959,961.265306122449,1035.91836734694,1110.57142857143,1185.22448979592,1259.87755102041,1334.5306122449,1409.18367346939,1483.83673469388,1558.48979591837,1633.14285714286,1707.79591836735,1782.44897959184,1857.10204081633,1931.75510204082,2006.40816326531,2081.0612244898,2155.71428571429,2230.36734693878,2305.02040816327,2379.67346938776,2454.32653061224,2528.97959183673,2603.63265306122,2678.28571428571,2752.9387755102,2827.59183673469,2902.24489795918,2976.89795918367,3051.55102040816,3126.20408163265,3200.85714285714,3275.51020408163,3350.16326530612,3424.81632653061,3499.4693877551,3574.12244897959,3648.77551020408,3723.42857142857,3798.08163265306,3872.73469387755,3947.38775510204,4022.04081632653,4096.69387755102,4171.34693877551,4246],"y":[1,1.08163265306122,1.16326530612245,1.24489795918367,1.3265306122449,1.40816326530612,1.48979591836735,1.57142857142857,1.6530612244898,1.73469387755102,1.81632653061224,1.89795918367347,1.97959183673469,2.06122448979592,2.14285714285714,2.22448979591837,2.30612244897959,2.38775510204082,2.46938775510204,2.55102040816327,2.63265306122449,2.71428571428571,2.79591836734694,2.87755102040816,2.95918367346939,3.04081632653061,3.12244897959184,3.20408163265306,3.28571428571429,3.36734693877551,3.44897959183673,3.53061224489796,3.61224489795918,3.69387755102041,3.77551020408163,3.85714285714286,3.93877551020408,4.02040816326531,4.10204081632653,4.18367346938775,4.26530612244898,4.3469387755102,4.42857142857143,4.51020408163265,4.59183673469388,4.6734693877551,4.75510204081633,4.83673469387755,4.91836734693878,5],"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script> We see that the predictions from linear regression with two predictors form a plane as well, but this plane differs from the one we get from k-nn regression in its flexibility. The plane from k-nn regression above was more flexible and more closely followed the shape of the training data. The plane from linear regression however is constrained to being linear (i.e., a flat plane). As discussed this can be advantageous in one aspect, which is that for each predictor, we can get a slope from linear regression, and thus describe the plane mathematically. We can extract those slope values from our model object as shown below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_mult_reg_final<span class="op">$</span>finalModel<span class="op">$</span>coefficients</code></pre></div>
<pre><code>## (Intercept)        sqft       baths 
##  25284.3344    140.2523  -7115.9565</code></pre>
<p>And then use those slopes, to write a mathematical equation to describe the prediction plane:</p>
<p>Remembering that the equation for a plane is:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_1X_1 + \beta_2X_2\]</span> Where:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> is the y-intercept of the hyperplane (the value where it cuts the y-axis)</li>
<li><span class="math inline">\(\beta_1\)</span> is the slope for the first predictor</li>
<li><span class="math inline">\(X_1\)</span> is the first predictor</li>
<li><span class="math inline">\(\beta_2\)</span> is the slope for the second predictor</li>
<li><span class="math inline">\(X_2\)</span> is the second predictor</li>
</ul>
<p>We can then write:</p>
<p><span class="math display">\[house\: price = \beta_0 + \beta_1  \:house\: size + \beta_2  \:number\: of \: bathrooms\]</span></p>
<p>And finally, fill in the values for <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> from the model output above:</p>
<p><span class="math display">\[house\: price = 25284.33 + 140*house\: size + -7116 *  \:number\: of \: bathrooms\]</span></p>
<p>OK great, so this model is more interpretable than the multivariate k-nn regression model (i.e., we can write a mathematical equation that explains how each predictor is affecting the predictions), but as always, we should look at the test error and ask whether linear regression is doing a better job of predicting compared to k-nn regression in this multivariate regression case? To do that we can use this linear regression model to predict on the test data to get our test error.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_pred_lm &lt;-<span class="st"> </span><span class="kw">predict</span>(lm_mult_reg_final, lm_X_test)
lm_modelvalues &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">obs =</span> lm_Y_test, <span class="dt">pred =</span> test_pred_lm)
lm_mult_test_results &lt;-<span class="st"> </span><span class="kw">defaultSummary</span>(lm_modelvalues)
lm_mult_test_results[[<span class="dv">1</span>]]</code></pre></div>
<pre><code>## [1] 86778.87</code></pre>
<p>We get that the <span class="math inline">\(RMSPE\)</span> for the multivariate linear regression model of 86778.87. This prediction error is less than the prediction error for the multivariate k-nn regression model, indicating that we should likely choose linear regression for predictions of house price on this data set. But wait, we should also ask if this more complex model is doing a better job of predicting compared to our simple linear regression model with only a single predictor (house size). Revisiting last section, we see that our <span class="math inline">\(RMSPE\)</span> for our simple linear regression model with only a single predictor was 86688.47 which is less than that for our more complex model, meaning that it performed better at predicting on the test data set.</p>
<p>Should we always end up choosing a simple linear regression as our model? No! And you never know what model will be the best until you go through this process. Exploratory data analysis can give you some hints, but until you look at the prediction errors to compare the models you don’t really know. Additionally, here we compare test errors purely for the purposes of teaching. In practice, if you wanted to choose compare several regression models with differing numbers of variables to see which performed the best you would use cross-validation to choose this (similar to how we use cross validation to choose k in k-nn regression). There are several well known and more advanced methods to do this that are beyond the scope of this course, and they include backward or forward selection, and L1 or L2 regularization (also known as Lasso and Ridge regression, respectively).</p>
</div>
<div id="the-other-side-of-regression" class="section level2">
<h2><span class="header-section-number">9.7</span> The other side of regression</h2>
<p>So far in this textbook we have used regression only in the context of prediction, however, regression is also a powerful method to understand and/or describe the relationship between a quantitative outcome/response variable and one or more explanatory variables. Extending the case we have been working with in this chapter (where we are interested in house price as the outcome/response variable), we could also, or instead, be interested in describing the individual effects of house size and the number of bathrooms on house price, quantifying how big each of these effects are, and assessing how accurately we can estimate each of these effects. This side of regression is the topic of many follow-on statistics courses and beyond the scope of this course.</p>
</div>
<div id="additional-readingsresources-2" class="section level2">
<h2><span class="header-section-number">9.8</span> Additional readings/resources</h2>
<ul>
<li>Pages 59-71 of <a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">Introduction to Statistical Learning</a> with Applications in R by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani</li>
<li>Pages 104 - 109 of <a href="https://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">An Introduction to Statistical Learning with Applications in R</a> by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani</li>
<li><a href="https://topepo.github.io/caret/index.html">The <code>caret</code> Package</a></li>
<li>Chapters 6 - 11 of <a href="https://moderndive.com/">Modern Dive</a> Statistical Inference via Data Science by Chester Ismay and Albert Y. Kim</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-regression2.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
