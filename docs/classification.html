<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Classification I: Training &amp; predicting | Introduction to Data Science</title>
  <meta name="description" content="This is an open source textbook for teaching introductory data science." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Classification I: Training &amp; predicting | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source textbook for teaching introductory data science." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Classification I: Training &amp; predicting | Introduction to Data Science" />
  
  <meta name="twitter:description" content="This is an open source textbook for teaching introductory data science." />
  

<meta name="author" content="Tiffany-Anne Timbers" />
<meta name="author" content="Trevor Campbell" />
<meta name="author" content="Melissa Lee" />


<meta name="date" content="2020-07-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="GitHub.html"/>
<link rel="next" href="classification-continued.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data Science</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#jupyter-notebooks"><i class="fa fa-check"></i><b>1.2</b> Jupyter notebooks</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#loading-a-spreadsheet-like-dataset"><i class="fa fa-check"></i><b>1.3</b> Loading a spreadsheet-like dataset</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#assigning-value-to-a-data-frame"><i class="fa fa-check"></i><b>1.4</b> Assigning value to a data frame</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#creating-subsets-of-data-frames-with-select-filter"><i class="fa fa-check"></i><b>1.5</b> Creating subsets of data frames with <code>select</code> &amp; <code>filter</code></a><ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#using-select-to-extract-multiple-columns"><i class="fa fa-check"></i><b>1.5.1</b> Using <code>select</code> to extract multiple columns</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#using-select-to-extract-a-range-of-columns"><i class="fa fa-check"></i><b>1.5.2</b> Using <code>select</code> to extract a range of columns</a></li>
<li class="chapter" data-level="1.5.3" data-path="index.html"><a href="index.html#using-filter-to-extract-a-single-row"><i class="fa fa-check"></i><b>1.5.3</b> Using <code>filter</code> to extract a single row</a></li>
<li class="chapter" data-level="1.5.4" data-path="index.html"><a href="index.html#using-filter-to-extract-rows-with-values-above-a-threshold"><i class="fa fa-check"></i><b>1.5.4</b> Using <code>filter</code> to extract rows with values above a threshold</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#exploring-data-with-visualizations"><i class="fa fa-check"></i><b>1.6</b> Exploring data with visualizations</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot"><i class="fa fa-check"></i><b>1.6.1</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot-1"><i class="fa fa-check"></i><b>1.6.2</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.3" data-path="index.html"><a href="index.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.6.3</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.6.4" data-path="index.html"><a href="index.html#coloring-points-by-group"><i class="fa fa-check"></i><b>1.6.4</b> Coloring points by group</a></li>
<li class="chapter" data-level="1.6.5" data-path="index.html"><a href="index.html#putting-it-all-together"><i class="fa fa-check"></i><b>1.6.5</b> Putting it all together</a></li>
<li class="chapter" data-level="1.6.6" data-path="index.html"><a href="index.html#whats-next"><i class="fa fa-check"></i><b>1.6.6</b> What’s next?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a><ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-plain-text-file-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data from a plain text file into R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#skipping-rows-when-reading-in-data"><i class="fa fa-check"></i><b>2.4.1</b> Skipping rows when reading in data</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.2</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.3</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.4" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.4</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#reading-data-from-an-microsoft-excel-file"><i class="fa fa-check"></i><b>2.5</b> Reading data from an Microsoft Excel file</a></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#reading-data-from-a-database"><i class="fa fa-check"></i><b>2.6</b> Reading data from a database</a><ul>
<li class="chapter" data-level="2.6.1" data-path="reading.html"><a href="reading.html#reading-data-from-a-sqlite-database"><i class="fa fa-check"></i><b>2.6.1</b> Reading data from a SQLite database</a></li>
<li class="chapter" data-level="2.6.2" data-path="reading.html"><a href="reading.html#reading-data-from-a-postgresql-database"><i class="fa fa-check"></i><b>2.6.2</b> Reading data from a PostgreSQL database</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="reading.html"><a href="reading.html#writing-data-from-r-to-a-.csv-file"><i class="fa fa-check"></i><b>2.7</b> Writing data from R to a <code>.csv</code> file</a></li>
<li class="chapter" data-level="2.8" data-path="reading.html"><a href="reading.html#scraping-data-off-the-web-using-r"><i class="fa fa-check"></i><b>2.8</b> Scraping data off the web using R</a><ul>
<li class="chapter" data-level="2.8.1" data-path="reading.html"><a href="reading.html#html-and-css-selectors"><i class="fa fa-check"></i><b>2.8.1</b> HTML and CSS selectors</a></li>
<li class="chapter" data-level="2.8.2" data-path="reading.html"><a href="reading.html#are-you-allowed-to-scrape-that-website"><i class="fa fa-check"></i><b>2.8.2</b> Are you allowed to scrape that website?</a></li>
<li class="chapter" data-level="2.8.3" data-path="reading.html"><a href="reading.html#using-rvest"><i class="fa fa-check"></i><b>2.8.3</b> Using <code>rvest</code></a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="reading.html"><a href="reading.html#additional-readingsresources"><i class="fa fa-check"></i><b>2.9</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a><ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#vectors-and-data-frames"><i class="fa fa-check"></i><b>3.3</b> Vectors and Data frames</a><ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#how-are-vectors-different-from-a-list"><i class="fa fa-check"></i><b>3.3.3</b> How are vectors different from a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.4</b> Tidy Data</a><ul>
<li class="chapter" data-level="3.4.1" data-path="wrangling.html"><a href="wrangling.html#what-is-tidy-data"><i class="fa fa-check"></i><b>3.4.1</b> What is tidy data?</a></li>
<li class="chapter" data-level="3.4.2" data-path="wrangling.html"><a href="wrangling.html#why-is-tidy-data-important-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Why is tidy data important in R?</a></li>
<li class="chapter" data-level="3.4.3" data-path="wrangling.html"><a href="wrangling.html#going-from-wide-to-long-or-tidy-using-gather"><i class="fa fa-check"></i><b>3.4.3</b> Going from wide to long (or tidy!) using <code>gather</code></a></li>
<li class="chapter" data-level="3.4.4" data-path="wrangling.html"><a href="wrangling.html#using-separate-to-deal-with-multiple-delimiters"><i class="fa fa-check"></i><b>3.4.4</b> Using separate to deal with multiple delimiters</a></li>
<li class="chapter" data-level="3.4.5" data-path="wrangling.html"><a href="wrangling.html#notes-on-defining-tidy-data"><i class="fa fa-check"></i><b>3.4.5</b> Notes on defining tidy data</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#combining-functions-using-the-pipe-operator"><i class="fa fa-check"></i><b>3.5</b> Combining functions using the pipe operator, <code>%&gt;%</code>:</a><ul>
<li class="chapter" data-level="3.5.1" data-path="wrangling.html"><a href="wrangling.html#using-to-combine-filter-and-select"><i class="fa fa-check"></i><b>3.5.1</b> Using <code>%&gt;%</code> to combine <code>filter</code> and <code>select</code></a></li>
<li class="chapter" data-level="3.5.2" data-path="wrangling.html"><a href="wrangling.html#using-with-more-than-two-functions"><i class="fa fa-check"></i><b>3.5.2</b> Using <code>%&gt;%</code> with more than two functions</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#iterating-over-data-with-group_by-summarize"><i class="fa fa-check"></i><b>3.6</b> Iterating over data with <code>group_by</code> + <code>summarize</code></a><ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics"><i class="fa fa-check"></i><b>3.6.1</b> Calculating summary statistics:</a></li>
<li class="chapter" data-level="3.6.2" data-path="wrangling.html"><a href="wrangling.html#calculating-group-summary-statistics"><i class="fa fa-check"></i><b>3.6.2</b> Calculating group summary statistics:</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#additional-reading-on-the-dplyr-functions"><i class="fa fa-check"></i><b>3.7</b> Additional reading on the <code>dplyr</code> functions</a></li>
<li class="chapter" data-level="3.8" data-path="wrangling.html"><a href="wrangling.html#using-purrrs-map-functions-to-iterate"><i class="fa fa-check"></i><b>3.8</b> Using <code>purrr</code>’s <code>map*</code> functions to iterate</a><ul>
<li class="chapter" data-level="3.8.1" data-path="wrangling.html"><a href="wrangling.html#a-bit-more-about-the-map_-functions"><i class="fa fa-check"></i><b>3.8.1</b> A bit more about the <code>map_*</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="wrangling.html"><a href="wrangling.html#additional-readingsresources-1"><i class="fa fa-check"></i><b>3.9</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a><ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-2"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#choosing-the-visualization"><i class="fa fa-check"></i><b>4.3</b> Choosing the visualization</a></li>
<li class="chapter" data-level="4.4" data-path="viz.html"><a href="viz.html#refining-the-visualization"><i class="fa fa-check"></i><b>4.4</b> Refining the visualization</a></li>
<li class="chapter" data-level="4.5" data-path="viz.html"><a href="viz.html#creating-visualizations-with-ggplot2"><i class="fa fa-check"></i><b>4.5</b> Creating visualizations with <code>ggplot2</code></a><ul>
<li class="chapter" data-level="4.5.1" data-path="viz.html"><a href="viz.html#the-mauna-loa-co2-data-set"><i class="fa fa-check"></i><b>4.5.1</b> The Mauna Loa CO2 data set</a></li>
<li class="chapter" data-level="4.5.2" data-path="viz.html"><a href="viz.html#the-island-landmass-data-set"><i class="fa fa-check"></i><b>4.5.2</b> The island landmass data set</a></li>
<li class="chapter" data-level="4.5.3" data-path="viz.html"><a href="viz.html#the-old-faithful-eruption-waiting-time-data-set"><i class="fa fa-check"></i><b>4.5.3</b> The Old Faithful eruption / waiting time data set</a></li>
<li class="chapter" data-level="4.5.4" data-path="viz.html"><a href="viz.html#the-michelson-speed-of-light-data-set"><i class="fa fa-check"></i><b>4.5.4</b> The Michelson speed of light data set</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="viz.html"><a href="viz.html#explaining-the-visualization"><i class="fa fa-check"></i><b>4.6</b> Explaining the visualization</a></li>
<li class="chapter" data-level="4.7" data-path="viz.html"><a href="viz.html#saving-the-visualization"><i class="fa fa-check"></i><b>4.7</b> Saving the visualization</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="GitHub.html"><a href="GitHub.html"><i class="fa fa-check"></i><b>5</b> Version control with GitHub</a><ul>
<li class="chapter" data-level="5.1" data-path="GitHub.html"><a href="GitHub.html#overview-3"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="GitHub.html"><a href="GitHub.html#videos-to-learn-about-version-control-with-github-and-git"><i class="fa fa-check"></i><b>5.2</b> Videos to learn about version control with GitHub and Git</a><ul>
<li class="chapter" data-level="5.2.1" data-path="GitHub.html"><a href="GitHub.html#creating-a-github-repository"><i class="fa fa-check"></i><b>5.2.1</b> Creating a GitHub repository</a></li>
<li class="chapter" data-level="5.2.2" data-path="GitHub.html"><a href="GitHub.html#exploring-a-github-repository"><i class="fa fa-check"></i><b>5.2.2</b> Exploring a GitHub repository</a></li>
<li class="chapter" data-level="5.2.3" data-path="GitHub.html"><a href="GitHub.html#directly-editing-files-on-github"><i class="fa fa-check"></i><b>5.2.3</b> Directly editing files on GitHub</a></li>
<li class="chapter" data-level="5.2.4" data-path="GitHub.html"><a href="GitHub.html#logging-changes-and-pushing-them-to-github"><i class="fa fa-check"></i><b>5.2.4</b> Logging changes and pushing them to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="GitHub.html"><a href="GitHub.html#git-command-cheatsheet"><i class="fa fa-check"></i><b>5.3</b> Git command cheatsheet</a><ul>
<li class="chapter" data-level="5.3.1" data-path="GitHub.html"><a href="GitHub.html#getting-a-repository-from-github-onto-the-server-for-the-first-time"><i class="fa fa-check"></i><b>5.3.1</b> Getting a repository from GitHub onto the server for the first time</a></li>
<li class="chapter" data-level="5.3.2" data-path="GitHub.html"><a href="GitHub.html#logging-changes"><i class="fa fa-check"></i><b>5.3.2</b> Logging changes</a></li>
<li class="chapter" data-level="5.3.3" data-path="GitHub.html"><a href="GitHub.html#sending-your-changes-back-to-github"><i class="fa fa-check"></i><b>5.3.3</b> Sending your changes back to GitHub</a></li>
<li class="chapter" data-level="5.3.4" data-path="GitHub.html"><a href="GitHub.html#getting-changes"><i class="fa fa-check"></i><b>5.3.4</b> Getting changes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="GitHub.html"><a href="GitHub.html#terminal-cheatsheet"><i class="fa fa-check"></i><b>5.4</b> Terminal cheatsheet</a><ul>
<li class="chapter" data-level="5.4.1" data-path="GitHub.html"><a href="GitHub.html#see-where-you-are"><i class="fa fa-check"></i><b>5.4.1</b> See where you are:</a></li>
<li class="chapter" data-level="5.4.2" data-path="GitHub.html"><a href="GitHub.html#see-what-is-inside-the-directory-where-you-are"><i class="fa fa-check"></i><b>5.4.2</b> See what is inside the directory where you are:</a></li>
<li class="chapter" data-level="5.4.3" data-path="GitHub.html"><a href="GitHub.html#move-to-a-different-directory"><i class="fa fa-check"></i><b>5.4.3</b> Move to a different directory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>6</b> Classification I: Training &amp; predicting</a><ul>
<li class="chapter" data-level="6.1" data-path="classification.html"><a href="classification.html#overview-4"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification.html"><a href="classification.html#chapter-learning-objectives-4"><i class="fa fa-check"></i><b>6.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification.html"><a href="classification.html#the-classification-problem"><i class="fa fa-check"></i><b>6.3</b> The classification problem</a></li>
<li class="chapter" data-level="6.4" data-path="classification.html"><a href="classification.html#exploring-a-labelled-data-set"><i class="fa fa-check"></i><b>6.4</b> Exploring a labelled data set</a></li>
<li class="chapter" data-level="6.5" data-path="classification.html"><a href="classification.html#classification-with-k-nearest-neighbours"><i class="fa fa-check"></i><b>6.5</b> Classification with K-nearest neighbours</a></li>
<li class="chapter" data-level="6.6" data-path="classification.html"><a href="classification.html#k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>6.6</b> K-nearest neighbours in R</a></li>
<li class="chapter" data-level="6.7" data-path="classification.html"><a href="classification.html#data-preprocessing"><i class="fa fa-check"></i><b>6.7</b> Data preprocessing</a><ul>
<li class="chapter" data-level="6.7.1" data-path="classification.html"><a href="classification.html#shifting-and-scaling"><i class="fa fa-check"></i><b>6.7.1</b> Shifting and scaling</a></li>
<li class="chapter" data-level="6.7.2" data-path="classification.html"><a href="classification.html#balancing"><i class="fa fa-check"></i><b>6.7.2</b> Balancing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-continued.html"><a href="classification-continued.html"><i class="fa fa-check"></i><b>7</b> Classification II: Evaluation &amp; tuning</a><ul>
<li class="chapter" data-level="7.1" data-path="classification-continued.html"><a href="classification-continued.html#overview-5"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="classification-continued.html"><a href="classification-continued.html#chapter-learning-objectives-5"><i class="fa fa-check"></i><b>7.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="classification-continued.html"><a href="classification-continued.html#evaluating-accuracy"><i class="fa fa-check"></i><b>7.3</b> Evaluating accuracy</a></li>
<li class="chapter" data-level="7.4" data-path="classification-continued.html"><a href="classification-continued.html#tuning-the-classifier"><i class="fa fa-check"></i><b>7.4</b> Tuning the classifier</a><ul>
<li class="chapter" data-level="7.4.1" data-path="classification-continued.html"><a href="classification-continued.html#cross-validation"><i class="fa fa-check"></i><b>7.4.1</b> Cross-validation</a></li>
<li class="chapter" data-level="7.4.2" data-path="classification-continued.html"><a href="classification-continued.html#parameter-value-selection"><i class="fa fa-check"></i><b>7.4.2</b> Parameter value selection</a></li>
<li class="chapter" data-level="7.4.3" data-path="classification-continued.html"><a href="classification-continued.html#underoverfitting"><i class="fa fa-check"></i><b>7.4.3</b> Under/overfitting</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="classification-continued.html"><a href="classification-continued.html#splitting-data"><i class="fa fa-check"></i><b>7.5</b> Splitting data</a></li>
<li class="chapter" data-level="7.6" data-path="classification-continued.html"><a href="classification-continued.html#summary"><i class="fa fa-check"></i><b>7.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>8</b> Regression I: K-nearest neighbours</a><ul>
<li class="chapter" data-level="8.1" data-path="regression1.html"><a href="regression1.html#overview-6"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression1.html"><a href="regression1.html#chapter-learning-objectives-6"><i class="fa fa-check"></i><b>8.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression1.html"><a href="regression1.html#regression"><i class="fa fa-check"></i><b>8.3</b> Regression</a></li>
<li class="chapter" data-level="8.4" data-path="regression1.html"><a href="regression1.html#sacremento-real-estate-example"><i class="fa fa-check"></i><b>8.4</b> Sacremento real estate example</a></li>
<li class="chapter" data-level="8.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbours-regression"><i class="fa fa-check"></i><b>8.5</b> K-nearest neighbours regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression1.html"><a href="regression1.html#assessing-a-nearest-neighbours-regression-model"><i class="fa fa-check"></i><b>8.6</b> Assessing a nearest neighbours regression model</a><ul>
<li class="chapter" data-level="8.6.1" data-path="regression1.html"><a href="regression1.html#rmspe-versus-rmse"><i class="fa fa-check"></i><b>8.6.1</b> RMSPE versus RMSE</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="regression1.html"><a href="regression1.html#how-do-different-ks-affect-k-nn-regression-predictions"><i class="fa fa-check"></i><b>8.7</b> How do different k’s affect k-nn regression predictions</a></li>
<li class="chapter" data-level="8.8" data-path="regression1.html"><a href="regression1.html#assessing-how-well-the-model-predicts-on-unseen-data-with-the-test-set"><i class="fa fa-check"></i><b>8.8</b> Assessing how well the model predicts on unseen data with the test set</a></li>
<li class="chapter" data-level="8.9" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9</b> Strengths and limitations of k-nn regression</a></li>
<li class="chapter" data-level="8.10" data-path="regression1.html"><a href="regression1.html#multivariate-k-nn-regression"><i class="fa fa-check"></i><b>8.10</b> Multivariate k-nn regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>9</b> Regression II: Linear regression</a><ul>
<li class="chapter" data-level="9.1" data-path="regression2.html"><a href="regression2.html#overview-7"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="regression2.html"><a href="regression2.html#chapter-learning-objectives-7"><i class="fa fa-check"></i><b>9.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="regression2.html"><a href="regression2.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.3</b> Simple linear regression</a></li>
<li class="chapter" data-level="9.4" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r-using-caret"><i class="fa fa-check"></i><b>9.4</b> Linear regression in R using <code>caret</code></a></li>
<li class="chapter" data-level="9.5" data-path="regression2.html"><a href="regression2.html#comparing-simple-linear-and-k-nn-regression"><i class="fa fa-check"></i><b>9.5</b> Comparing simple linear and k-nn regression</a></li>
<li class="chapter" data-level="9.6" data-path="regression2.html"><a href="regression2.html#multivariate-linear-regression"><i class="fa fa-check"></i><b>9.6</b> Multivariate linear regression</a></li>
<li class="chapter" data-level="9.7" data-path="regression2.html"><a href="regression2.html#the-other-side-of-regression"><i class="fa fa-check"></i><b>9.7</b> The other side of regression</a></li>
<li class="chapter" data-level="9.8" data-path="regression2.html"><a href="regression2.html#additional-readingsresources-2"><i class="fa fa-check"></i><b>9.8</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>10</b> Clustering</a><ul>
<li class="chapter" data-level="10.1" data-path="clustering.html"><a href="clustering.html#overview-8"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="clustering.html"><a href="clustering.html#chapter-learning-objectives-8"><i class="fa fa-check"></i><b>10.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="clustering.html"><a href="clustering.html#clustering-1"><i class="fa fa-check"></i><b>10.3</b> Clustering</a></li>
<li class="chapter" data-level="10.4" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>10.4</b> K-means</a><ul>
<li class="chapter" data-level="10.4.1" data-path="clustering.html"><a href="clustering.html#measuring-cluster-quality"><i class="fa fa-check"></i><b>10.4.1</b> Measuring cluster quality</a></li>
<li class="chapter" data-level="10.4.2" data-path="clustering.html"><a href="clustering.html#the-clustering-algorithm"><i class="fa fa-check"></i><b>10.4.2</b> The clustering algorithm</a></li>
<li class="chapter" data-level="10.4.3" data-path="clustering.html"><a href="clustering.html#random-restarts"><i class="fa fa-check"></i><b>10.4.3</b> Random restarts</a></li>
<li class="chapter" data-level="10.4.4" data-path="clustering.html"><a href="clustering.html#choosing-k"><i class="fa fa-check"></i><b>10.4.4</b> Choosing K</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="clustering.html"><a href="clustering.html#k-means-in-r"><i class="fa fa-check"></i><b>10.5</b> K-means in R</a></li>
<li class="chapter" data-level="10.6" data-path="clustering.html"><a href="clustering.html#additional-readings"><i class="fa fa-check"></i><b>10.6</b> Additional readings:</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Classification I: Training &amp; predicting</h1>
<div id="overview-4" class="section level2">
<h2><span class="header-section-number">6.1</span> Overview</h2>
<p>Up until this point, we have focused solely on descriptive and exploratory questions about data. This chapter and the next together serve as our
first foray into answering <em>predictive</em> questions about data. In particular, we will focus on the problem of <em>classification</em>, i.e.,
using one or more quantitative variables to predict the value of a third, categorical variable. This chapter will cover the basics of classification,
how to preprocess data to make it suitable for use in a classifier,
and how to use our observed data to make predictions. The next will focus on how to evaluate how accurate the predictions from our classifier are, as well as how to
improve our classifier (where possible) to maximize its accuracy.</p>
</div>
<div id="chapter-learning-objectives-4" class="section level2">
<h2><span class="header-section-number">6.2</span> Chapter learning objectives</h2>
<ul>
<li>Recognize situations where a classifier would be appropriate for making predictions</li>
<li>Describe what a training data set is and how it is used in classification</li>
<li>Interpret the output of a classifier</li>
<li>Compute, by hand, the straight-line (Euclidean) distance between points on a graph when there are two explanatory variables/predictors</li>
<li>Explain the K-nearest neighbour classification algorithm</li>
<li>Standardize variables in R, and explain why standardization is useful in predictive modelling</li>
<li>Handle imbalanced data by oversampling in R, and explain why imbalanced data are problematic for classifiers</li>
<li>Perform K-nearest neighbour classification in R using <code>caret::train(method = "knn", ...)</code></li>
</ul>
</div>
<div id="the-classification-problem" class="section level2">
<h2><span class="header-section-number">6.3</span> The classification problem</h2>
<p>In many situations, we want to make predictions based on the current situation as well as past experiences. For instance, a doctor may want to diagnose
a patient as either diseased or healthy based on their symptoms and the doctor’s past experience with patients; an email provider might want to tag a given email as “spam” or “non-spam”
depending on past email text data; or an online store may want to predict whether an order is fraudulent or not.</p>
<p>These tasks are all examples of <strong>classification</strong>, i.e., predicting a categorical class (sometimes called a <em>label</em>) for an observation given its other
quantitative variables (sometimes called <em>features</em>). Generally, a classifier assigns an observation (e.g. a new patient) to a class (e.g. diseased or healthy) on
the basis of how similar it is to other observations for which we know the class (e.g. previous patients with known diseases and symptoms). These observations
with known classes that we use as a basis for prediction are called a <strong>training set</strong>. We call them a “training set” because we use these observations to train, or
teach, our classifier so that we can use it to make predictions on new data that we have not seen previously.</p>
<p>There are many possible classification algorithms that we could use to predict a categorical class/label for an observation. In addition, there are many
variations on the basic classification problem, e.g., binary classification where only two classes are involved (e.g. disease or healthy patient), or multiclass classification, which involves
assigning an object to one of several classes (e.g., private, public, or not for-profit organization). Here we will focus on the simple, widely used <strong>K-nearest neighbours</strong>
algorithm for the binary classification problem. Other examples you may encounter in future courses include decision trees, support vector machines (SVMs), logistic regression, and neural
networks.</p>
</div>
<div id="exploring-a-labelled-data-set" class="section level2">
<h2><span class="header-section-number">6.4</span> Exploring a labelled data set</h2>
<p>In this chapter and the next, we will study a data set of <a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">digitized breast cancer image features</a>,
created by Dr. William H. Wolberg, W. Nick Street, and Olvi L. Mangasarian at the University of Wisconsin, Madison. Each row in the data set represents an image of a tumour sample,
including the diagnosis (benign or malignant) and several other measurements
(e.g., nucleus texture, perimeter, area, etc.). Diagnosis for each image was conducted by physicians.</p>
<p>As with all data analyses, we first need to formulate a precise question that we want to answer. Here, the question is <em>predictive</em>: can
we use the tumour image measurements available to us to predict whether a future tumour image (with unknown diagnosis)
shows a benign or malignant tumour? Answering this question is important because traditional, non-data-driven methods for tumour diagnosis are quite subjective and
dependent upon how skilled and experienced the diagnosing physician is. Furthermore, benign tumours are not normally dangerous; the cells stay in the same
place and the tumour stops growing before it gets very large. By contrast, in malignant tumours, the cells invade the surrounding tissue and spread into nearby organs
where they can cause serious damage (<a href="https://www.worldwidecancerresearch.org/who-we-are/cancer-basics/">learn more about cancer here</a>). Thus, it is important to quickly
and accurately diagnose the tumour type to guide patient treatment.</p>
<p><strong>Loading the data</strong></p>
<<<<<<< HEAD
<p>Our first step is to load, wrangle, and explore the data using visualizations in order to better understand the data we are working with. We start by loading the necessary libraries for our analysis. Below you’ll see (in addition to the usual <code>tidyverse</code>) a new library, <code>forcats</code>, that enables us to easily manipulate factors in R. Factors are a special categorical type of variable in R that are very helpful when doing data analysis with categorical variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(forcats)</code></pre></div>
<p>In this case, the file containing the breast cancer data set is a simple <code>.csv</code> file with headers. We’ll use the <code>read_csv</code> function with no additional arguments, and then the <code>head</code> function to inspect its contents:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cancer &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/wdbc.csv&quot;</span>)
<span class="kw">head</span>(cancer)</code></pre></div>
<pre><code>## # A tibble: 6 x 12
##       ID Class Radius Texture Perimeter   Area Smoothness Compactness
##    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1 8.42e5 M      1.10   -2.07      1.27   0.984      1.57        3.28 
## 2 8.43e5 M      1.83   -0.353     1.68   1.91      -0.826      -0.487
## 3 8.43e7 M      1.58    0.456     1.57   1.56       0.941       1.05 
## 4 8.43e7 M     -0.768   0.254    -0.592 -0.764      3.28        3.40 
## 5 8.44e7 M      1.75   -1.15      1.78   1.82       0.280       0.539
## 6 8.44e5 M     -0.476  -0.835    -0.387 -0.505      2.24        1.24 
## # … with 4 more variables: Concavity &lt;dbl&gt;, Concave_Points &lt;dbl&gt;,
## #   Symmetry &lt;dbl&gt;, Fractal_Dimension &lt;dbl&gt;</code></pre>
=======
<p>Our first step is to load, wrangle, and explore the data using visualizations in order to better understand the data we are working with.
We start by loading the necessary libraries for our analysis. Below you’ll see (in addition to the usual <code>tidyverse</code>) a new library, <code>forcats</code>, that
enables us to easily manipulate factors in R. Factors are a special categorical type of variable in R that are very helpful when doing data analysis with categorical variables.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="classification.html#cb163-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb163-2"><a href="classification.html#cb163-2"></a><span class="kw">library</span>(forcats)</span></code></pre></div>
<p>In this case, the file containing the breast cancer data set is a simple <code>.csv</code> file with headers. We’ll use the <code>read_csv</code> function with no additional arguments,
and then the <code>head</code> function to inspect its contents:</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="classification.html#cb164-1"></a>cancer &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/clean-wdbc.data.csv&quot;</span>)</span>
<span id="cb164-2"><a href="classification.html#cb164-2"></a><span class="kw">head</span>(cancer)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 12
##         ID Class Radius Texture Perimeter   Area Smoothness Compactness Concavity Concave_points Symmetry Fractal_dimension
##      &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt;
## 1   842302 M      1.89  -1.36       2.30   2.00       1.31        2.61      2.11           2.29     2.75              1.94 
## 2   842517 M      1.80  -0.369      1.53   1.89      -0.375      -0.430    -0.147          1.09    -0.244             0.281
## 3 84300903 M      1.51  -0.0240     1.35   1.46       0.527       1.08      0.854          1.95     1.15              0.201
## 4 84348301 M     -0.281  0.134     -0.250 -0.550      3.39        3.89      1.99           2.17     6.04              4.93 
## 5 84358402 M      1.30  -1.47       1.34   1.22       0.220      -0.313     0.613          0.729   -0.868            -0.397
## 6   843786 M     -0.165 -0.314     -0.115 -0.244      2.05        1.72      1.26           0.905    1.75              2.24</code></pre>
>>>>>>> dev
<p><strong>Variable descriptions</strong></p>
<p>Breast tumours can be diagnosed by performing a <em>biopsy</em>, a process where tissue is removed from the body to diagnose the presence of a disease. Traditionally these procedures
were quite invasive; modern methods such as fine needle asipiration, used to collect the present data set, extract only a small amount of tissue and are less invasive. Based
on a digital image of each breast tissue sample collected for this data set, 10 different variables were measured for each cell nucleus in the image (3-12 below), and then
the mean of the three largest values for each variable across the nuclei was recorded. As part of the data preparation, these values have been <em>scaled</em>; we will discuss what this means
and why we do it later in this chapter. Each image additionally was given a unique ID and a diagnosis for malignance by a physician.
Therefore, the total set of variables per image in this data set are:</p>
<ol style="list-style-type: decimal">
<li>ID number</li>
<li>Class - diagnosis (M = malignant, B = benign)</li>
<li>radius (mean of distances from center to points on the perimeter)</li>
<li>texture (standard deviation of gray-scale values)</li>
<li>perimeter</li>
<li>area</li>
<li>smoothness (local variation in radius lengths)</li>
<li>compactness (<span class="math inline">\(perimeter^2 / area - 1.0\)</span>)</li>
<li>concavity (severity of concave portions of the contour)</li>
<li>concave points (number of concave portions of the contour)</li>
<li>symmetry</li>
<li>fractal dimension (<span class="math inline">\(&quot;coastline\: approximation&quot; - 1\)</span>)</li>
</ol>
<div class="figure">
<img src="img/malignant_cancer.png" title="A magnified image of a malignant breast fine needle aspiration." alt="" />
<p class="caption">A magnified image of a malignant breast fine needle aspiration image. White lines denote the boundary of the cell nuclei. Source: <a href="https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0" class="uri">https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0</a></p>
</div>
<p>Below we use <code>glimpse</code> to preview the data frame. This function is similar to <code>head</code>, but can be easier to read when we have a lot of columns:</p>
<<<<<<< HEAD
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(cancer)</code></pre></div>
<pre><code>## Observations: 569
## Variables: 12
## $ ID                &lt;dbl&gt; 842302, 842517, 84300903, 84348301, 84358402, …
## $ Class             &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;…
## $ Radius            &lt;dbl&gt; 1.0960995, 1.8282120, 1.5784992, -0.7682333, 1…
## $ Texture           &lt;dbl&gt; -2.0715123, -0.3533215, 0.4557859, 0.2535091, …
## $ Perimeter         &lt;dbl&gt; 1.26881726, 1.68447255, 1.56512598, -0.5921661…
## $ Area              &lt;dbl&gt; 0.98350952, 1.90703027, 1.55751319, -0.7637917…
## $ Smoothness        &lt;dbl&gt; 1.56708746, -0.82623545, 0.94138212, 3.2806668…
## $ Compactness       &lt;dbl&gt; 3.28062806, -0.48664348, 1.05199990, 3.3999174…
## $ Concavity         &lt;dbl&gt; 2.65054179, -0.02382489, 1.36227979, 1.9142128…
## $ Concave_Points    &lt;dbl&gt; 2.53024886, 0.54766227, 2.03543978, 1.45043113…
## $ Symmetry          &lt;dbl&gt; 2.215565542, 0.001391139, 0.938858720, 2.86486…
## $ Fractal_Dimension &lt;dbl&gt; 2.25376381, -0.86788881, -0.39765801, 4.906601…</code></pre>
<p>We can see from the summary of the data above that <code>Class</code> is of type character (denoted by <code>&lt;chr&gt;</code>). Since we are going to be working with <code>Class</code> as a categorical statistical variable, we will convert it to factor using the function <code>as.factor</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cancer &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Class =</span> <span class="kw">as.factor</span>(Class)) </code></pre></div>
<p>Factors have what are called “levels”, which you can think of as categories. We can ask for the levels from the <code>Class</code> column by using the <code>levels</code> function. This function should return the name of each category in that column. Given that we only have 2 different values in our <code>Class</code> column (“B” and “M”), we only expect to get two names back. If we had 4 different values in the column, we would expect to get 4 back. <em>Note the use of <code>unlist</code> to between <code>select</code> and <code>levels</code>. This is because <code>select</code> outputs a data frame (even though we only select a single column), and levels expects a vector.</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cancer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># turns a data frame into a vector</span>
<span class="st">  </span><span class="kw">levels</span>()</code></pre></div>
=======
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="classification.html#cb166-1"></a><span class="kw">glimpse</span>(cancer)</span></code></pre></div>
<pre><code>## Rows: 569
## Columns: 12
## $ ID                &lt;dbl&gt; 842302, 842517, 84300903, 84348301, 84358402, 843786, 844359, 84458202, 844981, 84501001, 845636, 846…
## $ Class             &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;B&quot;, &quot;…
## $ Radius            &lt;dbl&gt; 1.88503100, 1.80433981, 1.51054113, -0.28121702, 1.29743364, -0.16535275, 1.36777980, 0.16361901, -0.…
## $ Texture           &lt;dbl&gt; -1.35809849, -0.36887865, -0.02395331, 0.13386631, -1.46548091, -0.31356043, 0.32259904, 0.40069534, …
## $ Perimeter         &lt;dbl&gt; 2.301575480, 1.533776431, 1.346290616, -0.249719577, 1.337362721, -0.114908349, 1.367122374, 0.099361…
## $ Area              &lt;dbl&gt; 1.999478159, 1.888827020, 1.455004298, -0.549537693, 1.219651081, -0.244105421, 1.274098467, 0.028834…
## $ Smoothness        &lt;dbl&gt; 1.306536657, -0.375281748, 0.526943750, 3.391290721, 0.220362270, 2.046711944, 0.518184279, 1.4466881…
## $ Compactness       &lt;dbl&gt; 2.61436466, -0.43006581, 1.08198014, 3.88997467, -0.31311900, 1.72010293, 0.02119633, 0.72414833, 1.8…
## $ Concavity         &lt;dbl&gt; 2.10767182, -0.14661996, 0.85422232, 1.98783917, 0.61263970, 1.26213265, 0.50910429, -0.02103534, 1.2…
## $ Concave_points    &lt;dbl&gt; 2.29405760, 1.08612862, 1.95328166, 2.17387323, 0.72861815, 0.90509140, 1.19566374, 0.62364699, 1.390…
## $ Symmetry          &lt;dbl&gt; 2.7482041, -0.2436753, 1.1512420, 6.0407261, -0.8675896, 1.7525273, 0.2622449, 0.4772206, 2.3877562, …
## $ Fractal_dimension &lt;dbl&gt; 1.93531174, 0.28094279, 0.20121416, 4.93067187, -0.39675052, 2.23983079, -0.01471753, 1.72491676, 1.2…</code></pre>
<p>We can see from the summary of the data above that <code>Class</code> is of type character (denoted by <code>&lt;chr&gt;</code>). Since we are going to be working with <code>Class</code> as a categorical statistical
variable, we will convert it to factor using the function <code>as.factor</code>.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="classification.html#cb168-1"></a>cancer &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb168-2"><a href="classification.html#cb168-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Class =</span> <span class="kw">as.factor</span>(Class)) </span></code></pre></div>
<p>Factors have what are called “levels”, which you can think of as categories. We can ask for the levels from the <code>Class</code> column by using the <code>levels</code> function. This function should return
the name of each category in that column. Given that we only have 2 different values in our <code>Class</code> column (“B” and “M”), we only expect to get two names back. If we had 4 different values
in the column, we would expect to get 4 back. <em>Note the use of <code>pull</code> to between <code>select</code> and <code>levels</code>. This is because <code>select</code> outputs a data frame (even though we only select a single column), and levels expects a vector. <code>pull</code> converts a single column of a data frame into a vector.</em></p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="classification.html#cb169-1"></a>cancer <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb169-2"><a href="classification.html#cb169-2"></a><span class="st">  </span><span class="kw">select</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb169-3"><a href="classification.html#cb169-3"></a><span class="st">  </span><span class="kw">pull</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># turns a data frame into a vector</span></span>
<span id="cb169-4"><a href="classification.html#cb169-4"></a><span class="st">  </span><span class="kw">levels</span>()</span></code></pre></div>
>>>>>>> dev
<pre><code>## [1] &quot;B&quot; &quot;M&quot;</code></pre>
<p><strong>Exploring the data</strong></p>
<p>Before we start doing any modelling, let’s explore our data set. Below we use the <code>group_by</code> + <code>summarize</code> code pattern we used before to see that we have 357 (63%) benign and 212 (37%) malignant tumour observations.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="classification.html#cb171-1"></a>num_obs &lt;-<span class="st"> </span><span class="kw">nrow</span>(cancer)</span>
<span id="cb171-2"><a href="classification.html#cb171-2"></a>cancer <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb171-3"><a href="classification.html#cb171-3"></a><span class="st">  </span><span class="kw">group_by</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb171-4"><a href="classification.html#cb171-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(),</span>
<span id="cb171-5"><a href="classification.html#cb171-5"></a>            <span class="dt">percentage =</span> <span class="kw">n</span>() <span class="op">/</span><span class="st"> </span>num_obs <span class="op">*</span><span class="st"> </span><span class="dv">100</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   Class     n percentage
##   &lt;fct&gt; &lt;int&gt;      &lt;dbl&gt;
## 1 B       357       62.7
## 2 M       212       37.3</code></pre>
<p>Next, let’s draw a scatter plot to visualize the relationship between the perimeter and concavity variables. Rather than use <code>ggplot's</code> default palette, we define our own here (<code>cbPalette</code>) and pass it
as the <code>values</code> argument to the <code>scale_color_manual</code> function. We also make the category labels (“B” and “M”) more readable by changing them to “Benign” and “Malignant” using the <code>labels</code> argument.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="classification.html#cb173-1"></a><span class="co"># colour palette</span></span>
<span id="cb173-2"><a href="classification.html#cb173-2"></a>cbPalette &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#E69F00&quot;</span>,<span class="st">&quot;#009E73&quot;</span>, <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>, <span class="st">&quot;#999999&quot;</span>) </span>
<span id="cb173-3"><a href="classification.html#cb173-3"></a></span>
<span id="cb173-4"><a href="classification.html#cb173-4"></a>perim_concav &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span><span class="st">  </span></span>
<span id="cb173-5"><a href="classification.html#cb173-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Perimeter, <span class="dt">y =</span> Concavity, <span class="dt">color =</span> Class)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb173-6"><a href="classification.html#cb173-6"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></span>
<span id="cb173-7"><a href="classification.html#cb173-7"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">color =</span> <span class="st">&quot;Diagnosis&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb173-8"><a href="classification.html#cb173-8"></a><span class="st">    </span><span class="kw">scale_color_manual</span>(<span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Benign&quot;</span>, <span class="st">&quot;Malignant&quot;</span>), <span class="dt">values =</span> cbPalette)</span>
<span id="cb173-9"><a href="classification.html#cb173-9"></a>perim_concav</span></code></pre></div>
<p><img src="_main_files/figure-html/05-scatter-1.png" width="480" /></p>
<p>In this visualization, we can see that benign observations typically fall in the the lower left-hand side of the plot area. By contrast, malignant observations typically fall in upper right-hand side of
the plot. Suppose we obtain a new observation not in the current data set that has all the variables measured <em>except</em> the label (i.e., an image without the physician’s diagnosis for the tumour class). We
could compute the perimeter and concavity values, resulting in values of, say, 1 and 1. Could we use this information to classify that observation as benign or malignant? What about a new
observation with perimeter value of -1 and concavity value of -0.5? What about 0 and 1? It seems like the <em>prediction of an unobserved label</em> might be possible, based on our visualization.
In order to actually do this computationally in practice, we will need a classification algorithm; here we will use the K-nearest neighbour classification algorithm.</p>
</div>
<div id="classification-with-k-nearest-neighbours" class="section level2">
<h2><span class="header-section-number">6.5</span> Classification with K-nearest neighbours</h2>
<p>To predict the label of a new observation, i.e., classify it as either benign or malignant, the K-nearest neighbour classifier generally finds the <span class="math inline">\(K\)</span> “nearest” or “most similar”
observations in our training set, and then uses their diagnoses to make a prediction for the new observation’s diagnosis. To illustrate this concept, we will walk through an example.
Suppose we have a new observation, with perimeter of 2 and concavity of 4 (labelled in red on the scatterplot), whose diagnosis “Class” is unknown.</p>
<center>
<img src="_main_files/figure-html/05-knn-1-1.png" width="480" />
</center>
<<<<<<< HEAD
<p>We see that the nearest point to this new observation is <strong>malignant</strong> and located at the coordinates (2.1, 3.6). The idea here is that if a point is close to another in the scatterplot, then the perimeter and concavity values are similar, and so we may expect that they would have the same diagnosis.</p>
<center>
<img src="_main_files/figure-html/05-knn-2-1.png" width="480" />
</center>
<p>Suppose we have another new observation with perimeter 0.2 and concavity of 3.3. Looking at the scatterplot below, how would you classify this red observation? The nearest neighbour to this new point is a <strong>benign</strong> observation at (0.2, 2.7). Does this seem like the right prediction to make? Probably not, if you consider the other nearby points…</p>
<center>
<img src="_main_files/figure-html/05-knn-4-1.png" width="480" />
</center>
<p>So instead of just using the one nearest neighbour, we can consider several neighbouring points, say <span class="math inline">\(K = 3\)</span>, that are closest to the new red observation to predict its diagnosis class. Among those 3 closest points, we use the <em>majority class</em> as our prediction for the new observation. In this case, we see that the diagnoses of 2 of the 3 nearest neighbours to our new observation are malignant. Therefore we take majority vote and classify our new red observation as malignant. <!-- For our red observation at (0.2, 3.3), the nearest points are: (0.2, 2.7), (0.8, 2.9), and (0.6, 2.5). --></p>
=======
<p>We see that the nearest point to this new observation is <strong>malignant</strong> and located at the coordinates (2.3, 3.2). The idea here is that if
a point is close to another in the scatterplot, then the perimeter and concavity values are similar, and so we may expect that they would have the same diagnosis.</p>
<center>
<img src="_main_files/figure-html/05-knn-2-1.png" width="480" />
</center>
<p>Suppose we have another new observation with perimeter 0.38 and concavity of 1.8. Looking at the scatterplot below, how would you classify this red observation? The
nearest neighbour to this new point is a <strong>benign</strong> observation at (0.2, 1.8). Does this seem like the right prediction to make? Probably not,
if you consider the other nearby points…</p>
<center>
<img src="_main_files/figure-html/05-knn-4-1.png" width="480" />
</center>
<p>So instead of just using the one nearest neighbour, we can consider several neighbouring points, say <span class="math inline">\(K = 3\)</span>, that are closest to the new red observation to predict its diagnosis class. Among those 3 closest
points, we use the <em>majority class</em> as our prediction for the new observation. In this case, we see that the diagnoses of 2 of the 3 nearest neighbours to our new
observation are malignant. Therefore we take majority vote and classify our new red observation as malignant.
<!-- For our red observation at (0.38, 1.8), the nearest points are: (0.2, 1.8), (0.5, 1.7), and (0.4, 2). --></p>
>>>>>>> dev
<center>
<img src="_main_files/figure-html/05-knn-5-1.png" width="480" />
</center>
<p>Here we chose the <span class="math inline">\(K=3\)</span> nearest observations, but there is nothing special about <span class="math inline">\(K=3\)</span>. We could have used <span class="math inline">\(K=4, 5\)</span> or more (though we may want to choose an odd number
to avoid ties). We will discuss more about choosing <span class="math inline">\(K\)</span> in the next chapter.</p>
<p><strong>Distance between points</strong></p>
<p>How do we decide which points are the <span class="math inline">\(K\)</span> “nearest” to our new observation? We can compute the distance between any pair of points using the following formula:</p>
<p><span class="math display">\[\mathrm{Distance} = \sqrt{(x_a -x_b)^2 + (y_a - y_b)^2}\]</span></p>
<blockquote>
<p>This formula – sometimes called the <em>Euclidean distance</em> – is simply the straight line distance between two points on the x-y plane with coordinates <span class="math inline">\((x_a, y_a)\)</span> and <span class="math inline">\((x_b, y_b)\)</span>.</p>
</blockquote>
<<<<<<< HEAD
<p>Suppose we want to classify a new observation with perimeter of 0 and concavity of 3.5. Let’s calculate the distances between our new point and each of the observations in the training set to find the <span class="math inline">\(K=5\)</span> observations in the training data that are nearest to our new point.</p>
<center>
<img src="_main_files/figure-html/05-multiknn-1-1.png" width="480" />
</center>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">new_obs_Perimeter &lt;-<span class="st"> </span><span class="dv">0</span>
new_obs_Concavity &lt;-<span class="st"> </span><span class="fl">3.5</span>
cancer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(ID, Perimeter, Concavity, Class) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dist_from_new =</span> <span class="kw">sqrt</span>((Perimeter <span class="op">-</span><span class="st"> </span>new_obs_Perimeter)<span class="op">^</span><span class="dv">2</span>  <span class="op">+</span><span class="st"> </span>(Concavity <span class="op">-</span><span class="st"> </span>new_obs_Concavity)<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(dist_from_new) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>(<span class="dt">n =</span> <span class="dv">5</span>)</code></pre></div>
=======
<p>Suppose we want to classify a new observation with perimeter of -1 and concavity of 4.2. Let’s calculate the distances between our
new point and each of the observations in the training set to find the <span class="math inline">\(K=5\)</span> observations in the training data that are nearest to our new point.</p>
<center>
<img src="_main_files/figure-html/05-multiknn-1-1.png" width="480" />
</center>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="classification.html#cb174-1"></a>new_obs_Perimeter &lt;-<span class="st"> </span><span class="dv">-1</span></span>
<span id="cb174-2"><a href="classification.html#cb174-2"></a>new_obs_Concavity &lt;-<span class="st"> </span><span class="fl">4.2</span></span>
<span id="cb174-3"><a href="classification.html#cb174-3"></a>cancer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(ID, Perimeter, Concavity, Class) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb174-4"><a href="classification.html#cb174-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dist_from_new =</span> <span class="kw">sqrt</span>((Perimeter <span class="op">-</span><span class="st"> </span>new_obs_Perimeter)<span class="op">^</span><span class="dv">2</span>  <span class="op">+</span><span class="st"> </span>(Concavity <span class="op">-</span><span class="st"> </span>new_obs_Concavity)<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb174-5"><a href="classification.html#cb174-5"></a><span class="st">  </span><span class="kw">arrange</span>(dist_from_new) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb174-6"><a href="classification.html#cb174-6"></a><span class="st">  </span><span class="kw">head</span>(<span class="dt">n =</span> <span class="dv">5</span>)</span></code></pre></div>
>>>>>>> dev
<pre><code>## # A tibble: 5 x 5
##        ID Perimeter Concavity Class dist_from_new
##     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;         &lt;dbl&gt;
## 1   86409     0.241      2.65 B             0.881
## 2  887181     0.750      2.87 M             0.980
## 3  899667     0.623      2.54 M             1.14 
## 4  907914     0.417      2.31 M             1.26 
## 5 8710441    -1.16       4.04 B             1.28</code></pre>
<p>From this, we see that 3 of the 5 nearest neighbours to our new observation are malignant so classify our new observation as malignant. We circle those 5 in the plot below:</p>
<center>
<img src="_main_files/figure-html/05-multiknn-3-1.png" width="672" />
</center>
<p>It can be difficult sometimes to read code as math, so here we mathematically show the calculation of distance for each of the 5 closest points.</p>
<table>
<thead>
<tr class="header">
<th>Perimeter</th>
<th>Concavity</th>
<th>Distance</th>
<th>Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0.24</td>
<td>2.65</td>
<td><span class="math inline">\(\sqrt{0 - 0.241)^2 + (3.5 - 2.65)^2}=\)</span> 0.88</td>
<td>B</td>
</tr>
<tr class="even">
<td>0.75</td>
<td>2.87</td>
<td><span class="math inline">\(\sqrt{(0 - 0.750)^2 + (3.5 - 2.87)^2} =\)</span> 0.98</td>
<td>M</td>
</tr>
<tr class="odd">
<td>0.62</td>
<td>2.54</td>
<td><span class="math inline">\(\sqrt{(0 - 0.623)^2 + (3.5 - 2.54)^2} =\)</span> 1.14</td>
<td>M</td>
</tr>
<tr class="even">
<td>0.42</td>
<td>2.31</td>
<td><span class="math inline">\(\sqrt{(0 - 0.417)^2 + (3.5 - 2.31)^2} =\)</span> 1.26</td>
<td>M</td>
</tr>
<tr class="odd">
<td>-1.16</td>
<td>4.04</td>
<td><span class="math inline">\(\sqrt{(0 - (-1.16))^2 + (3.5 - 4.04)^2} =\)</span> 1.28</td>
<td>B</td>
</tr>
</tbody>
</table>
<hr />
<p><strong>More than two explanatory variables</strong></p>
<p>Although the above description is directed toward two explanatory variables / predictors, exactly the same K-nearest neighbour algorithm applies
when you have a higher number of explanatory variables (i.e., a higher-dimensional predictor space).
Each explanatory variable/predictor can give us new information to help create our classifier.
The only difference is the formula for the distance between points. In particular, let’s say we have <span class="math inline">\(m\)</span> predictor variables for two observations <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>,
i.e.,
<span class="math inline">\(u = (u_{1}, u_{2}, \dots, u_{m})\)</span> and
<span class="math inline">\(v = (v_{1}, v_{2}, \dots, v_{m})\)</span>.
Before, we added up the squared difference between each of our (two) variables, and then took the square root; now we will do the same, except for <em>all</em> of our <span class="math inline">\(m\)</span> variables.
In other words, the distance formula becomes</p>
<p><span class="math display">\[Distance = \sqrt{(u_{1} -v_{1})^2 + (u_{2} - v_{2})^2 + \dots + (u_{m} - v_{m})^2}\]</span></p>
<<<<<<< HEAD
<div id="htmlwidget-a1de80fb537b5ba0bd90" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-a1de80fb537b5ba0bd90">{"x":{"visdat":{"16e7161c92c0":["function () ","plotlyVisDat"]},"cur_data":"16e7161c92c0","attrs":{"16e7161c92c0":{"x":{},"y":{},"z":{},"opacity":0.4,"color":{},"size":150,"colors":["#E69F00","#56B4E9"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Perimeter"},"yaxis":{"title":"Concavity"},"zaxis":{"title":"Symmetry"}},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[-0.185564710912121,-0.260876510904117,-1.30166089440005,-0.385161557885442,-1.65681982004537,-0.573235287920097,-0.208199404898786,-0.709866531621423,-0.195853208178787,-0.669124082445426,-0.766659036533419,-0.385161557885442,-1.54858482880004,-1.1284026004294,-1.53541555229871,-1.34857644193605,-1.31112631188539,-0.830036179696082,-1.36544957745338,-0.436192504328106,-1.36544957745338,-0.525908200493434,-0.167045415832122,-0.361292244226777,-0.747316661672087,-0.225484080306785,-0.618093136002762,-0.501627346944102,0.156424938231859,0.107040151351861,-0.297503561173448,-0.220957141509452,-0.583523785186764,-1.22881833375206,-0.725505047466755,-1.98275941345335,-0.606981558954762,-1.1530949938694,-1.01070219169874,-0.691347236541424,-0.533315918525433,-0.80205146713075,-1.21276827801606,-0.404092392856108,0.241202155709187,-0.960082785146741,-1.48685384520004,-0.635377811410761,-1.36750727690672,-0.766659036533419,0.0951054945225291,-0.241534136042784,-0.14523380162679,0.313221636575849,-0.530435139290767,0.412814290117177,-0.709866531621423,-0.778182153472085,-0.780651392816085,-1.26462230424006,-0.753489760032087,-0.338657550240112,-0.975721300992073,-0.570354508685431,0.241613695599854,0.0823477579118631,-0.158403078128122,-0.348122967725444,-1.59261959710137,-1.16009117201073,-0.86830938952808,-0.274045787405449,-0.563769870434765,0.676199820143828,-0.622620074800095,-0.958025085693408,-0.653074026709426,-0.498746567709436,0.145313361183859,-0.954732766568075,0.174944233311858,-0.5399005567761,-0.895471022312079,-1.00740987257341,-1.54529250967471,-1.12634490097606,-0.409853951325441,-0.439484823453439,-0.758839778610753,-1.16091425179206,-0.711512691184089,-0.687231837634758,-0.540723636557433,-0.409442411434774,-1.28561083866406,-0.388453877010775,-0.552658293386765,-0.447715621266772,-1.19548360260806,-0.203672466101453,0.255194511991853,-0.677354880258758,-0.602866160048096,-1.10782560589607,-0.168280035504122,-0.13906070326679,-1.1049448266614,-0.305322819096114,0.0222629338745336,-1.0432138430614,0.225563639863855,-0.437015584109439,-0.831682339258749,-0.871601708653413,-1.30701091297872,-0.089675916386793,0.0239090934371999,-0.188857030037454,-0.549777514152099,-0.742378182984087,-0.141118402720123,-1.03909844415474,-0.322607494504113,-0.288861223469448,-0.986009798258739,-0.744847422328087,-0.769128275877419,-0.933744232144076,-0.19791090763212,-0.394626975370775,-0.92469035454941,-0.0686873819627946,-0.812339964397417,-1.25392226708272,-0.64895862780276,-0.830447719586749,-0.235772577573451,-0.122599107640125,-0.729620446373422,-0.324665193957446,-0.499569647490769,-0.58023146606143,-0.41479243001344,-0.751020520688087,-0.814809203741417,0.167124975389191,0.208278964455856,-0.36334994368011,-0.676120260586758,-0.419319368810773,-0.160872317472122,-0.939505790613409,-0.0308257120214635,-1.03374842557607,-0.47487725405077,-1.0333368856854,-0.756370539266753,-0.730031986264088,-0.325076733848113,-1.46545377088538,-0.258407271560117,-0.381046158978776,-0.725916587357422,0.0292591120158666,-0.398330834386775,-0.75060898079742,-1.55887332606671,-0.525908200493434,-0.605746939282762,-1.31277247144805,-0.550189054042766,-1.04732924196807,-0.376519220181443,-0.574469907592097,-0.441130983016106,-0.0797989590107938,-0.653485566600093,-0.306557438768114,-0.824274621226749,-0.847320855104082,-0.579819926170764,-0.324665193957446,-1.13416415889873,0.0897554759438629,-1.24816070861339,-0.842793916306748,-0.697108795010757,-1.0604985184694,-0.630027792832094,0.119386348071861,-0.779828313034752,-0.606570019064095,-0.75184360046942,-0.853082413573415,-0.41355781034144,-0.283099665000115,-0.141941482501457,-1.44981525504005,-1.32306096871472,-0.516442783008101,-0.276926566640116,-0.415615509794774,0.602122639823832,-0.267049609264116,-0.562123710872098,0.233794437677188,-0.169926195066788,0.589776443103833,-0.897940261656078,-0.250176473746784,-0.152229979768123,-0.774066754565419,-0.876540187341413,-0.544015955682766,-0.466234916346771,-0.25429187265345,-0.542781336010766,-0.148114580861456,-0.765012876970753,-1.0790178135494,-1.51031161896804,-0.572000668248098,-0.0913220759494598,-0.159226157909456,-0.36705380269611,-0.891355623405412,-0.687643377525424,-0.65142786714676,-0.320549795050779,-0.361703784117443,-0.562946790653431,-0.888063304280079,0.507468464970504,-0.384338478104109,-0.558008311965432,-0.801639927240084,-0.866251690074747,-1.32594174794939,0.228855958989188,-0.641139369880094,-1.33211484630939,-0.456357958970772,-0.865017070402747,-0.731266605936088,0.257252211445186,-0.679412579712092,-0.103256732778793,-1.23622605178406,-1.18437202556006,-1.00740987257341,-0.953909686786741,-0.884770985154746,-0.452242560064105,-0.43207710542144,0.120209427853194,-0.382692318541442,-0.0900874562774598,-0.13535684425079,-0.0979067142001259,-0.832916958930749,-0.148114580861456,-1.03498304524807,-0.590931503218763,0.160951877029192,0.0938708748505291,-0.623031614690761,-0.625500854034761,0.0778208191145301,-0.467057996128104,-0.231657178666785,-0.703693433261423,-0.323842114176113,-0.385161557885442,-1.24651454905072,0.0115628967172007,-0.744435882437421,-0.316434396144113,-0.209845564461453,-0.246472614730784,-1.27203002227206,-0.64155090977076,-1.25433380697339,-0.622208534909428,0.18440965079719,-0.598750761141429,-0.887240224498746,-0.373638440946776,0.0181475349678668,-0.123422187421458,-0.739908943640088,-0.562946790653431,-0.133299144797457,-0.191326269381454,-0.173218514192121,0.445737481370508,-0.375284600509443,0.0922247152878623,-0.678177960040092,-0.567473729450764,0.931354552357145,-0.540723636557433,-0.325488273738779,0.170828834405191,-0.381869238760109,-0.474054174269437,0.278240745869185,-0.441130983016106,-1.25433380697339,-1.14609881572806,-0.514385083554768,-0.852670873682748,0.52393006059717,-0.644431689005427,0.110744010367861,0.095517034413196,-0.790528350192084,-0.30943821800278,-0.389276956792108,-1.31729941024539,-0.850613174229415,-0.133299144797457,-1.19219128348273,-1.54076557087737,-0.186387790693454,-0.5361966977601,-0.0682758420721278,-0.581877625624097,-0.661716364413426,-0.689701076978758,-0.173218514192121,-0.871601708653413,-0.641962449661427,-1.81032419926402,-1.79550876320002,-0.712747310856089,0.158071097794525,0.112390169930528,-0.291742002704115,-0.0904989961681267,-0.19667628796012,-1.09712556873873,-1.07490241464273,-1.27244156216272,-0.949794287880075,-0.965432803725407,-0.842793916306748,-0.437015584109439,-1.35639569985872,-0.389688496682775,-1.08231013267473,-1.1209948823974,-1.34610720259205,0.181940411453191,-0.718097329434756,-0.0242410737707973,-0.876540187341413,-1.81279343860802],"y":[-0.277964989836072,-0.540885841500442,-0.743094053753764,-0.79251715277846,-0.914695067626311,-0.286996622145153,-0.51793044271486,-0.906039753330108,-0.880951885804882,-0.866526361977877,-0.733058906743674,-1.10521233361288,-0.855362260929151,-0.977916493789881,-0.737574722898215,-0.362761982071336,-0.841438494452651,-0.648638232521288,2.81235853192128,-0.655662835428351,-0.0343617961661264,-0.690911289301294,-0.251246410921706,-0.626059151748585,-0.538000736735041,0.352493121072861,-0.593194045290538,-0.359375119955431,0.136235703005411,-0.724779910460349,-0.704835055777794,-0.615396808050363,-0.801548785087541,-1.02823021211172,-0.587549275097362,-1.11389273577661,-0.814970794213537,-0.341939052025399,-0.738201919586345,-0.227036618759863,-0.782356566430743,-0.470012615741678,-0.570238646504956,0.222036209941685,2.6530505731361,-0.301547585309785,-0.595577392705435,-0.696430620156844,0.0480518486542413,-0.673349782033636,-0.00475811248635957,-0.0988376157059574,-0.935768876347501,0.31360692640876,-0.755763426854004,-0.218883061814165,-0.663314635023545,-0.674478736072271,-0.532481405879491,-1.11389273577661,-0.859125441057935,-0.499992617434323,-0.831528786780186,-0.648512793183662,0.0213332697398756,-0.0492890773436359,-0.752502004075724,-0.720514972981061,0.543160914264579,4.03915525390484,-0.865271968601616,0.0518150287830253,-0.626560909099089,-0.467880147002034,-0.866526361977877,-1.07513198045013,-0.255511348400995,-0.440283492724285,-0.86966234541853,-0.79640577224487,-0.787499579273415,-0.613766096661224,-0.81747958096606,-1.11389273577661,-1.11389273577661,0.525599406996921,-1.09388516142524,-0.998576352696904,-0.338552189909493,-1.09386007355771,-0.636094298758675,-0.818733974342321,-0.63170392194176,-0.723525517084088,-1.11389273577661,-0.628066181150603,-0.588678229135998,-0.109750838079431,-0.893621258905121,-0.0219433017411394,-0.374804158483445,-0.779095143652464,-0.281477291289604,-0.389606000323328,-0.626184591086211,-0.12793954203522,-0.892115986853607,-0.668081329853338,-0.395877967204635,-1.03056338379157,-0.297909844518627,-0.431753617765708,-0.909050297433135,-1.05158701677771,-0.906666950018239,-0.930500424167204,0.269703158239614,-0.523700652245662,-0.981805113256291,0.827908210675895,-0.524704166946671,-0.507895295704769,-0.569987767829704,0.609643763206428,-0.815472551564042,-0.570991282530713,-0.782983763118874,-0.31271168635851,-0.603103752963003,-0.624679319034697,-0.054181211511055,-1.02294921599766,-0.70433329842729,-0.975533146374984,-0.370162902991278,-1.0952399062716,-0.863390378537224,-0.552049942549168,-0.832281422805943,0.28475587875475,-1.09056101897815,-0.289254530222424,-0.830399832741551,0.0494316813681289,-0.812963764811519,0.594591042691292,-0.368783070277391,-0.341813612687772,-0.776711796237567,-0.95232686891415,-0.98055071988003,-0.958849714470709,-0.803430375151933,-0.800921588399411,-0.257142059790134,-0.825758577249385,-0.694423590754826,-0.866275483302624,-1.09556604854943,-1.06771851559643,-1.07929656645932,-1.05670494175285,-0.915322264314442,-0.932382014231596,-0.605612539715525,-0.942417161241686,-1.11389273577661,-1.05778372005644,-0.973024359622462,1.36353418233947,-0.945553144682339,-0.270187750903252,-0.63722325279731,-0.863766696550102,-0.713364930736371,-0.892492304866486,-1.09449981417961,-0.222395363267696,-1.05109780336097,-1.10167870747195,-1.01660198551378,-0.64500049173013,-0.798914558997393,-0.109499959404179,-0.0574426342893344,-0.436896630608379,-0.611382749246327,-0.664694467737433,-1.01968779321938,-0.535868267995397,-0.789381169337807,-0.967003271416408,-1.00970282194434,-0.548788519770888,0.178132441772539,0.0907012234471257,-0.925482850662158,-0.521693622843644,-0.773952130809793,-1.09891527886405,-0.694423590754826,-0.776711796237567,-0.378567338612229,-0.840309540414016,-0.562963164922641,-0.688277063211145,-0.793269788804217,-0.279595701225212,1.74612416209917,-0.954459337653794,-0.580900990203178,-0.122921968530175,-0.669084844554347,-0.117528077012251,-0.374804158483445,-0.477037218648741,-0.256013105751499,-0.857369290331169,0.149281394118529,-0.872672889521557,-1.11389273577661,-0.513916383910824,-0.77758987160095,-0.0376232189444058,-0.186896030719501,-0.77370125213454,-0.756014305529256,-0.78699782192291,-0.604985343027394,-0.70044467896088,-0.849341172723097,-0.493720650553017,-0.423976378832888,-0.34545135347893,-0.711107022659101,-0.764795059163085,-0.731804513367413,-0.645376809743009,-0.253504318998977,-0.793395228141843,-0.857118411655917,-0.817855898978938,-1.00156180893241,-0.42585796889728,0.704977659802287,-0.223649756643957,0.0974749476789369,-1.00182523154142,-1.08290921938295,-0.319234531915069,-0.66055496959577,-0.942166282566434,-0.938026784424771,-0.142866823212729,-0.694172712079573,-0.88847824606245,-0.670590116605861,-0.945553144682339,-0.852100838150872,0.0723870801537108,-0.981554234581039,-0.863892135887728,-0.43137729975283,-0.603480070975881,-0.00789409592701284,-0.012911669432058,-0.605236221702647,-0.248988502844436,-0.741839660377503,-0.760279243008544,-0.215747078373511,-0.766174891876973,-0.962612894599493,-0.920590716494739,-0.677865598188176,-0.691538485989425,-0.504382994251238,0.153044574247313,0.247124077466911,-0.928367955427559,0.165588508009926,-0.744097568454773,-0.816977823615555,-0.419084244665469,-1.11389273577661,-0.472270523818948,-0.381954200728134,-0.478793369375507,-0.834915648896092,-0.448060731657105,-0.74811162725881,-0.738201919586345,-0.388100728271815,-0.543394628252964,0.380089775350609,0.82289063717085,-0.462611694821736,-0.577137810074394,-0.898889711085419,-0.556314880028456,-1.02391509889738,-0.888101928049571,-0.257894695815891,-0.108245566027917,-0.661182166283901,-0.145375609965252,-0.370288342328904,0.106632019325644,0.376326595221825,-0.0884261506829886,-0.604232707001638,-0.420714956054609,-0.270187750903252,-0.685391958445744,-0.0825305018145605,-0.574252705308993,-0.508647931730526,-0.62718810578722,-0.695928862806339,-1.05033262340145,-0.438401902659893,-0.821619079107722,-0.792140834765581,-0.586922078409232,-0.742843175078512,0.153044574247313,-0.639606600212207,-0.451322154435384,-0.587047517746858,-0.894123016255626,-0.453705501850281,-0.547534126394627,-1.11389273577661,0.0466720159403541,-0.268807918189365,0.151790180871052,-0.59896425482134,-0.739205434287354,-0.651272458611437,-0.740836145676494,-0.986948126098962,-0.567228102401929,-0.820741003744339,-0.919712641131356,-1.11389273577661,-0.508773371068152,-0.863390378537224,-0.612637142622589,-0.336796039182727,-0.361382149357449,-1.05085946861948,-1.11389273577661,0.176878048396278,0.280992698625966,-0.554182411288812,-1.11389273577661,-1.11389273577661],"z":[0.267675704960214,0.566789874669315,0.0123343405743969,-1.25707701380081,-0.155461413164854,-0.498348388197237,-0.00955206208724415,-1.15494046804648,-1.672918664372,0.20566423075223,0.395346387153123,0.0269252756821583,-0.469166517981715,3.39743128557494,0.0597548796746199,1.93104230724497,-0.345143569565747,-1.07833805873074,1.09206353854871,-0.808405759237158,0.329687179168199,-0.334200368234927,2.15720180141526,-0.341495835788806,0.110823152551784,0.475596530245809,0.975336057686622,0.431823724922525,1.11030220743341,-0.461871050427834,-1.55254344973297,-0.633314537944026,0.322391711614318,-1.68386186570282,-0.69897374592895,0.431823724922525,-0.264893426473062,0.486539731576629,1.47872331890438,-0.0387339323027659,-0.764632953913875,-1.184122338262,-0.830292161898799,-0.279484361580823,-0.39256410866597,0.402641854707004,-0.593189466397684,-0.450927849097014,-1.84800988566513,-0.52753025841276,0.161891425428947,-1.42122503376312,-0.720860148590592,0.690812823085283,0.249437036075513,0.0159820743513378,-1.72398693724916,-0.283132095357763,-0.148165945610973,0.333334912945139,-0.607780401505444,-0.122631809172391,-1.50512291063274,0.668926420423641,-0.24665475758836,-0.319609433127165,-1.23519061113917,2.65694132885607,1.49696198778908,2.6861231990716,0.0670503472285006,0.0378684770129789,0.577733076000134,0.118118620105665,-0.808405759237158,-1.34827035822431,0.661630952869761,-0.950667376537828,-1.08198579250768,-1.57078211861767,-0.115336341618511,0.537608004453792,-0.895951369883724,0.424528257368645,-0.326904900681046,-0.520234790858879,-1.51971384574051,-1.26072474757775,-2.35139714688288,-0.39621184244291,-1.07833805873074,-0.341495835788806,-0.52753025841276,-0.429041446435373,-0.578598531289922,0.0634026134515608,0.610562679992597,0.413585056037824,0.446414660030286,0.140005022767306,-1.65103226171035,-1.01632658452275,0.566789874669315,0.555846673338493,-1.64738452793341,0.548551205784614,0.35886904938372,-1.15129273426954,0.96074512257886,-0.08615447140299,0.253084769852453,-1.08563352628462,0.209311964529171,0.121766353882604,-0.950667376537828,-1.0746903249538,-1.71304373591834,-0.345143569565747,-0.968906045422529,0.884142713263116,-0.140870478057093,-0.272188894026942,-1.184122338262,-0.786519356575517,0.311448510283497,0.260380237406334,0.081641282336262,0.402641854707004,-0.644257739274847,0.723642427077745,-0.523882524635819,-1.10751992894626,-0.155461413164854,0.982631525240502,0.741881095962446,0.519369335569091,-0.870417233445142,1.08841580477177,1.05558620077931,-1.38474769599372,-0.418098245104552,-0.815701226791039,-1.73128240480304,2.85756668658779,0.734585628408566,-0.356086770896568,0.245789302298573,-0.297723030465523,0.231198367190812,-0.633314537944026,-0.801110291683277,-1.32273622178573,-0.644257739274847,-0.425393712658432,-0.111688607841571,-1.2023610071467,-1.46135010530946,0.450062393807227,-0.655200940605667,-0.08615447140299,-1.62914585904871,-1.30814528667797,0.453710127584167,-0.655200940605667,-0.768280687690815,0.0779935485593212,1.2817456949496,-2.17630592558975,-0.505643855751117,1.89091723569862,-1.23883834491611,-0.2503024913653,-0.97984924675335,-0.633314537944026,-0.38162090733515,-1.59996398883319,-1.56713438484073,-0.184643283380376,0.468301062691927,-0.140870478057093,-0.99444018186111,-0.582246265066862,0.285914373844915,0.366164516937601,0.818483505278191,-0.129927276726272,0.719994693300804,-0.651553206828727,-0.936076441430067,-1.06009938984603,-0.647905473051787,2.36147489292391,-0.512939323304998,-0.443632381543134,-1.01632658452275,0.81483577150125,-1.41392956620924,0.431823724922525,-1.11481539650014,-1.03456525340745,0.0123343405743969,-0.191938750934257,-1.15494046804648,-0.589541732620743,-0.425393712658432,-0.330552634457986,0.220255165859991,0.650687751538939,1.37293903937311,-1.42487276754006,-0.0715635362952286,0.752824297293267,0.698108290639163,-2.22007873091303,-0.118984075395452,-0.709916947259771,-0.604132667728504,-0.746394285029173,-0.0059043283103033,-0.0423816660797068,0.632449082654239,0.457357861361107,-0.622371336613206,-0.0204952634180647,-0.866769499668201,-1.00903111696887,0.129061821436485,-0.768280687690815,0.227550633413872,-0.279484361580823,-0.877712700999023,-1.18777007203894,-0.279484361580823,-0.84488309700656,0.563142140892374,-0.768280687690815,-0.356086770896568,-1.96108963275027,0.482891997799688,0.756472031070207,0.778358433731849,-0.83393989567574,-0.717212414813652,0.80024483639349,1.0008701941252,0.271323438737154,0.132709555213425,2.64964586130219,-0.662496408159548,0.413585056037824,0.745528829739386,-1.09657672761544,-1.28625888401633,-0.00225659453336345,-0.870417233445142,0.180130094313648,-0.356086770896568,-0.936076441430067,-0.812053493014098,-1.17682687070812,-1.4832365079711,2.04412205433011,0.0305730094590982,0.296857575175736,-1.23519061113917,-1.68750959947976,-0.717212414813652,-0.589541732620743,-0.0460293998566466,-1.59266852127931,-0.0460293998566466,-0.702621479705891,-0.52753025841276,-0.695326012152011,-0.38162090733515,-1.07833805873074,-1.30449755290103,-0.768280687690815,-0.910542304991485,-0.480109719312535,0.530312536899912,1.55532572822012,0.154595957875067,-0.454575582873955,-0.403507309996791,0.180130094313648,-0.388916374889029,-1.11481539650014,0.00503887302051623,-0.118984075395452,-1.26802021513163,-0.8485308307835,-0.118984075395452,-0.290427562911643,-0.10074540651075,0.986279259017442,-1.46864557286334,0.150948224098126,-0.976201512976409,-2.15806725670505,-0.724507882367532,-0.359734504673508,-1.184122338262,-0.622371336613206,-1.04186072096133,-0.523882524635819,0.479244264022748,2.06600845699176,0.895085914593936,1.13948407764893,0.519369335569091,-0.367029972227388,-1.14034953293872,-0.556712128628281,-0.264893426473062,0.420880523591705,-0.374325439781269,1.12489314254117,1.40576864336557,-0.636962271720966,-0.356086770896568,-1.54889571595603,-0.487405186866416,-0.323257166904105,-0.447280115320074,0.599619478661776,-0.564007596182162,-0.779223889021636,0.172834626759768,-0.658848674382608,-0.702621479705891,1.16501821408751,0.212959698306111,0.822131239055131,0.0232775419052175,0.220255165859991,0.103527684997903,-0.669791875713429,-0.69897374592895,-0.53847345974358,0.267675704960214,-0.520234790858879,-0.84488309700656,0.599619478661776,-0.549416661074401,0.79659710261655,-0.99444018186111,-0.436336913989253,-0.895951369883724,-0.797462557906337,-0.0752112700721684,-0.253950225142241,-1.30449755290103,-1.54524798217909,-1.00173564941499,-2.74170466101549,-0.819348960567978],"opacity":0.4,"type":"scatter3d","mode":"markers","name":"B","marker":{"color":"rgba(230,159,0,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(230,159,0,1)"}},"textfont":{"color":"rgba(230,159,0,1)","size":55},"error_y":{"color":"rgba(230,159,0,1)","width":55},"error_x":{"color":"rgba(230,159,0,1)","width":55},"line":{"color":"rgba(230,159,0,1)","width":55},"frame":null},{"x":[1.26881726270379,1.6844725522771,1.56512598398377,-0.592166122890763,1.77501132822376,-0.386807717448109,1.13712449769047,-0.0728027808694608,-0.183918551349454,-0.329192132754779,0.441622082463842,0.478660672623839,1.66389555774377,0.482776071530506,0.0671207819571972,0.195932767735857,0.114036329493194,0.663853623423828,1.56512598398377,0.433391284650509,1.86143470526376,0.74204620265049,0.988970137050476,0.223917480301188,1.24000947035713,0.429275885743843,0.947816147983811,1.35112524083712,-0.57776222671743,0.85727737203715,1.47870260694378,0.618584235450498,0.746161601557157,0.0683554016291971,0.146959520746526,-0.146879961189456,-0.238241816917451,-0.825920780789416,1.49516420257045,-0.191326269381454,-0.269518848608116,1.30585585286379,-0.246472614730784,1.16593229003713,0.217744381941189,1.37993303318379,0.147371060637192,0.183175031125191,-0.381869238760109,0.223505940410522,1.30174045395712,0.91489295673048,-0.0633373633841279,0.499237667157171,1.16181689113047,2.12893563419707,3.27301653025034,1.52808739382378,1.19885548129046,0.0938708748505291,1.23589407145046,0.338737109797181,0.342852508703847,1.66389555774377,0.103336292335862,-0.161283857362789,-0.195853208178787,2.50343693470372,0.274536886853185,0.565084049663834,0.91489295673048,1.21120167801046,3.05490038819702,-0.173218514192121,1.29350965614379,1.58158757961044,0.400468093397178,0.585661044197166,1.16181689113047,-0.421788608154773,0.200871246423856,0.540391656223836,-0.534138998306767,1.04658572174381,1.41285622443712,1.59393377633044,2.47462914235705,0.713238410303825,0.993085535957142,-0.252234173200117,0.433391284650509,0.713238410303825,3.70924881435698,2.08778164513041,0.379891098863845,0.286060003791851,1.0959705086238,0.098809353538529,-0.445246381922772,0.346967907610514,-0.0551065655707955,1.04658572174381,1.46224101131711,0.103747832226528,0.951931546890478,2.75447626801037,-0.0168333557387975,0.280298445322518,0.729700005930491,1.7585497325971,3.97263434438363,0.927239153450479,0.0370783699385327,-0.0415257491787964,1.55277978726377,1.48281800585045,0.437506683557175,-0.276103486858782,0.881969765477149,1.7462035358771,2.53224472705038,1.66801095665044,0.881969765477149,1.52808739382378,1.93139648667709,1.59393377633044,0.865508169850483,1.42108702225045,-0.0221833743174637,1.71328034462377,0.462199076997174,0.750277000463823,0.482776071530506,1.6844725522771,0.783200191717155,0.923123754543813,0.330506311983848,0.807892585157153,1.79970372166376,2.27708999483707,0.956046945797144,1.19062468347713,1.40874082553045,1.44989481459711,0.692661415770493,-0.698343414682757,1.54454898945044,1.7585497325971,1.10008590753047,1.6103953719571,1.80793451947709,0.614468836543832,0.63916122998383,0.569199448570501,0.816123382970486,1.27293266161046,2.59809110955705,1.56101058507711,0.622699634357164,3.38413230073033,0.24819833385052,1.7215111424371,1.71739574353043,2.01370446481041,2.2729745959304,0.700892213583826,2.03016606043708,1.76266513150376,-0.768305196096086,0.0823477579118631,1.51985659601044,0.429275885743843,2.15774342654374,1.33466364521046,1.06304731737047,0.195109687954523,0.449852880277175,0.416929689023843,1.7215111424371,1.30585585286379,-0.0349411109281297,0.840815776410485,1.05070112065047,1.04247032283714,1.89847329542375,1.47047180913045,0.791430989530488,3.90678796187697,1.11243210425047,0.733815404837157,1.48693340475711,0.622699634357164,1.08773971081047,1.2070862791038,1.88612709870376,0.0148552158425338,2.47462914235705,0.486891470437172,-0.137003003813457,0.217744381941189,1.18650928457046,1.58570297851711,3.02609259585035,1.7585497325971,1.88612709870376,0.0741169600985301,0.470429874810507,2.10012784185041,2.05897385278374,1.61451077086377,0.672084421237161,1.98078127355708],"y":[2.65054178638357,-0.0238248918055313,1.36227978896321,1.91421287451819,1.36980614922078,0.865540011963735,0.299808599269886,0.060972100429733,1.21802455069316,1.73734340846534,-0.700068360948002,0.134730430953898,1.47642958620299,0.13272340155188,1.55545636890745,0.942058007915674,-0.186268834031371,1.04617265814536,0.741355067713865,1.49148230671813,0.262176797982046,0.799057163021885,1.68215009990984,0.673617825395755,0.75515339485274,0.997251316471172,0.124820723281433,1.79504550377336,0.413958396509665,1.91797605464697,0.964637088688378,0.584555895681202,0.577029535423634,0.540652127512056,-0.813089204149145,0.219527423189162,-0.72377639575934,0.195693949040197,1.52911410800597,0.121308421827902,-0.0778892463223937,1.36227978896321,0.423993543519755,1.10889232695843,-0.454959895226542,0.545669701017102,0.508037899729262,1.56423712254128,0.301062992646147,0.475423671946469,0.240852110585604,1.00854085685752,-0.136845735006675,0.111524153493064,0.998505709847433,3.59509999870834,3.07452674755989,1.31586723404154,0.560722421532237,0.396396889242006,0.727556740574991,0.293536632388579,1.01857600386761,0.723793560446207,0.0637317658575077,-0.03197844875123,1.48395594646056,4.2348406206016,1.006032070105,1.56172833578876,-0.199063646469236,0.713758413436117,4.23985819410665,-0.450945836422506,0.0490553633552505,2.07853840680842,0.725047953822468,0.194439555663936,0.33242282705268,-0.522948016219905,0.816618670289544,0.0711326867774495,0.9671458754409,1.21300697718812,0.382598562103132,2.03212585188675,0.546924094393363,-0.0574426342893344,1.59434256357155,-0.379069095962733,1.43503460478637,1.13523458785992,2.4874706474696,2.00578359098526,-0.286871182807527,-0.439656296036154,-0.0891787867087455,1.37106054259704,0.247124077466911,1.01481282373883,0.623442090345303,0.269703158239614,0.283501485378489,0.366291448211735,0.185658802030107,3.30533512879198,0.840452144438508,-0.16682573669932,-0.242089339274999,0.943312401291935,2.90142046163583,0.99599692309491,0.28475587875475,0.128082146059713,0.481695638827775,0.322387680042589,0.324896466795112,1.01230403698631,1.28199861288249,0.835434570933463,1.33217434793294,0.0203297550388666,0.663582678385664,1.45635929218281,2.28802210064406,1.91797605464697,0.474169278570207,0.615915730087735,0.114032940245586,1.12394504747356,1.95686224931107,2.8700606272293,1.08255006605694,0.791530802764318,-0.751247610699463,0.102492521183982,-0.585918563708223,0.022713102453763,0.600863009572599,1.63950072511696,-0.399013950645288,-0.107869248015039,1.29579694002136,0.925750894024277,1.32966556118042,-0.777088114250446,1.64200951186948,1.74988734222796,0.30357177939867,0.334931613805202,2.10362627433364,0.740100674337604,1.14276094811748,0.396396889242006,0.777732475625443,0.215764243060378,1.78124717663449,1.22304212419821,2.54140956264884,3.11090415547147,0.435283083906107,0.115287333621847,0.944566794668197,0.351238727696599,1.95686224931107,1.15781366863262,1.30959526716024,0.801565949774408,1.00477767672874,-0.0614566930933706,1.21426137056438,1.25816513873352,2.41095265151766,2.8863677411207,0.392633709113222,-0.526083999660558,0.795293982893102,2.31436436154554,1.56172833578876,0.885610305983915,0.298554205893624,0.396396889242006,0.253396044348217,1.01606721711509,0.858013651706167,0.962128301935855,0.149281394118529,3.44582718693324,1.56549151591754,1.69093085354367,1.7160187210689,-0.656164592778856,0.353747514449122,0.756407788229001,1.63071997148313,0.588319075809986,0.988470562837343,1.43252581803385,0.698705692920981,-0.174853854307393,0.854250471577383,0.656056318128097,1.78375596338701,0.796548376269363,1.50151745372822,0.721284773693685,2.08481037368972,2.86755184047678,1.94557270892472,0.692433726039675,0.046546576602728,3.29404558840562],"z":[2.2155655418463,0.00139113924357639,0.938858719917219,2.86486215414167,-0.00955206208724415,1.00451792790214,-0.0642680687413479,1.40212090958863,1.96387191123743,0.79659710261655,-1.03456525340745,0.110823152551784,2.13531539875362,0.129061821436485,0.938858719917219,1.79242842372124,-0.822996694344919,1.28539342872654,-0.83758762945268,2.58763438709421,-0.155461413164854,0.668926420423641,4.4808082173262,1.60639400109728,-0.418098245104552,0.417232789814764,-0.264893426473062,1.35470037048841,1.78513295616736,1.59180306598952,0.150948224098126,0.679869621754462,0.307800776506557,0.267675704960214,-0.899599103660664,-0.334200368234927,-0.10074540651075,0.304153042729617,1.81796256015982,0.592324011107896,-0.23935929003448,0.3479258480529,1.15407501275669,1.02275659678684,-0.713564681036712,0.384403185822302,0.785653901285729,0.50113066668439,0.340630380499019,0.515721601792151,-0.83758762945268,0.420880523591705,-0.545768927297461,-0.0496771336335875,1.24162062340326,3.99201189121621,0.0634026134515608,-0.647905473051787,1.16866594786445,0.96074512257886,0.515721601792151,-0.345143569565747,0.158243691652007,1.03369979811767,0.245789302298573,-0.739098817475294,0.413585056037824,2.71530506928712,1.25985929228796,1.03734753189461,1.15772274653363,0.563142140892374,3.0764307132042,-0.184643283380376,0.490187465353569,1.42400731225027,0.435471458699465,1.27080249361878,-0.436336913989253,-0.826644428121859,0.530312536899912,0.180130094313648,3.16032859007383,0.581380809777075,-0.257597958919181,0.785653901285729,-0.0387339323027659,0.296857575175736,-0.998087915638051,-0.779223889021636,0.563142140892374,-0.0642680687413479,-0.0423816660797068,2.12801993119974,-0.706269213482831,-0.308666231796345,-0.695326012152011,2.0878948596534,0.479244264022748,-0.272188894026942,0.081641282336262,-0.151813679387914,-0.162756880718735,0.50477840046133,-1.11481539650014,1.41671184469639,1.60274626732034,-0.793814824129397,0.782006167508789,-0.170052348272615,-0.596837200174624,-1.83706668433431,1.5443825268893,1.07382486966401,1.03005206434073,-1.39933863110148,0.450062393807227,1.13583634387199,1.16501821408751,-1.32638395556267,0.35522131560678,-1.25707701380081,-0.00955206208724415,0.606914946215657,1.43495051358109,-0.286779829134703,0.00503887302051623,-0.129927276726272,0.35157358182984,0.296857575175736,2.13896313253056,2.49279330889376,1.0191088630099,0.00868660679745709,-0.903246837437604,1.08112033721789,-0.965258311645588,0.20201649697529,-0.155461413164854,-0.330552634457986,-0.998087915638051,-0.954315110314768,0.329687179168199,0.296857575175736,0.234846100967752,-0.702621479705891,-0.0715635362952286,1.59545079976646,-0.0168475296411249,0.424528257368645,2.76272560838734,0.49748293290745,0.209311964529171,-0.108040874064631,-0.308666231796345,0.515721601792151,-0.0533248674105273,0.986279259017442,2.05506525566093,0.526664803122971,-0.600484933951563,-0.706269213482831,0.231198367190812,-0.345143569565747,0.0451639445668596,1.32551850027289,0.588676277330956,-0.877712700999023,1.40212090958863,-0.673439609490368,0.647040017761999,0.428175991145585,1.27809796117266,1.09935900610259,0.65798321909282,0.147300490321186,0.997222460348263,0.836722174162893,-0.319609433127165,0.479244264022748,-0.520234790858879,-1.25707701380081,-0.334200368234927,-0.359734504673508,-0.939724175207006,-0.54212119352052,-0.0679158025182887,0.909676849701697,-0.421745978881492,1.23797288962632,0.0415162107899187,0.125414087659544,1.11030220743341,0.0743458147823814,0.132709555213425,1.69029187796691,-1.11846313027708,-0.0168475296411249,1.11030220743341,-0.914190038768425,0.176482360536709,-0.0350861985258261,0.65433548531588,1.29268889628042,1.15042727897975,0.417232789814764,1.15407501275669,1.23067742207244,-0.312313965573285,-0.217472887372838,-0.808405759237158,2.13531539875362],"opacity":0.4,"type":"scatter3d","mode":"markers","name":"M","marker":{"color":"rgba(86,180,233,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(86,180,233,1)"}},"textfont":{"color":"rgba(86,180,233,1)","size":55},"error_y":{"color":"rgba(86,180,233,1)","width":55},"error_x":{"color":"rgba(86,180,233,1)","width":55},"line":{"color":"rgba(86,180,233,1)","width":55},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p><em>Click and drag the plot above to rotate it, and scroll to zoom. Note that in general we recommend against using 3D visualizations; here we show the data in 3D only to illustrate what “higher dimensions” look like for learning purposes.</em></p>
=======
<div id="htmlwidget-61b4c2fca97548c6f1b1" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-61b4c2fca97548c6f1b1">{"x":{"visdat":{"f83cf7568d":["function () ","plotlyVisDat"]},"cur_data":"f83cf7568d","attrs":{"f83cf7568d":{"x":{},"y":{},"z":{},"opacity":0.4,"color":{},"size":150,"colors":["#E69F00","#56B4E9"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Perimeter"},"yaxis":{"title":"Concavity"},"zaxis":{"title":"Symmetry"}},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[-0.22501906532072,-0.332451412882306,-1.25381027174843,-0.678556178018386,-1.4880187413633,-0.517258858410686,-0.245850822465626,-0.722600464553329,-0.332749009412948,-0.702066303939065,-0.757419258638386,-0.506545383307591,-1.40945325727394,-1.11304711275499,-1.34517240665537,-1.24012083133892,-1.19726693092654,-0.870803536812803,-1.24279920011469,-0.642546997810762,-1.3302925801233,-0.522317999431592,-0.473214571875742,-0.457739552282383,-0.676473002303895,-0.31548841063574,-0.579754129845403,-0.470238606569327,0.0636495694015471,-0.129788175515436,-0.0821727306127943,-0.287811933286079,-0.747598573127216,-1.14429474847235,-0.723195657614613,-1.69187236485274,-0.674985019650687,-1.0428143315236,-0.983295025395294,-0.647308542301027,-0.645820559647819,-0.692543214958537,-1.05888454417824,-0.543447353107139,-0.00777359795241612,-1.03091047029794,-1.27315404624013,-0.586896446580799,-1.30708005073326,-0.699983128224575,-0.132764140821852,-0.454465990445327,-0.20716327348223,-0.0405092163229823,-0.472619378814459,0.209471869415888,-0.627964767809328,-0.813367406398991,-0.914550226817105,-1.21214675745862,-0.732123553533858,-0.300310987573023,-0.877053063956274,-0.624988802502913,-0.00479763264600116,0.0398418469502257,-0.29971579451174,-0.489284784530384,-1.4636158258507,-1.0779307221393,-0.922882929675067,-0.285431161040947,-0.614870520461102,0.388029787800796,-0.689864846182763,-0.868720361098312,-0.546125721882913,-0.592253184132347,-0.147643967353927,-0.999960431111219,-0.0791967653063793,-0.603859448827366,-1.04906385866707,-1.01364987152073,-1.45528312299273,-1.01751862641907,-0.567850268619743,-0.611894555154687,-0.837472725380953,-0.948476231310237,-0.679746564140951,-0.824080881502085,-0.613382537807894,-0.542256966984573,-1.33951807257319,-0.489582381061025,-0.449704445955062,-0.333641799004873,-1.19577894827333,-0.231566188994833,0.191616077577397,-0.655938841689631,-0.626774381686762,-0.948178634779596,-0.224721468790079,-0.183355551030909,-1.05114703438156,-0.25061236695589,0.0934092224656983,-1.00561476519341,0.206495904109473,-0.493748732490006,-0.816640968236048,-0.857709289464576,-1.2356568833793,-0.267575369202457,-0.141692036741097,-0.391375525949326,-0.696709566387518,-0.598205114745177,-0.275610475529777,-0.999365238049936,-0.564874303313328,-0.0672929040807186,-0.871398729874086,-0.785095735988047,-0.718434113124348,-0.86247083395484,-0.285728757571589,-0.535412246779818,-0.915145419878388,-0.381554840438156,-0.862768430485482,-1.16572169867854,-0.827354443339142,-0.889552118243218,-0.2485291912414,-0.264599403896041,-0.671413861282989,-0.450597235546987,-0.645820559647819,-0.448216463301855,-0.591062798009781,-0.862768430485482,-0.832413584360047,-0.165499759192418,0.0547216734823014,-0.549101687189328,-0.681829739855442,-0.557136793516648,-0.389589946765477,-1.03686240091077,-0.0434851816293977,-1.1059047960196,-0.569338251272951,-1.08626342499726,-0.731230763941933,-0.76991831292533,-0.454168393914685,-1.37969360420979,-0.350604801251439,-0.395839473908949,-0.783905349865481,-0.105980453064115,-0.452978007792119,-0.774679857415594,-1.50617212973243,-0.677960984957102,-0.763668785781858,-1.14994908255454,-0.758907241291594,-1.06334849213786,-0.430360671463364,-0.48065448514178,-0.552375249026384,-0.263706614304117,-0.729742781288726,-0.239601295322155,-0.903241558652728,-0.749384152311066,-0.676473002303895,-0.591657991071064,-1.04995664825899,0.12316887552985,-1.07168119499582,-0.818426547419896,-0.687484073937631,-1.08239467009892,-0.616656099644951,0.206495904109473,-0.82110491619567,-0.719326902716273,-0.703851883122914,-0.822592898848877,-0.542852160045856,-0.388101964112269,-0.313107638390608,-1.24964392031945,-0.936572370084577,-0.608323396786989,-0.426194320034383,-0.578563743722837,0.295774863301927,-0.401791404521779,-0.399113035746005,-0.0821727306127943,-0.241089277975362,0.173760285738906,-0.915145419878388,-0.302096566756872,-0.276800861652344,-0.664569141078234,-0.819319337011821,-0.592253184132347,-0.358044714517476,-0.317571586350231,-0.583622884743743,-0.226209451443286,-0.819319337011821,-1.0127570819288,-1.28714108318028,-0.56338632066012,-0.322630727371136,-0.295549443082759,-0.492260749836799,-0.78777410476382,-0.632726312299593,-0.583920481274384,-0.325904289208193,-0.522913192492874,-0.688972056590838,-0.729147588227443,0.25708731431853,-0.465179465548421,-0.543447353107139,-0.660402789649253,-0.813367406398991,-1.20976598521349,0.087457291852868,-0.65980759658797,-1.14667552071748,-0.569635847803592,-0.833306373951972,-0.619929661482007,0.203519938803058,-0.753848100270688,-0.174427655111663,-1.05561098234118,-1.11126153357114,-0.769323119864047,-0.701471110877782,-0.979426270496955,-0.547316108005478,-0.525293964738006,-0.147643967353927,-0.36072308329325,-0.180379585724493,-0.189307481643739,-0.31935716553408,-0.509521348614006,-0.278586440836192,-1.12822453581771,-0.677960984957102,-0.0405092163229823,0.0249620204181501,-0.706827848429329,-0.660402789649253,-0.123836244902606,-0.465477062079062,-0.314595621043816,-0.631535926177026,-0.475297747590232,-0.482142467794987,-1.16750727786239,-0.204187308175814,-0.731528360472575,-0.361913469415816,0.230303626560794,-0.189307481643739,-1.0758475464248,-0.569040654742309,-1.08269226662956,-0.595824342500045,0.14102466736834,-0.660105193118612,-0.788071701294462,-0.417861617176421,0.144000632674755,-0.180379585724493,-0.750574538433631,-0.548506494128045,-0.0851486959192092,-0.36667501390608,-0.341676905332193,0.155904493900416,-0.280967213081325,-0.0375332510165674,-0.615763310053027,-0.432146250647213,0.590395428637024,-0.71486295475665,-0.356259135333627,-0.100028522451285,-0.356259135333627,-0.429765478402081,0.0725774653207924,-0.612787344746611,-1.13715243173696,-1.12465337745001,-0.658617210465404,-0.927942070695973,0.0755534306272073,-0.774084664354311,-0.165499759192418,0.0368658816438108,-0.836579935789029,-0.236625330015739,-0.405660159420119,-1.17316161194458,-0.919014174776728,-0.233054171648041,-0.980319060088879,-1.30827043685583,-0.159547828579587,-0.596419535561328,-0.379174068193024,-0.605347431480573,-0.557731986577932,-0.602966659235441,-0.168475724498833,-0.91752619212352,-0.629155153931894,-1.49069711013907,-1.570452980351,-0.847591007422765,0.185664146964567,0.00413026327324455,-0.439883760443892,-0.24079168144472,-0.288109529816721,-1.07554994989416,-1.07674033601673,-1.13566444908375,-0.69522158373431,-0.987461376824276,-0.876755467425633,-0.570231040864875,-1.32136468420405,-0.548208897597403,-1.1216774121436,-1.17197122582201,-1.21303954705054,-0.0405092163229823,-0.743432221698235,-0.210139238788645,-0.954428161923068,-1.43147540054141],"y":[-0.159082553609287,-0.398747849778323,-0.879660233071109,-1.07302219402029,-0.974903221768684,0.15727563733384,-0.210850257581799,-1.03994838314896,-0.801385547342302,-0.86355472516855,-0.869642223691244,-1.29583901986864,-0.74482453744641,-1.20076379687838,-0.873237203133779,-0.635057831800992,-0.853536715788685,-0.612529293961102,4.69653634677537,-0.806658183858021,-0.617322599884483,-0.488382670545542,-0.895382276499798,-0.474961413960076,-0.463457479743962,1.02390534828107,-0.21804021646687,-0.137992007546412,-0.0565058068489398,-0.864225787997823,-0.657586369640881,-0.642727121278401,-1.06597603431292,-1.20646783092721,-0.383409270823504,-1.30468266929728,-0.755849141070186,-0.0373325831554169,-0.92184132519686,0.0724341224900012,-0.376219311938433,0.190828778797505,-0.681552899257785,-0.242486076676112,1.94661673853186,-0.683949552219475,-0.127446734514974,-0.584248789013156,-0.564596234727295,-0.297129764202652,-0.077596352911815,0.280942930157062,-0.915705893614932,-0.365194708314658,-0.829426386994079,-0.485506686991514,-0.803302869711655,-0.634099170616315,-0.889150978799403,-1.30468266929728,-0.935214648723092,-0.302881731310708,-0.837095676471489,-0.853153251314814,-0.106356188452099,0.182680158727758,-0.555009622880534,-0.915849692792634,1.27459524807388,2.63349747735232,-0.963591019789506,0.137623083047979,-0.373343328384405,-0.402582494517027,-0.890732769754119,-1.2158147774778,-0.36711203068401,-0.495572629430613,-0.933201460235272,-0.802823539119316,-0.986023691510927,-0.709354073613393,-1.11592228203454,-1.30468266929728,-1.30468266929728,0.366263775593239,-1.26644646794647,-1.17248329193044,-0.514745853124136,-1.27151299230748,-0.575620838351071,-0.882727948862073,-0.622595236400202,-1.05610182411075,-1.30468266929728,-0.45914350441292,-0.644644443647753,-0.0243906571622891,-1.00687457227763,0.210960663675704,0.11509454520809,-0.599587367967974,0.0403189728033505,-0.38197127904649,-0.46154015737461,-0.0694477328420679,-0.989666604012697,-0.448598231381482,-0.522415142601545,-1.17818732597926,0.326000005836841,0.569979277336919,-0.782691654241118,-1.19357383799331,-0.961434032123984,-1.00601177721142,0.163986265626573,-0.569868871243014,-1.00543658050062,2.25961961532862,-0.653272394309838,-0.738593239746015,-0.20318096810439,2.399104817699,-0.765435752916947,-0.439970280719397,-0.91618522420727,-0.386285254377533,-0.60821531863006,-0.349856129359839,-0.0900589483126048,-1.11937346229938,-0.693536164066236,-1.11088931081499,-0.961817496597855,-1.28093183844693,-0.796592241418922,-0.606777326853045,-0.981853515357586,0.298198831481233,-1.27794081555074,-0.171065818417739,-0.736196586784325,-0.563637573542619,-0.943794666325943,-0.240568754306759,-0.439970280719397,-0.23050281186766,-0.673883609780375,-1.05384897032676,-1.12579649223671,-1.16644372646698,-0.554530292288196,-1.10537700900311,-0.39203722148559,-0.90094251137092,-0.717023363090802,-0.957695253503747,-1.25099764295541,-1.23412520610511,-1.23858298061386,-1.21725276925481,-0.925292505461694,-1.07719237017363,-0.456746851451229,-0.905687884235067,-1.30468266929728,-1.21178840050216,-1.10739019749093,0.904552030788892,-1.19745641579125,-0.394913205039618,-0.446201578419792,-0.745303868038748,-0.815765465112445,-1.05030192394346,-1.2676208278977,0.343735237753349,-1.24069203522014,-1.27823320721206,-1.13121292793013,-0.609653310407074,-0.798988894380612,0.49520370493218,0.776091432042289,-0.202701637512052,-0.783650315425794,-0.96138609906475,-1.08869630438974,-0.273642565178086,-0.83383622844359,-1.15503565836933,-1.1586785708711,-0.729006627899254,-0.160041214793963,-0.0713650552114202,-1.05135645124661,-0.852146657070904,-0.756328471662524,-1.28751784078565,-0.723733991383535,-0.703122775912998,-0.507555894239065,-0.650875741348148,-0.148057949985512,-0.651834402532824,-0.659503692010233,-0.291377797094595,1.58568080250129,-0.924381777336251,-0.0732823775807723,-0.227626828313631,-0.560282259396253,0.0911280155911861,0.232051209738579,0.0690788083436348,0.16973823273463,-0.781732993056441,0.143375050156036,-0.891739363998029,-1.30468266929728,-0.536315729779349,-0.899168988179269,0.343255907161011,-0.393475213262604,-0.308154367826427,-0.610132640999412,-0.578976152497437,-0.535836399187011,-0.437094297165368,-1.06880408480771,-0.627867872915921,-0.197429000996333,-0.423673040579902,-0.644644443647753,-0.43661496657303,-0.793236927272555,-0.40929312280976,0.187952795243476,-0.746741859815762,-1.01032575254247,-0.854830908387997,-1.13298645112178,-0.077596352911815,0.238282507438974,-0.201263645735037,0.449667298660063,-1.20474224079479,-1.24548534114352,0.104069941584314,-0.381012617861814,-1.08514925800644,-1.1384028868152,-0.152851255908892,-0.71989934664483,-0.963063756137934,-0.769270397655652,-1.07685683875899,-1.00462171849364,0.986038231486365,-1.13610209997198,-1.11362149519132,-0.533439746225321,-0.317261649080851,0.506707639148294,0.237803176846636,-0.43661496657303,-0.646561766017105,-0.400185841555337,-0.969007455482926,0.0964006521069048,-0.638413145947358,-1.09080535899603,-0.960043973406204,-0.599108037375636,-0.413127767548465,-0.405458478071056,1.83780869407112,0.854222318593395,-0.997479692667807,0.222464597891817,-0.69257750288156,-1.03990045008973,0.205688027159985,-1.30468266929728,0.308264773920332,0.361470469669858,-0.100604221344043,-0.641289129501387,-0.0603404515876445,-0.528167109709602,-0.502762588315684,-0.418879734656522,-0.469688777444357,0.61455702242436,1.04211991078992,-0.136554015769398,-0.590480086713551,-0.71510604072145,-0.802344208526978,-1.22444272813988,-0.93569397931543,-0.489820662322556,0.412279512457694,-0.332600228035669,-0.415045089917817,-0.399227180370661,-0.298567755979666,0.0916073461835241,0.389750974617804,-0.70264344532066,-0.371426006015053,-0.0152833759078657,-0.776939687133061,-0.110190833190804,-0.52624978734025,-0.70743675124404,-0.622595236400202,-0.825543809196141,-1.18326823025804,-0.377177973123109,-0.900415247719348,-0.4639368103363,-0.0325392772320362,-0.446201578419792,-0.557406275842224,-0.527208448524926,-0.649917080163472,0.017311104371123,-0.726609974937563,-0.287063821763552,-0.636016492985668,-1.30468266929728,0.321686030505798,-0.443325594865763,0.63181292374853,-0.532481085040645,-0.795633580234245,-0.644644443647753,-0.80186487793464,-1.09454413761627,-0.450036223158496,-0.85650856546118,-1.00778530040308,-1.30468266929728,-0.555009622880534,-0.889917907747144,-0.921553726841457,-0.135595354584722,-0.346021484621135,-1.2565099447673,-1.30468266929728,0.450625959844739,0.435287380889921,-0.669090303856995,-1.30468266929728,-1.30468266929728],"z":[0.123238094688002,0.457824280674147,-0.728582774948222,-1.47695670785443,0.330131968148034,-0.248524334185492,-0.0480958942710862,-0.756060867517132,-0.896684047134497,-0.187102715502045,0.65502000381574,-0.746362717198693,0.516013182584781,1.06072595880377,0.11515630275597,0.616227402541983,-0.036781385566241,-0.809400694268546,2.14530243608253,-0.836878786837457,-1.04538901868389,-0.45703456603193,-0.308329594482532,-0.196800865820485,-0.224278958389395,1.01223520721158,0.773014166023413,0.11515630275597,0.404484453922732,-0.612204971126954,-1.41230237239817,-0.360053062847541,-1.08903069511687,-1.56262370233397,-0.20811537452533,0.05050196729971,-0.334191328665037,-0.450569132486304,-0.120832021659379,-0.153159189387509,0.132936245006441,-0.11598294650016,-0.594425028876482,-1.09064705350328,-0.812633411041359,-0.836878786837457,0.0408038169812712,-0.7479790755851,-2.01843676730061,0.186276071757855,-0.0190014433157698,-1.37835884628363,-0.86758959617918,-0.502292600851312,0.918486420799998,-0.287316935459248,-1.92145526411622,-0.363285779620353,-1.29107549341768,0.330131968148034,-0.511990751169751,1.04779509171252,-0.971036532909196,-0.280851501913622,-0.0788067036128098,-0.339040403824256,-0.890218613588871,0.477220581311025,0.680881737998243,0.334981043307253,-0.0674921949079647,1.53270260763447,0.343062835239286,-0.604123179194922,-0.625135838218206,-0.263071559663151,0.431962546491643,-1.0227600012742,-0.411776531212548,-1.31047179405456,-0.80293526072292,-0.119215663272972,-1.61434717069898,-0.308329594482532,-0.499059884078499,-0.463499999577556,-0.979118324841228,-1.80669381868135,-1.76143578386197,0.0521183256861163,-0.531387051806629,0.483686014856651,-0.676859306583214,-1.16661589766438,-1.60303266199414,0.199206938849107,-0.376216646711606,0.183043354985042,0.14263439532488,1.98366659744188,-0.938709365181066,-0.591192312103669,0.802108616978731,-0.052944969430306,-0.841727861996676,0.265477632691774,0.249314048827709,-0.638066705309458,0.260628557532555,-0.461883641191149,0.0860618518006526,-0.120832021659379,-0.0836557787720297,0.0165584411851737,-0.232360750321427,-1.09064705350328,-1.63374347133586,-0.599274104035702,0.000394857321108762,0.658252720588552,-0.384298438643638,-0.0286995936342086,-0.216197166457362,-0.423091039917393,0.821504917615608,-0.382682080257231,-0.259838842890337,0.0634328343909615,-0.735048208493847,1.13669480296488,-0.478047225055214,-0.71565190785697,-0.271153351595183,-0.0965866458632811,-1.10034520382172,-0.230744391935021,-0.914463989384968,0.0876782101870589,0.323666534602407,-1.45756040721755,-0.639683063695864,-0.704337399152124,-0.956489307431538,0.0876782101870589,0.591982026745886,-1.01629456772858,0.0989927188919049,0.77463052440982,0.323666534602407,-0.859507804247148,-0.125681096818598,-1.22480479957502,-0.427940115076613,-1.08903069511687,-0.348738554142695,-1.11165971252656,-1.11974150445859,0.554805783858537,-0.403694739280516,0.145867112097693,-1.02437635966061,-1.28299370148565,0.947580871755315,-0.599274104035702,-0.544317918897881,0.790794108273886,0.389937228445074,-1.59010179490288,-0.982351041614041,0.378622719740229,-1.61596352908539,-0.473198149895995,-0.838495145223863,-0.387531155416451,-0.343889478983476,-1.2943082101905,-1.17954676475563,1.12376393587362,0.632390986406048,-0.138611963909851,-0.560481502761946,-0.757677225903538,-0.0109196513837373,0.246081332054896,0.131319886620035,0.646938211883707,-0.219429883230175,-0.754444509130725,-0.0335486687934284,0.33659740169366,-0.0804230619992161,0.360842777489757,-0.274386068367996,-0.524921618261003,-1.26036468407596,0.343062835239286,-0.870822312951993,-0.754444509130725,-0.722117341402595,-1.07933254479843,-0.426323756690207,-0.253373409344712,-0.819098844586985,-0.258222484503931,0.512780465811967,-0.668777514651181,0.68249809638465,0.407717170695546,-0.490978092146467,-0.334191328665037,0.785945033114666,0.71482526411278,0.486918731629464,-1.1472195970275,-0.132146530364225,-0.266304276435963,-0.361669421233947,-0.579877803398824,-1.20217578216532,0.0585837592317425,-0.736664566880254,0.23961589850927,-0.610588612740547,-0.379449363484418,-1.47534034946802,-0.502292600851312,-0.196800865820485,-0.712419191084157,0.495000523561496,0.640472778338081,-0.974269249682009,-1.05023809384311,-0.198417224206891,-0.667161156264775,0.895857403390307,0.116772661142376,0.157181620802539,-0.848193295542302,0.423880754559611,0.281641216555839,-0.0464795358846799,-0.20326629936611,0.121621736301595,0.216986881099579,-0.119215663272972,-0.183869998729232,-0.253373409344712,0.477220581311025,-0.891834971975278,0.192741505303481,0.103841794051124,-0.836878786837457,-1.18924491507407,-0.557248785989133,-0.607355895967734,0.666334512520585,-0.284084218686435,-0.626752196604612,-1.23611930827986,-0.583110520171637,-1.68385058131446,-0.326109536733004,-0.487745375373653,1.13022936941925,-0.694639248833685,-0.962954740977163,-0.733431850107441,-0.476430866668808,0.596831101905106,-1.13913780509547,-0.0270832352478022,-0.73828092526666,-0.961338382590757,-0.93709300679466,-0.898300405520904,0.499849598720716,-1.07609982802562,-0.0901212123176558,-0.545934277284288,0.252546765600522,-0.389147513802857,0.441660696810082,-0.80293526072292,-0.343889478983476,-0.794853468790888,-0.516839826328971,0.17011248789379,-0.592808670490076,-0.358436704461133,0.0650491927773678,-0.799702543950107,-0.880520463270432,0.527327691289626,-0.618670404672579,-0.555632427602727,0.533793124835252,-0.720500983016189,-0.156391906160322,0.322050176216001,-1.80669381868135,-1.00336370063733,-0.345505837369882,-0.859507804247148,0.532176766448846,0.216986881099579,-1.16984861443719,0.410949887468358,0.221835956258799,-0.085272137158436,-0.309945952868939,-0.195184507434077,-0.971036532909196,-0.479663583441621,-0.916080347771375,-0.444103698940678,0.257395840759741,-0.515223467942564,0.275175783010213,1.26115439871818,-0.555632427602727,-0.0836557787720297,-0.644532138855084,0.132936245006441,0.997687981733917,0.338213760080066,-1.19732670700611,-0.193568149047671,-0.68332474012884,0.49338416517509,-0.153159189387509,-0.988816475159668,-0.158008264546728,0.254163123986929,-0.179020923570012,-0.924162139703408,0.462673355833366,-0.288933293845655,-0.691406532060872,-1.05347081061593,-0.418241964758174,-0.355203987688321,-0.339040403824256,-0.563714219534759,0.255779482373335,-0.71565190785697,0.43357890487805,-0.798086185563701,-0.752828150744319,-0.854658729087928,-1.09064705350328,-1.03245815159264,-0.688173815288059,-1.03892358513827,-1.27491190955362,-1.05185445222952,-2.15744358853156,-0.0480958942710862],"opacity":0.4,"type":"scatter3d","mode":"markers","name":"B","marker":{"color":"rgba(230,159,0,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(230,159,0,1)"}},"textfont":{"color":"rgba(230,159,0,1)","size":55},"error_y":{"color":"rgba(230,159,0,1)","width":55},"error_x":{"color":"rgba(230,159,0,1)","width":55},"line":{"color":"rgba(230,159,0,1)","width":55},"frame":null},{"x":[2.30157547982572,1.53377643077062,1.34629061646647,-0.249719577363966,1.33736272054722,-0.11490834898336,1.36712237361137,0.0993611530785282,-0.031581320403737,-0.28602635410223,0.492188573525325,0.870136167440046,1.32248289401514,0.14102466736834,0.0457937775630561,0.50111646944457,0.480284712299665,0.879064063359292,2.36704671656685,0.530876122508722,2.40275830024384,2.07540211653817,1.34331465116005,0.450525059235513,0.971318987858161,1.25105972666118,0.822520722537404,1.58436784097968,0.36124610004306,0.858232306214385,1.61115152873741,0.757049485796271,0.780857208247592,0.266015210237776,-0.348819222067589,0.00115429796682918,-0.141692036741097,-0.596419535561328,2.08730597776383,0.173760285738906,-0.052413077548643,1.28974727564458,-0.132764140821852,0.828472653150234,0.310654689834002,1.87006051039553,0.2511353837057,0.352318204123814,0.13507273675551,0.218399765335133,1.74506996752609,1.31950692870873,0.090433257159283,0.640986838846082,1.2748674491125,1.87601244100836,3.10806207786422,1.01298250214797,1.33736272054722,0.0338899163373958,1.35819447769213,0.00710622857965951,0.48326067760608,1.45342536749741,0.066625534707962,0.0398418469502257,-0.0256293897909067,2.96223977784988,0.590395428637024,0.685626318442309,0.652890700071742,1.13499707971099,2.19146476348836,0.176736251045322,1.21832410829062,1.23320393482269,0.524924191895892,0.667770526603817,1.14094901032382,-0.452978007792119,0.420765406171362,0.646938769458912,-0.456251569629175,0.763001416409102,1.17070866338797,2.01290684510345,2.28967161860006,0.697530179667968,1.42961764504609,0.277919071463436,0.527900157202307,0.48326067760608,3.378874920748,2.0605222900061,0.655866665378157,0.194592042883812,0.950487230713254,-0.0256293897909067,-0.165499759192418,0.337438377591738,0.12912080614268,0.649914734765327,1.75994979405817,0.316606620446833,0.9594151266325,2.07540211653817,0.632058942926836,0.310654689834002,0.676698422523063,1.51889660423854,2.41763812677591,0.391005753107211,0.230303626560794,-0.0851486959192092,1.87601244100836,2.17063300634346,0.554683844960043,-0.0583650081614733,0.780857208247592,1.64983907772081,2.93843205539856,1.62007942465666,1.01000653684156,1.12011725317892,1.7272141756876,1.56353608383477,0.703482110280799,1.66174293894647,0.0249620204181501,2.12301756144081,0.37314996126872,1.08440566950193,0.566587706185703,1.63793521649515,0.62313104700759,0.911799681729858,0.25708731431853,0.989174779696651,3.17650927991177,2.63785955945063,0.828472653150234,0.646938769458912,1.56353608383477,1.34331465116005,0.584443498024194,-0.659510000057329,1.89982016345968,1.53377643077062,1.00107864092231,1.27784341441892,1.89982016345968,0.670746491910233,0.191616077577397,0.507068400057401,1.06952584296986,1.60222363281817,2.83129730436761,1.49806484709364,0.36124610004306,3.63183197179328,0.414813475558532,1.60519959812458,1.5694880144476,2.74499431048158,2.61107587169289,0.655866665378157,1.33438675524081,1.77185365528383,-0.461310710650081,-0.150619932660342,1.03381425929288,1.03679022459929,1.92660385121742,1.25998762258043,0.917751612342688,0.0844813265464526,1.48318502056156,0.539804018427967,1.15285287154948,1.13202111440458,0.197568008190228,0.760025451102687,0.774905277634762,1.13499707971099,1.81351716957364,0.968343022551746,1.33438675524081,4.28356837389819,1.08142970419552,0.441597163316268,1.38795413075628,0.596347359249854,1.07547777358269,1.16475673277514,1.66471890425288,-0.0375332510165674,3.10211014725139,0.310654689834002,0.179712216351737,0.194592042883812,1.03976618990571,1.58436784097968,2.92950415947931,1.33141078993439,1.57543994506043,-0.0881246612256246,0.638010873539666,2.13789738797289,1.75102189813892,1.42068974912684,0.578491567411364,2.30157547982572],"y":[2.10767181755745,-0.146619958208497,0.854222318593395,1.98783916947293,0.612639700055007,1.26213265267309,0.509104292109984,-0.0210353430159227,1.27890922340493,3.99192037603841,-0.605339335076031,0.595863129323175,0.439601356220964,-0.191677033888276,2.02330963330595,2.06309407247001,0.0920866767758621,0.988434884448055,1.27028127274284,1.71749671539426,0.207605349529337,0.945774461729966,0.542178102981311,1.3503294816633,0.347090551899716,1.7318766331644,-0.111628824967818,1.63505185351211,2.02954093100635,1.37381668068786,1.61491996863391,1.22330687469371,1.28801650465935,1.18112578256796,-1.18973919325461,1.10635021016322,-0.305278384272399,0.623664303678783,2.16662948041503,0.451584621029415,0.482261778939052,2.21600053142586,1.09484627594711,-0.0473985255945167,-0.00473810287642824,0.554640698382101,0.414676165419384,2.01324369086685,0.624143634271121,0.14481304193305,-0.01672136768488,1.8426019999945,0.0273770468102224,0.051343576427126,0.51006295329466,2.37705561045145,1.79946224668407,-0.138950668731088,0.208564010714013,0.300595484442923,1.45386488960832,0.0594921964968734,1.18927440263771,0.659614098104138,0.226299242630522,0.21431597782207,1.75152918745026,3.30072566188691,0.950088437061009,2.22127316794157,-0.226668167128955,0.263687028832892,1.47687275804055,0.514856259218041,0.232530540330917,1.4145597810366,0.51245960625635,0.129474462978232,0.595863129323175,-0.261179969777296,0.303471467996952,0.0384016504339982,0.854222318593395,0.412758843050032,-0.219478208243884,1.95955866452499,0.587714509253427,-0.193594356257628,1.03924392723589,-0.0373325831554169,1.48981468403368,1.5051532629885,1.25494269378802,1.94517874675484,0.0863347096678053,0.435287380889921,0.391188966394818,2.76387539846827,0.816355201798687,0.894965418942131,0.521087556918436,-0.0895796177202668,0.547930070089368,1.07615238284592,0.376809048624676,2.47819436543478,0.922287262705401,0.290050211411485,-0.378615964900124,0.546012747720015,0.229654556776889,0.0388809810263362,0.489931068416461,0.917493956782021,0.429056083189526,0.610243047093317,0.601135765838894,1.70647211177049,1.10059824305516,0.682621966536366,1.4850213781103,0.209043341306352,0.248827780470411,0.352842519007773,2.04631750173818,2.76435472906061,0.314496071620727,0.764587497826176,0.233489201515593,0.732951678731863,0.81827252416804,1.65805972194434,1.42893969880674,0.511021614479336,-0.724213321975873,-0.20318096810439,-0.221395530613236,0.559434004305482,0.345173229530364,1.4787900804099,-0.307675037234089,-0.24536206023014,1.45338555901598,0.764108167233838,1.10443288779387,-1.01133234678638,1.62929988640406,1.05937581211409,0.542178102981311,-0.0555471456642638,1.25686001615737,0.419469471342765,0.298198831481233,1.0708797463302,0.574293252667962,0.916535295597344,1.00521145517989,0.964468354831151,1.98927716124995,1.78747898187562,0.626540287232811,-0.00953140879980896,0.4702785141306,0.0666821553819445,0.975013627862589,2.09233323860263,0.624143634271121,0.688853264236761,2.7226529675272,-0.0224733347929368,0.530674168765197,1.35704010995603,2.07603599846314,3.02558990188486,0.277587616010696,-0.563158242950281,0.71377845503834,3.01839994299979,1.2396041148332,0.570458607929257,0.645713510926334,1.10922619371725,0.751645571833048,1.76255379107404,0.803892606397898,0.601615096431232,-0.0397292361171073,1.97058326814876,1.17105984012886,1.52192983372033,1.54062372682151,-0.117380792075875,-0.0852656423892241,0.388792313433128,1.17777046842159,0.315934063397741,0.513897598033365,1.52864046201306,1.14277933518091,0.0690788083436348,0.497121027301532,0.70131585963755,0.928039229813458,0.177407522212039,0.820189846537392,0.724803058662116,4.30348526105815,1.85841990954165,0.663928073435181,0.236365185069622,0.326479336429179,3.1947936009802],"z":[2.74820411421215,-0.243675259026272,1.15124202844253,6.04072614732218,-0.86758959617918,1.75252734818575,0.262244915918961,0.477220581311025,2.3877561940435,2.36835989340663,0.0763637014822138,1.4405701796093,0.444893413582895,-0.14831011422829,1.12376393587362,2.12913885221846,0.20728873078114,1.30156335837834,-0.214580808070956,2.85488376771498,-0.127297455205005,1.15124202844253,1.88345237748468,2.20349133799316,-0.90476583906653,1.82041440041482,-0.233977108707833,0.878077461139836,3.00682145603719,1.01708428237079,1.24660717324052,2.2131894883116,3.17169001145065,1.11568214394159,-2.15905994691797,-0.151542831001102,0.150716187256913,0.102225435664718,2.8597328428742,1.35490318512975,1.28055069935505,1.45188468831414,1.6151368853412,0.194357863689888,-0.36490213800676,1.02839879107564,1.28863249128709,-0.0917375707040622,0.779479599569039,0.679265379611837,-0.565330577921165,0.666334512520585,-0.503908959237718,-0.405311097666922,1.37429948576663,4.1043288004072,-0.882136821656839,-0.953256590658724,1.28378341612787,0.192741505303481,1.70565295497996,-0.557248785989133,-0.107901154568127,1.27408526580943,-0.295398727391281,-0.403694739280516,0.398019020377106,1.86567243523421,1.10598399362315,0.603296535450732,3.20240082079238,-0.0109196513837373,0.519245899357593,0.920102779186404,-0.0965866458632811,0.653403645429333,-0.103052079408907,0.936266363050469,0.33659740169366,-0.11598294650016,0.829586709547641,-0.1757882067972,4.64419250146697,-0.707570115924937,-0.739897283653067,1.19973278003473,1.11244942716878,-0.146693755841882,-1.19732670700611,-0.0270832352478022,0.509547749039155,0.247697690441302,-0.0723412700671836,1.93517584584968,0.866762952434991,0.443277055196488,0.49338416517509,3.66144660253182,0.507931390652748,0.160414337575351,0.289723008487871,-0.859507804247148,0.472371506151805,2.99389058894594,0.0440365337540838,0.480453298083837,2.47503954690945,0.831203067934048,0.604912893837138,0.0133257244123602,-2.02490220084623,-2.09763832823452,2.94701619574015,1.17872012101144,0.273559424623806,-0.303480519323313,1.765458215277,0.818272200842796,0.33659740169366,-0.749595433971506,0.326899251375221,-1.0712507528664,-0.0771903452264035,0.0311056666628315,0.36407549426257,-0.245291617412679,0.383471794899448,0.773014166023413,0.270326707850994,-0.133762888750631,0.577434801268227,0.608145610609951,0.987989831415478,0.404484453922732,-0.725350058175409,0.268710349464586,-0.351971270915508,0.509547749039155,-0.052944969430306,-0.109517512954533,-0.641299422082271,-0.539468843738662,0.577434801268227,1.11406578555518,-0.211348091298142,-1.49150393333209,0.108690869210344,0.635623703178862,-0.14346103906907,0.249314048827709,4.29505909000317,0.326899251375221,-0.266304276435963,0.191125146917075,-0.448952774099898,1.25792168194536,-0.497443525692093,1.84950885137014,2.17278052865144,1.27570162419583,-0.398845664121296,-0.471581791509588,0.598447460291512,-0.631601271763832,-0.258222484503931,3.1086520343808,-0.276002426754402,-0.342273120597069,2.02569191548845,-0.684941098515246,-0.524921618261003,0.462673355833366,1.49875908151993,0.556422142244943,0.257395840759741,0.537025841608065,0.165263412734571,-0.0561776862031187,0.21213780594036,0.171728846280197,0.449742488742115,-0.647764855627897,-0.0949702874768748,0.11515630275597,-1.0227600012742,-0.982351041614041,0.176577921439416,-0.419858323144581,-0.96942017452279,0.674416304452617,0.59036566835948,2.87104735157905,0.566120292563382,-0.631601271763832,-0.680092023356027,1.21266364712598,0.0117093660259539,0.181426996598636,1.10598399362315,-1.00013098386451,0.280024858169432,-0.568563294693978,0.414182604241171,0.516013182584781,0.284873933328651,-0.327725895119411,1.92062862037203,0.0456528921404902,-1.35896254564676,-0.531387051806629,-1.10357792059453,1.91739590359921],"opacity":0.4,"type":"scatter3d","mode":"markers","name":"M","marker":{"color":"rgba(86,180,233,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(86,180,233,1)"}},"textfont":{"color":"rgba(86,180,233,1)","size":55},"error_y":{"color":"rgba(86,180,233,1)","width":55},"error_x":{"color":"rgba(86,180,233,1)","width":55},"line":{"color":"rgba(86,180,233,1)","width":55},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p><em>Click and drag the plot above to rotate it, and scroll to zoom. Note that in general we recommend against using 3D visualizations; here
we show the data in 3D only to illustrate what “higher dimensions” look like for learning purposes.</em></p>
>>>>>>> dev
<p><strong>Summary</strong></p>
<p>In order to classify a new observation using a K-nearest neighbour classifier, we have to:</p>
<ol style="list-style-type: decimal">
<li>Compute the distance between the new observation and each observation in the training set</li>
<li>Sort the data table in ascending order according to the distances</li>
<li>Choose the top <span class="math inline">\(K\)</span> rows of the sorted table</li>
<li>Classify the new observation based on a majority vote of the neighbour classes</li>
</ol>
</div>
<div id="k-nearest-neighbours-in-r" class="section level2">
<h2><span class="header-section-number">6.6</span> K-nearest neighbours in R</h2>
<p>Coding the K-nearest neighbour algorithm in R ourselves would get complicated if we might have to predict the label/class for multiple new observations, or when there
are multiple classes and more than two variables. Thankfully, in R, the K-nearest neighbour algorithm is implemented in
the <a href="https://topepo.github.io/caret/index.html"><code>caret</code> package</a> (<strong>c</strong>lassification <strong>a</strong>nd <strong>re</strong>gression <strong>t</strong>raining). The <code>caret</code> library
contains a set of tools to help make and use predictive models, such as classifiers.
Using this package will help keep our code simple, readable and accurate; the less we have to code ourselves, the less mistakes we are likely to make.</p>
<p>We start off by loading the <code>caret</code> library:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="classification.html#cb176-1"></a><span class="kw">library</span>(caret)</span></code></pre></div>
<p>Let’s again suppose we have a new observation with perimeter -1 and concavity 4.2, but its diagnosis is unknown (as in our example above). Suppose we again want to use the
perimeter and concavity explanatory variables/predictors to predict the diagnosis class of this observation. Let’s pick out our 2 desired variables and store it as a
new dataset named <code>cancer_train</code>:</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="classification.html#cb177-1"></a>cancer_train &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span></span>
<span id="cb177-2"><a href="classification.html#cb177-2"></a><span class="st">  </span><span class="kw">select</span>(<span class="st">&quot;Perimeter&quot;</span>, <span class="st">&quot;Concavity&quot;</span>)</span>
<span id="cb177-3"><a href="classification.html#cb177-3"></a><span class="kw">head</span>(cancer_train)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   Perimeter Concavity
##       &lt;dbl&gt;     &lt;dbl&gt;
## 1     1.27     2.65  
## 2     1.68    -0.0238
## 3     1.57     1.36  
## 4    -0.592    1.91  
## 5     1.78     1.37  
## 6    -0.387    0.866</code></pre>
<p>Next, we store the diagnosis class labels (column <code>Class</code>) as a vector:</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="classification.html#cb179-1"></a>cancer_labels &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb179-2"><a href="classification.html#cb179-2"></a><span class="st">  </span><span class="kw">select</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb179-3"><a href="classification.html#cb179-3"></a><span class="st">  </span><span class="kw">pull</span>()</span>
<span id="cb179-4"><a href="classification.html#cb179-4"></a><span class="kw">head</span>(cancer_labels)</span></code></pre></div>
<pre><code>## [1] M M M M M M
## Levels: B M</code></pre>
<p>We will use the function <code>train()</code>, where:</p>
<ul>
<li><code>x</code> is a data frame object containing the explanatory variables/predictors,</li>
<li><code>y</code> is a numeric or factor vector containing the outcomes/labels/classes,</li>
<li><code>method</code> is the type of prediction algorithm we want to use, we will use “knn”, and</li>
<li><code>tuneGrid</code> is a data frame with possible “tuning values”. For now, just know that this is where we will specify <span class="math inline">\(K=5\)</span> (the number of nearest neighbours to vote on the predicted class).</li>
</ul>
<p>The arguments <code>x</code> and <code>y</code> should come from the original data frame and be in the same order. We will also discuss how to choose <span class="math inline">\(K\)</span> in the next chapter.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="classification.html#cb181-1"></a>k &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">k =</span> <span class="dv">5</span>)</span>
<span id="cb181-2"><a href="classification.html#cb181-2"></a>model_knn &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> <span class="kw">data.frame</span>(cancer_train), <span class="dt">y =</span> cancer_labels, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid =</span> k)</span></code></pre></div>
<blockquote>
<p><strong>Note:</strong> the <code>caret</code> package expects <code>data.frames</code> and not <code>tibbles</code> (a special kind of data frames). This is a
bit annoying, and will likely change in the future, but for now we have to change <code>tibbles</code> to <code>data.frames</code> when using <code>caret</code>.</p>
</blockquote>
<p>Now we can create a <code>data.frame</code> with our new observation and predict the label of the new observation using the <code>predict</code> function:</p>
<<<<<<< HEAD
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">new_obs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Perimeter =</span> <span class="dv">-1</span>, <span class="dt">Concavity =</span> <span class="fl">4.2</span>)
<span class="kw">predict</span>(<span class="dt">object =</span> model_knn, new_obs)</code></pre></div>
<pre><code>## [1] B
=======
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="classification.html#cb182-1"></a>new_obs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Perimeter =</span> <span class="dv">-1</span>, <span class="dt">Concavity =</span> <span class="fl">4.2</span>)</span>
<span id="cb182-2"><a href="classification.html#cb182-2"></a><span class="kw">predict</span>(<span class="dt">object =</span> model_knn, new_obs)</span></code></pre></div>
<pre><code>## [1] M
>>>>>>> dev
## Levels: B M</code></pre>
<p>Our model classifies this new observation as malignant. In the next chapter, we will discuss evaluating how accurate our predictions are, and selecting the value of <span class="math inline">\(K\)</span>
to maximize that accuracy.</p>
</div>
<div id="data-preprocessing" class="section level2">
<h2><span class="header-section-number">6.7</span> Data preprocessing</h2>
<div id="shifting-and-scaling" class="section level3">
<h3><span class="header-section-number">6.7.1</span> Shifting and scaling</h3>
<p>When using K-nearest neighbour classification, the <em>scale</em> of each variable (i.e., its size and range of values) matters. Since
the classifier predicts classes by identifying observations that are nearest to it, any variables that have a large scale will have a
much larger effect than variables with a small scale. But just because a variable has a large scale <em>doesn’t mean</em> that it is more important
for making accurate predictions. For example, suppose you have a data set with two attributes, salary
(in dollars) and years of education, and you want to predict the corresponding type of job. When we compute the neighbour distances, a difference
of $1000 is huge compared to a difference of 10 years of education. But for our conceptual understanding and answering of the problem, it’s
the opposite; 10 years of education is huge compared to a difference of $1000 in yearly salary!</p>
<p>In many other predictive models, the <em>center</em> of each variable (e.g., its mean) matters as well. For example, if we had a data set
with a temperature variable measured in degrees Kelvin, and the same data set with temperature measured in degrees Celcius, the two variables
would differ by a constant shift of 273 (even though they contain exactly the same information). Likewise in our hypothetical job classification
example, we would likely see that the center of the salary variable is in the tens of thousands, while the center of the years of education
variable is in the single digits. Although this doesn’t affect the K-nearest neighbour classification algorithm, this large shift can
change the outcome of using many other predictive models.</p>
<p><strong>Standardization:</strong> when all variables in a data set have a mean (center) of 0 and a standard deviation (scale) of 1, we say that the data have been <em>standardized</em>.</p>
<<<<<<< HEAD
<p>To illustrate the effect that standardization can have on the K-nearest neighbour algorithm, we will read in the original, unscaled Wisconsin breast cancer data set; we have been using a standardized version of the data set up until now.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unscaled_cancer &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/unscaled_wdbc.csv&quot;</span>)
<span class="kw">head</span>(unscaled_cancer)</code></pre></div>
<pre><code>## # A tibble: 6 x 12
##       ID Class Radius Texture Perimeter  Area Smoothness Compactness
##    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1 8.42e5 M       18.0    10.4     123.  1001      0.118       0.278 
## 2 8.43e5 M       20.6    17.8     133.  1326      0.0847      0.0786
## 3 8.43e7 M       19.7    21.2     130   1203      0.110       0.160 
## 4 8.43e7 M       11.4    20.4      77.6  386.     0.142       0.284 
## 5 8.44e7 M       20.3    14.3     135.  1297      0.100       0.133 
## 6 8.44e5 M       12.4    15.7      82.6  477.     0.128       0.17  
## # … with 4 more variables: Concavity &lt;dbl&gt;, Concave_Points &lt;dbl&gt;,
## #   Symmetry &lt;dbl&gt;, Fractal_Dimension &lt;dbl&gt;</code></pre>
<p>Looking at the unscaled / unshifted data above, you can see that the difference between the values for area measurements are much larger than those for smoothness, and the mean appears to be much larger too. Will this affect predictions? In order to find out, we will create a scatter plot of these two predictors (coloured by diagnosis) for both the unstandardized data we just loaded, and the standardized version of that same data.</p>
<p>We will use the <code>preProcess</code> function from <code>caret</code> to create an object we can use to standardize the <code>unscaled_cancer</code> data set. When we do this, we need to specify the <code>method</code> argument to be <code>c(&quot;center&quot;, &quot;scale&quot;)</code> so that the standardization results in the predictors having a mean (center) of 0 and a standard deviation (scale) of 1. Finally, we use the <code>predict</code> function to apply the data transformation to our data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">scale_transformer &lt;-<span class="st"> </span><span class="kw">preProcess</span>(unscaled_cancer, <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>)) 
scaled_cancer &lt;-<span class="st"> </span><span class="kw">predict</span>(scale_transformer, unscaled_cancer)
<span class="kw">head</span>(scaled_cancer)</code></pre></div>
<pre><code>## # A tibble: 6 x 12
##       ID Class Radius Texture Perimeter   Area Smoothness Compactness
##    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1 -0.236 M      1.10   -2.07      1.27   0.984      1.57        3.28 
## 2 -0.236 M      1.83   -0.353     1.68   1.91      -0.826      -0.487
## 3  0.431 M      1.58    0.456     1.57   1.56       0.941       1.05 
## 4  0.432 M     -0.768   0.254    -0.592 -0.764      3.28        3.40 
## 5  0.432 M      1.75   -1.15      1.78   1.82       0.280       0.539
## 6 -0.236 M     -0.476  -0.835    -0.387 -0.505      2.24        1.24 
## # … with 4 more variables: Concavity &lt;dbl&gt;, Concave_Points &lt;dbl&gt;,
## #   Symmetry &lt;dbl&gt;, Fractal_Dimension &lt;dbl&gt;</code></pre>
<p>Now let’s generate the two scatter plots, one for <code>unscaled_cancer</code> and one for <code>scaled_cancer</code>, and show them side-by-side. Each has the same new observation annotated with its <span class="math inline">\(K=3\)</span> nearest neighbours:</p>
<center>
<img src="_main_files/figure-html/06-scaling-2-1.png" width="960" />
</center>
<p>In the plot for the nonstandardized original data, you can see some odd choices for the three nearest neighbours. In particular, the “neighbours” are visually well within the cloud of benign observations, and the neighbours are all nearly vertically aligned with the new observation (which is why it looks like there is only one black line on this plot). Here the computation of nearest neighbours is dominated by the much larger-scale area variable. On the right, the plot for standardized data shows a much more intuitively reasonable selection of nearest neighbours. Thus, standardizing the data can change things in an important way when we are using predictive algorithms. As a rule of thumb, standardizing your data should be a part of the preprocessing you do before any predictive modelling / analysis.</p>
=======
<p>To illustrate the effect that standardization can have on the K-nearest neighbour algorithm, we
will read in the original, unscaled Wisconsin breast cancer data set; we have been using a standardized version of the data set up until now. In order
to do this we will download the raw data from the UCI Machine learning repository, and then compute the unscaled columns equivalent to those we have been working with
in the scaled version of the data set (“worst” measures).</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="classification.html#cb184-1"></a>unscaled_cancer &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/unscaled-wdbc.data.csv&quot;</span>)</span>
<span id="cb184-2"><a href="classification.html#cb184-2"></a><span class="kw">head</span>(unscaled_cancer)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 11
##   Class Radius Texture Perimeter  Area Smoothness Compactness Concavity Concave_points Symmetry Fractal_dimension
##   &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt;
## 1 M      0.242  0.0787     1.10  0.905       8.59       153.    0.00640         0.0490   0.0537            0.0159
## 2 M      0.181  0.0567     0.544 0.734       3.40        74.1   0.00522         0.0131   0.0186            0.0134
## 3 M      0.207  0.0600     0.746 0.787       4.58        94.0   0.00615         0.0401   0.0383            0.0206
## 4 M      0.260  0.0974     0.496 1.16        3.44        27.2   0.00911         0.0746   0.0566            0.0187
## 5 M      0.181  0.0588     0.757 0.781       5.44        94.4   0.0115          0.0246   0.0569            0.0188
## 6 M      0.209  0.0761     0.334 0.890       2.22        27.2   0.00751         0.0334   0.0367            0.0114</code></pre>
<p>Looking at the unscaled / unshifted data above, you can see that the difference between the values for smoothness measurements are much larger than those for area, and the mean appears to be much larger too. Will this affect predictions? In order to find out, we will create a scatter plot of these two predictors (coloured by diagnosis) for both the unstandardized data we just loaded, and the standardized version of that same data.</p>
<p>We will use the <code>preProcess</code> function from <code>caret</code> to create an object we can use to standardize the <code>unscaled_cancer</code> data set. When we do this, we need to specify the <code>method</code> argument to be <code>c("center", "scale")</code> so that the standardization results in the predictors having a mean (center) of 0 and a standard deviation (scale) of 1. Finally, we use the <code>predict</code> function to apply the data transformation to our data set:</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="classification.html#cb186-1"></a>scale_transformer &lt;-<span class="st"> </span><span class="kw">preProcess</span>(unscaled_cancer, <span class="dt">method =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>)) </span>
<span id="cb186-2"><a href="classification.html#cb186-2"></a>scaled_cancer &lt;-<span class="st"> </span><span class="kw">predict</span>(scale_transformer, unscaled_cancer)</span>
<span id="cb186-3"><a href="classification.html#cb186-3"></a><span class="kw">head</span>(scaled_cancer)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 11
##   Class   Radius Texture Perimeter   Area Smoothness Compactness Concavity Concave_points Symmetry Fractal_dimension
##   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;             &lt;dbl&gt;
## 1 M      2.22      2.25      2.49  -0.565      2.83        2.49     -0.214         1.32      0.723            0.660 
## 2 M      0.00139  -0.868     0.499 -0.875      0.263       0.742    -0.605        -0.692    -0.440            0.260 
## 3 M      0.939    -0.398     1.23  -0.779      0.850       1.18     -0.297         0.814     0.213            1.42  
## 4 M      2.86      4.91      0.326 -0.110      0.286      -0.288     0.689         2.74      0.819            1.11  
## 5 M     -0.00955  -0.562     1.27  -0.790      1.27        1.19      1.48         -0.0485    0.828            1.14  
## 6 M      1.00      1.89     -0.255 -0.592     -0.321      -0.289     0.156         0.445     0.160           -0.0691</code></pre>
<p>Now let’s generate the two scatter plots, one for <code>unscaled_cancer</code> and one for <code>scaled_cancer</code>, and show them side-by-side:</p>
<center>
<img src="_main_files/figure-html/06-scaling-2-1.png" width="960" />
</center>
<p>In the plot with the original data above, its very clear that K-nearest neighbours would classify the
red dot (new observation) as malignant. However, once we standardize the data, the diagnosis class labelling
becomes less clear, and appears it would depend upon the choice of <span class="math inline">\(K\)</span>. Thus,
standardizing the data can change things in an important way when we are using predictive algorithms.
As a rule of thumb, standardizing your data should be a part of the preprocessing you do before any predictive
modelling / analysis.</p>
>>>>>>> dev
</div>
<div id="balancing" class="section level3">
<h3><span class="header-section-number">6.7.2</span> Balancing</h3>
<p>Another potential issue in a data set for a classifier is <em>class imbalance</em>, i.e., when one label is much more common
than another. Since classifiers like the K-nearest neighbour algorithm use the labels of nearby points to predict the
label of a new point, if there are many more data points with one label overall, the algorithm is more likely to pick
that label in general (even if the “pattern” of data suggests otherwise). Class imbalance is actually quite a common
and important problem: from rare disease diagnosis to malicious email detection, there are many cases in which the “important”
class to identify (presence of disease, malicious email) is much rarer than the “unimportant”
class (no disease, normal email).</p>
<p>To better illustrate the problem, let’s revisit the breast cancer data; except now we will remove many of the
observations of malignant tumours, simulating what the data would look like if the cancer was rare. We will
do this by picking only 3 observations randomly from the malignant group, and keeping all of the benign observations.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="classification.html#cb188-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb188-2"><a href="classification.html#cb188-2"></a>rare_cancer &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(<span class="kw">filter</span>(cancer, Class <span class="op">==</span><span class="st"> &quot;B&quot;</span>),</span>
<span id="cb188-3"><a href="classification.html#cb188-3"></a>        cancer <span class="op">%&gt;%</span></span>
<span id="cb188-4"><a href="classification.html#cb188-4"></a><span class="st">        </span><span class="kw">filter</span>(Class <span class="op">==</span><span class="st"> &quot;M&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb188-5"><a href="classification.html#cb188-5"></a><span class="st">        </span><span class="kw">sample_n</span>(<span class="dv">3</span>)</span>
<span id="cb188-6"><a href="classification.html#cb188-6"></a>            )</span>
<span id="cb188-7"><a href="classification.html#cb188-7"></a>rare_plot &lt;-<span class="st"> </span>rare_cancer <span class="op">%&gt;%</span><span class="st">  </span></span>
<span id="cb188-8"><a href="classification.html#cb188-8"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Perimeter, <span class="dt">y =</span> Concavity, <span class="dt">color =</span> Class)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb188-9"><a href="classification.html#cb188-9"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></span>
<span id="cb188-10"><a href="classification.html#cb188-10"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">color =</span> <span class="st">&quot;Diagnosis&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb188-11"><a href="classification.html#cb188-11"></a><span class="st">    </span><span class="kw">scale_color_manual</span>(<span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Benign&quot;</span>, <span class="st">&quot;Malignant&quot;</span>), <span class="dt">values =</span> cbPalette)</span>
<span id="cb188-12"><a href="classification.html#cb188-12"></a>rare_plot</span></code></pre></div>
<p><img src="_main_files/figure-html/05-unbalanced-1.png" width="480" /></p>
<blockquote>
<p>Note: You will see in the code above that we use the <code>set.seed</code> function. This is because we are using <code>sample_n</code> to artificially pick
only 3 of the malignant tumour observations, which uses random sampling to choose which rows will be in the training set. In order to
make the code reproducible, we use <code>set.seed</code> to specify where the random number generator starts for this
process, which then guarantees the same result, i.e., the same choice of 3 observations, each time the code is run. In general, when your
code involves random numbers, if you want <em>the same result</em> each time, you should use <code>set.seed</code>; if you want a <em>different result</em> each time,
you should not.</p>
</blockquote>
<p>Suppose we now decided to use <span class="math inline">\(K = 7\)</span> in K-nearest neighbour classification. With only 3 observations of malignant
tumours, the classifier will <em>always predict that the tumour is benign, no matter what its concavity and perimeter are!</em> This is because in a majority
vote of 7 observations, at most 3 will be malignant (we only have 3 total malignant observations), so at least 4 must be benign,
and the benign vote will always win. For example, look what happens for a new tumour observation that is quite close to two
that were tagged as malignant:</p>
<center>
<img src="_main_files/figure-html/05-upsample-1.png" width="480" />
</center>
<p>And if we set the background colour of each area of the plot to the decision the K-nearest neighbour
classifier would make, we can see that the decision is always “benign,” corresponding to the blue colour:</p>
<center>
<img src="_main_files/figure-html/05-upsample-2-1.png" width="480" />
</center>
<p>Despite the simplicity of the problem, solving it in a statistically sound manner is actually
fairly nuanced, and a careful treatment would require a lot more detail and mathematics than we will cover in this textbook.
For the present purposes, it will suffice to rebalance the data by <em>oversampling</em> the rare class.
In other words, we will replicate rare observations multiple times in our data set to give them more
voting power in the K-nearest neighbour algorithm. In order to do this, we will use the
<code>upSample</code> function from the <code>caret</code> library. We show below how to do this, and also
use the <code>group_by + summarize</code> pattern we’ve seen before to see that our classes are now balanced:</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="classification.html#cb189-1"></a>rare_cancer &lt;-<span class="st"> </span><span class="kw">upSample</span>(<span class="dt">x =</span> <span class="kw">select</span>(rare_cancer, Perimeter, Concavity),</span>
<span id="cb189-2"><a href="classification.html#cb189-2"></a>            <span class="dt">y =</span> <span class="kw">select</span>(rare_cancer, Class) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>()</span>
<span id="cb189-3"><a href="classification.html#cb189-3"></a>            )</span>
<span id="cb189-4"><a href="classification.html#cb189-4"></a>rare_cancer <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb189-5"><a href="classification.html#cb189-5"></a><span class="st">    </span><span class="kw">group_by</span>(Class) <span class="op">%&gt;%</span></span>
<span id="cb189-6"><a href="classification.html#cb189-6"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>())</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   Class     n
##   &lt;fct&gt; &lt;int&gt;
## 1 B       357
## 2 M       357</code></pre>
Now suppose we train our K-nearest neighbour classifier with <span class="math inline">\(K=7\)</span> on this <em>balanced</em> data. Setting the background colour
of each area of our scatter plot to the decision the K-nearest neighbour
classifier would make, we can see that the decision is more reasonable; when the points are close
to those labelled malignant, the classifier predicts a malignant tumour, and vice versa when they are closer to the benign tumour observations:
<center>
<img src="_main_files/figure-html/05-upsample-plot-1.png" width="480" />
</center>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="GitHub.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification-continued.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-classification.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
