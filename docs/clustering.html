<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Clustering | Introduction to Data Science</title>
  <meta name="description" content="This is an open source textbook for teaching introductory data science." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Clustering | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source textbook for teaching introductory data science." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Clustering | Introduction to Data Science" />
  
  <meta name="twitter:description" content="This is an open source textbook for teaching introductory data science." />
  

<meta name="author" content="Tiffany-Anne Timbers" />
<meta name="author" content="Melissa Lee" />
<meta name="author" content="Trevor Campbell" />


<meta name="date" content="2019-09-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression3.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data Science</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#jupyter-notebooks"><i class="fa fa-check"></i><b>1.2</b> Jupyter notebooks</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#loading-a-spreadsheet-like-dataset"><i class="fa fa-check"></i><b>1.3</b> Loading a spreadsheet-like dataset</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#assigning-value-to-a-data-frame"><i class="fa fa-check"></i><b>1.4</b> Assigning value to a data frame</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#creating-subsets-of-data-frames-with-select-filter"><i class="fa fa-check"></i><b>1.5</b> Creating subsets of data frames with <code>select</code> &amp; <code>filter</code></a><ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#using-select-to-extract-multiple-columns"><i class="fa fa-check"></i><b>1.5.1</b> Using <code>select</code> to extract multiple columns</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#using-select-to-extract-a-range-of-columns"><i class="fa fa-check"></i><b>1.5.2</b> Using <code>select</code> to extract a range of columns</a></li>
<li class="chapter" data-level="1.5.3" data-path="index.html"><a href="index.html#using-filter-to-extract-a-single-row"><i class="fa fa-check"></i><b>1.5.3</b> Using <code>filter</code> to extract a single row</a></li>
<li class="chapter" data-level="1.5.4" data-path="index.html"><a href="index.html#using-filter-to-extract-rows-with-values-above-a-threshold"><i class="fa fa-check"></i><b>1.5.4</b> Using <code>filter</code> to extract rows with values above a threshold</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#exploring-data-with-visualizations"><i class="fa fa-check"></i><b>1.6</b> Exploring data with visualizations</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot"><i class="fa fa-check"></i><b>1.6.1</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot-1"><i class="fa fa-check"></i><b>1.6.2</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.6.3" data-path="index.html"><a href="index.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.6.3</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.6.4" data-path="index.html"><a href="index.html#coloring-points-by-group"><i class="fa fa-check"></i><b>1.6.4</b> Coloring points by group</a></li>
<li class="chapter" data-level="1.6.5" data-path="index.html"><a href="index.html#putting-it-all-together"><i class="fa fa-check"></i><b>1.6.5</b> Putting it all together</a></li>
<li class="chapter" data-level="1.6.6" data-path="index.html"><a href="index.html#whats-next"><i class="fa fa-check"></i><b>1.6.6</b> What’s next?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a><ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data into R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.1</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.2</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.3</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#scraping-data-off-the-web-using-r"><i class="fa fa-check"></i><b>2.5</b> Scraping data off the web using R</a><ul>
<li class="chapter" data-level="2.5.1" data-path="reading.html"><a href="reading.html#html-and-css-selectors"><i class="fa fa-check"></i><b>2.5.1</b> HTML and CSS selectors</a></li>
<li class="chapter" data-level="2.5.2" data-path="reading.html"><a href="reading.html#are-you-allowed-to-scrape-that-website"><i class="fa fa-check"></i><b>2.5.2</b> Are you allowed to scrape that website?</a></li>
<li class="chapter" data-level="2.5.3" data-path="reading.html"><a href="reading.html#using-rvest"><i class="fa fa-check"></i><b>2.5.3</b> Using <code>rvest</code></a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#additional-readingsresources"><i class="fa fa-check"></i><b>2.6</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a><ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#vectors-and-data-frames"><i class="fa fa-check"></i><b>3.3</b> Vectors and Data frames</a><ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#how-are-vectors-different-from-a-list"><i class="fa fa-check"></i><b>3.3.3</b> How are vectors different from a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#the-dplyr-functions"><i class="fa fa-check"></i><b>3.4</b> The <code>dplyr</code> functions</a></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.5</b> Tidy Data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="wrangling.html"><a href="wrangling.html#what-is-tidy-data"><i class="fa fa-check"></i><b>3.5.1</b> What is tidy data?</a></li>
<li class="chapter" data-level="3.5.2" data-path="wrangling.html"><a href="wrangling.html#why-is-tidy-data-important-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Why is tidy data important in R?</a></li>
<li class="chapter" data-level="3.5.3" data-path="wrangling.html"><a href="wrangling.html#going-from-wide-to-long-or-tidy-using-gather"><i class="fa fa-check"></i><b>3.5.3</b> Going from wide to long (or tidy!) using <code>gather</code></a></li>
<li class="chapter" data-level="3.5.4" data-path="wrangling.html"><a href="wrangling.html#using-separate-to-deal-with-multiple-delimiters"><i class="fa fa-check"></i><b>3.5.4</b> Using separate to deal with multiple delimiters</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#using-purrrs-map-functions-to-iterate"><i class="fa fa-check"></i><b>3.6</b> Using <code>purrr</code>’s <code>map*</code> functions to iterate</a><ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#a-bit-more-about-the-map-functions"><i class="fa fa-check"></i><b>3.6.1</b> A bit more about the <code>map*</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#additional-readingsresources-1"><i class="fa fa-check"></i><b>3.7</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a><ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-2"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#making-effective-visualizations"><i class="fa fa-check"></i><b>4.3</b> Making effective visualizations</a><ul>
<li class="chapter" data-level="4.3.1" data-path="viz.html"><a href="viz.html#choosing-the-visualization"><i class="fa fa-check"></i><b>4.3.1</b> Choosing the visualization</a></li>
<li class="chapter" data-level="4.3.2" data-path="viz.html"><a href="viz.html#designing-the-visualization"><i class="fa fa-check"></i><b>4.3.2</b> Designing the visualization</a></li>
<li class="chapter" data-level="4.3.3" data-path="viz.html"><a href="viz.html#explaining-the-visualization"><i class="fa fa-check"></i><b>4.3.3</b> Explaining the visualization</a></li>
<li class="chapter" data-level="4.3.4" data-path="viz.html"><a href="viz.html#saving-the-visualization"><i class="fa fa-check"></i><b>4.3.4</b> Saving the visualization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="GitHub.html"><a href="GitHub.html"><i class="fa fa-check"></i><b>5</b> Version control with GitHub</a><ul>
<li class="chapter" data-level="5.1" data-path="GitHub.html"><a href="GitHub.html#overview-3"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="GitHub.html"><a href="GitHub.html#videos-to-learn-about-version-control-with-github-and-git"><i class="fa fa-check"></i><b>5.2</b> Videos to learn about version control with GitHub and Git</a><ul>
<li class="chapter" data-level="5.2.1" data-path="GitHub.html"><a href="GitHub.html#creating-a-github-repository"><i class="fa fa-check"></i><b>5.2.1</b> Creating a GitHub repository</a></li>
<li class="chapter" data-level="5.2.2" data-path="GitHub.html"><a href="GitHub.html#exploring-a-github-repository"><i class="fa fa-check"></i><b>5.2.2</b> Exploring a GitHub repository</a></li>
<li class="chapter" data-level="5.2.3" data-path="GitHub.html"><a href="GitHub.html#directly-editing-files-on-github"><i class="fa fa-check"></i><b>5.2.3</b> Directly editing files on GitHub</a></li>
<li class="chapter" data-level="5.2.4" data-path="GitHub.html"><a href="GitHub.html#logging-changes-and-pushing-them-to-github"><i class="fa fa-check"></i><b>5.2.4</b> Logging changes and pushing them to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="GitHub.html"><a href="GitHub.html#git-command-cheatsheet"><i class="fa fa-check"></i><b>5.3</b> Git command cheatsheet</a><ul>
<li class="chapter" data-level="5.3.1" data-path="GitHub.html"><a href="GitHub.html#getting-a-repository-from-github-onto-the-server-for-the-first-time"><i class="fa fa-check"></i><b>5.3.1</b> Getting a repository from GitHub onto the server for the first time</a></li>
<li class="chapter" data-level="5.3.2" data-path="GitHub.html"><a href="GitHub.html#logging-changes"><i class="fa fa-check"></i><b>5.3.2</b> Logging changes</a></li>
<li class="chapter" data-level="5.3.3" data-path="GitHub.html"><a href="GitHub.html#sending-your-changes-back-to-github"><i class="fa fa-check"></i><b>5.3.3</b> Sending your changes back to GitHub</a></li>
<li class="chapter" data-level="5.3.4" data-path="GitHub.html"><a href="GitHub.html#getting-changes"><i class="fa fa-check"></i><b>5.3.4</b> Getting changes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="GitHub.html"><a href="GitHub.html#terminal-cheatsheet"><i class="fa fa-check"></i><b>5.4</b> Terminal cheatsheet</a><ul>
<li class="chapter" data-level="5.4.1" data-path="GitHub.html"><a href="GitHub.html#see-where-you-are"><i class="fa fa-check"></i><b>5.4.1</b> See where you are:</a></li>
<li class="chapter" data-level="5.4.2" data-path="GitHub.html"><a href="GitHub.html#see-what-is-inside-the-directory-where-you-are"><i class="fa fa-check"></i><b>5.4.2</b> See what is inside the directory where you are:</a></li>
<li class="chapter" data-level="5.4.3" data-path="GitHub.html"><a href="GitHub.html#move-to-a-different-directory"><i class="fa fa-check"></i><b>5.4.3</b> Move to a different directory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>6</b> Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="classification.html"><a href="classification.html#overview-4"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification.html"><a href="classification.html#learning-objectives"><i class="fa fa-check"></i><b>6.2</b> Learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification.html"><a href="classification.html#classification"><i class="fa fa-check"></i><b>6.3</b> Classification</a></li>
<li class="chapter" data-level="6.4" data-path="classification.html"><a href="classification.html#wisconsin-breast-cancer-example"><i class="fa fa-check"></i><b>6.4</b> Wisconsin Breast Cancer Example:</a><ul>
<li class="chapter" data-level="6.4.1" data-path="classification.html"><a href="classification.html#data-exploration"><i class="fa fa-check"></i><b>6.4.1</b> Data Exploration</a></li>
<li class="chapter" data-level="6.4.2" data-path="classification.html"><a href="classification.html#k-nearest-neighbour-classifier"><i class="fa fa-check"></i><b>6.4.2</b> K-Nearest Neighbour Classifier</a></li>
<li class="chapter" data-level="6.4.3" data-path="classification.html"><a href="classification.html#k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>6.4.3</b> K-Nearest Neighbours in R</a></li>
<li class="chapter" data-level="6.4.4" data-path="classification.html"><a href="classification.html#more-than-two-explanatory-variablespredictors"><i class="fa fa-check"></i><b>6.4.4</b> More than two explanatory variables/predictors</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="classification.html"><a href="classification.html#additional-readingsresources-2"><i class="fa fa-check"></i><b>6.5</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-continued.html"><a href="classification-continued.html"><i class="fa fa-check"></i><b>7</b> Classification continued</a><ul>
<li class="chapter" data-level="7.1" data-path="classification-continued.html"><a href="classification-continued.html#overview-5"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="classification-continued.html"><a href="classification-continued.html#learning-objectives-1"><i class="fa fa-check"></i><b>7.2</b> Learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="classification-continued.html"><a href="classification-continued.html#assessing-how-good-your-classifier-is"><i class="fa fa-check"></i><b>7.3</b> Assessing how good your classifier is</a><ul>
<li class="chapter" data-level="7.3.1" data-path="classification-continued.html"><a href="classification-continued.html#assessing-your-classifier-in-r"><i class="fa fa-check"></i><b>7.3.1</b> Assessing your classifier in R</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="classification-continued.html"><a href="classification-continued.html#cross-validation-for-assessing-classifier-quality"><i class="fa fa-check"></i><b>7.4</b> Cross-validation for assessing classifier quality</a></li>
<li class="chapter" data-level="7.5" data-path="classification-continued.html"><a href="classification-continued.html#choosing-the-number-of-neighbours-for-k-nn-classification"><i class="fa fa-check"></i><b>7.5</b> Choosing the number of neighbours for k-nn classification</a></li>
<li class="chapter" data-level="7.6" data-path="classification-continued.html"><a href="classification-continued.html#other-ways-to-increase-accuracy"><i class="fa fa-check"></i><b>7.6</b> Other ways to increase accuracy</a></li>
<li class="chapter" data-level="7.7" data-path="classification-continued.html"><a href="classification-continued.html#test-data-set"><i class="fa fa-check"></i><b>7.7</b> Test data set</a></li>
<li class="chapter" data-level="7.8" data-path="classification-continued.html"><a href="classification-continued.html#scaling-your-data"><i class="fa fa-check"></i><b>7.8</b> Scaling your data</a></li>
<li class="chapter" data-level="7.9" data-path="classification-continued.html"><a href="classification-continued.html#strengths-and-limitations-of-k-nn-classification"><i class="fa fa-check"></i><b>7.9</b> Strengths and limitations of k-nn classification</a><ul>
<li class="chapter" data-level="7.9.1" data-path="classification-continued.html"><a href="classification-continued.html#strengths-of-k-nn-classification"><i class="fa fa-check"></i><b>7.9.1</b> Strengths of k-nn classification</a></li>
<li class="chapter" data-level="7.9.2" data-path="classification-continued.html"><a href="classification-continued.html#limitations-of-k-nn-classification"><i class="fa fa-check"></i><b>7.9.2</b> Limitations of k-nn classification</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="classification-continued.html"><a href="classification-continued.html#additional-readingsresources-3"><i class="fa fa-check"></i><b>7.10</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>8</b> Introduction to regression through K-nearest neighbours</a><ul>
<li class="chapter" data-level="8.1" data-path="regression1.html"><a href="regression1.html#overview-6"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression1.html"><a href="regression1.html#learning-objectives-2"><i class="fa fa-check"></i><b>8.2</b> Learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression1.html"><a href="regression1.html#regression"><i class="fa fa-check"></i><b>8.3</b> Regression</a></li>
<li class="chapter" data-level="8.4" data-path="regression1.html"><a href="regression1.html#sacremento-real-estate-example"><i class="fa fa-check"></i><b>8.4</b> Sacremento real estate example</a></li>
<li class="chapter" data-level="8.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbours-regression"><i class="fa fa-check"></i><b>8.5</b> K-nearest neighbours regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression1.html"><a href="regression1.html#assessing-a-knn-regression-model"><i class="fa fa-check"></i><b>8.6</b> Assessing a knn regression model</a></li>
<li class="chapter" data-level="8.7" data-path="regression1.html"><a href="regression1.html#how-do-different-ks-affect-k-nn-regression-predictions"><i class="fa fa-check"></i><b>8.7</b> How do different k’s affect k-nn regression predictions</a></li>
<li class="chapter" data-level="8.8" data-path="regression1.html"><a href="regression1.html#assessing-model-goodness-with-the-test-set"><i class="fa fa-check"></i><b>8.8</b> Assessing model goodness with the test set</a></li>
<li class="chapter" data-level="8.9" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9</b> Strengths and limitations of k-nn regression</a><ul>
<li class="chapter" data-level="8.9.1" data-path="regression1.html"><a href="regression1.html#strengths-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9.1</b> Strengths of k-nn regression</a></li>
<li class="chapter" data-level="8.9.2" data-path="regression1.html"><a href="regression1.html#limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9.2</b> Limitations of k-nn regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>9</b> Regression, continued</a><ul>
<li class="chapter" data-level="9.1" data-path="regression2.html"><a href="regression2.html#overview-7"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="regression2.html"><a href="regression2.html#learning-objectives-3"><i class="fa fa-check"></i><b>9.2</b> Learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="regression2.html"><a href="regression2.html#rmse-versus-rmpse"><i class="fa fa-check"></i><b>9.3</b> <span class="math inline">\(RMSE\)</span> versus <span class="math inline">\(RMPSE\)</span></a></li>
<li class="chapter" data-level="9.4" data-path="regression2.html"><a href="regression2.html#linear-regression"><i class="fa fa-check"></i><b>9.4</b> Linear regression</a></li>
<li class="chapter" data-level="9.5" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r-using-caret"><i class="fa fa-check"></i><b>9.5</b> Linear regression in R using <code>caret</code></a></li>
<li class="chapter" data-level="9.6" data-path="regression2.html"><a href="regression2.html#comparing-linear-and-k-nn-regression"><i class="fa fa-check"></i><b>9.6</b> Comparing linear and k-nn regression</a></li>
<li class="chapter" data-level="9.7" data-path="regression2.html"><a href="regression2.html#additional-readingsresources-4"><i class="fa fa-check"></i><b>9.7</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression3.html"><a href="regression3.html"><i class="fa fa-check"></i><b>10</b> Regression, continued some more…</a><ul>
<li class="chapter" data-level="10.1" data-path="regression3.html"><a href="regression3.html#overview-8"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="regression3.html"><a href="regression3.html#learning-objectives-4"><i class="fa fa-check"></i><b>10.2</b> Learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="regression3.html"><a href="regression3.html#multivariate-k-nn-regression"><i class="fa fa-check"></i><b>10.3</b> Multivariate k-nn regression</a></li>
<li class="chapter" data-level="10.4" data-path="regression3.html"><a href="regression3.html#multivariate-linear-regression"><i class="fa fa-check"></i><b>10.4</b> Multivariate linear regression</a></li>
<li class="chapter" data-level="10.5" data-path="regression3.html"><a href="regression3.html#the-other-side-of-regression"><i class="fa fa-check"></i><b>10.5</b> The other side of regression</a></li>
<li class="chapter" data-level="10.6" data-path="regression3.html"><a href="regression3.html#additional-readingsresources-5"><i class="fa fa-check"></i><b>10.6</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>11</b> Clustering</a><ul>
<li class="chapter" data-level="11.1" data-path="clustering.html"><a href="clustering.html#overview-9"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="clustering.html"><a href="clustering.html#learning-objectives-5"><i class="fa fa-check"></i><b>11.2</b> Learning objectives</a></li>
<li class="chapter" data-level="11.3" data-path="clustering.html"><a href="clustering.html#clustering"><i class="fa fa-check"></i><b>11.3</b> Clustering</a><ul>
<li class="chapter" data-level="11.3.1" data-path="clustering.html"><a href="clustering.html#a-toy-example"><i class="fa fa-check"></i><b>11.3.1</b> A toy example</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="clustering.html"><a href="clustering.html#k-means-clustering-algorithm"><i class="fa fa-check"></i><b>11.4</b> K-means clustering algorithm</a></li>
<li class="chapter" data-level="11.5" data-path="clustering.html"><a href="clustering.html#k-means-clustering-in-r"><i class="fa fa-check"></i><b>11.5</b> K-means clustering in R</a></li>
<li class="chapter" data-level="11.6" data-path="clustering.html"><a href="clustering.html#choosing-k-for-k-means-clustering"><i class="fa fa-check"></i><b>11.6</b> Choosing K for K-means clustering</a></li>
<li class="chapter" data-level="11.7" data-path="clustering.html"><a href="clustering.html#additional-readings"><i class="fa fa-check"></i><b>11.7</b> Additional readings:</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="clustering" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Clustering</h1>
<div id="overview-9" class="section level2">
<h2><span class="header-section-number">11.1</span> Overview</h2>
<p>Introduction to clustering using K-means. Will discuss the K-means algorithm, how we choose K (the number of clusters) and other practical considerations (such as scaling).</p>
</div>
<div id="learning-objectives-5" class="section level2">
<h2><span class="header-section-number">11.2</span> Learning objectives</h2>
<p>By the end of the chapter, students will be able to:</p>
<ul>
<li>Describe a case where clustering would be an appropriate tool, and what insight it would bring from the data.</li>
<li>Explain the K-means clustering algorithm.</li>
<li>Interpret the output of a K-means analysis.</li>
<li>Perform kmeans clustering in R using <code>kmeans</code>.</li>
<li>Visualize the output of K-means clustering in R using pair-wise scatter plots.</li>
<li>Identify when it is necessary to scale variables before clustering and do this using R.</li>
<li>Use the elbow method to choose the number of clusters for K-means.</li>
<li>Describe advantages, limitations and assumptions of the K-means clustering algorithm.</li>
</ul>
</div>
<div id="clustering" class="section level2">
<h2><span class="header-section-number">11.3</span> Clustering</h2>
<p>While at first glance, clustering may seem very similar to classification, these two methods have some very important distinction. Most notably, classification is a supervised method (we use past information to predict the future values/labels for our target/response variable), whereas clustering is considered an unsupervised method (there is no target/response variable and we are looking to find sub-groups/clusters of observations based on how similar they are). So, where classification might be used to label future emails as spam or not spam, clustering might be instead be used to group emails into categories based on their similarity, however we would not have labels for these categories in the case of clustering. Another example problem we might try to solve with clustering is grouping Amazon customers into groups based upon their similar purchasing behaviours. Again here, we do not have, nor need, labels for customer groups.</p>
<p>Another way to think about it is, that classification is really about predicting something that you might have a scientific question about and/or hypothesis for, whereas, clustering is very often a hypothesis generating process (you identify things that are similar to each other that might be unexpected, and from those observations, you might generate a question and hypothesis that you might follow-up with classification).</p>
<p>Another major difference between clustering and classification is in how success is determined. With classification we are able to use a test data set to assess prediction performance, in clustering we must use variance metrics to determine how well our defined clusters fit the data. The two metrics used to determine success are between- and within- variation. Ideally we want clusters where the between-variance is large (so that the clusters are well separated) and the within- variation is small (so that the clusters are composed of close/tight-knit observations).</p>
<div id="a-toy-example" class="section level3">
<h3><span class="header-section-number">11.3.1</span> A toy example</h3>
<p>What if we had some customer data, and we wanted to learn more about the types of customers we had so that we could come up with better products and/or promotions to increase our business in a data-driven way. For example, let’s consider this data below, where we have assessed customer loyalty and customer satisfaction:</p>
<p><img src="_main_files/figure-html/10-toy-example-plot-1.png" width="417.6" /></p>
<p>data modified from: <a href="http://www.segmentationstudyguide.com/using-cluster-analysis-for-market-segmentation/" class="uri">http://www.segmentationstudyguide.com/using-cluster-analysis-for-market-segmentation/</a></p>
<p>From this data we might ask whether there are sub-groups within our customers? For example do we have customers with high loyalty and high satisfaction? What about low satisfaction and high loyalty? One way to answer such a question is to apply K-means clustering analysis. When we do such an analysis on this data set we identify 3 customer subgroups within our data set:</p>
<p><img src="_main_files/figure-html/10-toy-example-clustering-1.png" width="480" /></p>
<p>What are the labels for these groups? We don’t really have any, only cluster numbers are output from the clustering algorithm. In a simple case like this, where we can easily visualize the clusters on a scatter plot, we can give labels to these groups after clustering using the positions of the groups on the plot:</p>
<ul>
<li>low loyalty and low satisfaction (<font color="#00BA38">green cluster</font>),</li>
<li>high loyalty and low satisfaction (<font color="#F8766D">pink cluster</font>),</li>
<li>and high loyalty and high satisfaction (<font color="#619CFF">blue cluster</font>).</li>
</ul>
<p>Once we have such data we can use it to inform our future business decisions, and/or ask questions like, why did we not observe customers who had high satisfaction but low loyalty?</p>
</div>
</div>
<div id="k-means-clustering-algorithm" class="section level2">
<h2><span class="header-section-number">11.4</span> K-means clustering algorithm</h2>
<p>Watch the video linked to below for an explanation of the K-means clustering algorithm: - <a href="https://www.coursera.org/lecture/machine-learning-data-analysis/what-is-a-k-means-cluster-analysis-p94tY" class="uri">https://www.coursera.org/lecture/machine-learning-data-analysis/what-is-a-k-means-cluster-analysis-p94tY</a></p>
<p><em>note - when the advertisement pops up to register for this course, you can just click to ignore it (i.e., no need to sign up to watch the entire video)</em></p>
</div>
<div id="k-means-clustering-in-r" class="section level2">
<h2><span class="header-section-number">11.5</span> K-means clustering in R</h2>
<p>Let’s take a look at the data we plotted above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(marketing_data)</code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   loyalty  csat
##     &lt;dbl&gt; &lt;dbl&gt;
## 1     7       1
## 2     7.5     1
## 3     8       2
## 4     7       2
## 5     3       2
## 6     1       3</code></pre>
<p>To peform Kmeans clustering in R, we use the <code>kmeans</code> function. It takes at least two arguments, the data frame containing the data you wish to cluster, and K, the number of clusters (here we choose K = 3). Given that the K-means algorithm uses a random start to begin the algorithm, to make this reproducible, we need to set the seed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
marketing_clust &lt;-<span class="st"> </span><span class="kw">kmeans</span>(marketing_data, <span class="dt">centers =</span> <span class="dv">3</span>)
marketing_clust</code></pre></div>
<pre><code>## K-means clustering with 3 clusters of sizes 5, 9, 5
## 
## Cluster means:
##    loyalty     csat
## 1 7.500000 1.800000
## 2 6.777778 7.444444
## 3 2.400000 3.200000
## 
## Clustering vector:
##  [1] 1 1 1 1 3 3 1 3 3 2 2 2 2 2 2 2 2 2 3
## 
## Within cluster sum of squares by cluster:
## [1]  3.80000 27.77778  8.00000
##  (between_SS / total_SS =  83.6 %)
## 
## Available components:
## 
## [1] &quot;cluster&quot;      &quot;centers&quot;      &quot;totss&quot;        &quot;withinss&quot;    
## [5] &quot;tot.withinss&quot; &quot;betweenss&quot;    &quot;size&quot;         &quot;iter&quot;        
## [9] &quot;ifault&quot;</code></pre>
<p>As you can see above, the clustering object returned has a lot of information about our analysis that we need to explore. Let’s take a look at it now. To do this, we will call in help from the <code>broom</code> package so that we get the model output back in a tidy data format. Let’s first start by getting the cluster identification for each point and plotting that on the scatter plot. To do that we use the augment function. Augment takes in the model and the original data frame, and returns a data frame with the data and the cluster assignments for each point:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(broom)

clustered_data &lt;-<span class="st"> </span><span class="kw">augment</span>(marketing_clust, marketing_data)
<span class="kw">head</span>(clustered_data)</code></pre></div>
<pre><code>## # A tibble: 6 x 3
##   loyalty  csat .cluster
##     &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;   
## 1     7       1 1       
## 2     7.5     1 1       
## 3     8       2 1       
## 4     7       2 1       
## 5     3       2 3       
## 6     1       3 3</code></pre>
<p>Now that we have this data frame, we can easily plot the data (i.e., cluster assignments of each point):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cluster_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(clustered_data, <span class="kw">aes</span>(<span class="dt">x =</span> csat, <span class="dt">y =</span> loyalty, <span class="dt">colour =</span> .cluster)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()
cluster_plot</code></pre></div>
<p><img src="_main_files/figure-html/10-plot-clusters-2-1.png" width="417.6" /></p>
</div>
<div id="choosing-k-for-k-means-clustering" class="section level2">
<h2><span class="header-section-number">11.6</span> Choosing K for K-means clustering</h2>
<p>As mentioned above, we need to choose a K to perform K-means clustering. How should we choose K? We have no data labels, and so cannot perform cross-validation with some measure of model prediction error, so what can we do? What we can do in this situation is to look at the total within-cluster sum of squares for different K’s and choose the K that gives the biggest decrease in the total within-cluster sum of squares. Why total within-cluster sum of squares? This statistic lets us know how close/tight-knit (or compact) observations are within clusters. A larger number means that clusters are not close/tight-knit, but are instead more spread out. A smaller number here means that clusters are indeed close/tight-knit together.</p>
<p>We can get at the total within-cluster sum of squares (<code>tot.withinss</code>) from our clustering using <code>broom</code>’s <code>glance</code> function (it gives model-level statistics). For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(marketing_clust)</code></pre></div>
<pre><code>## # A tibble: 1 x 4
##   totss tot.withinss betweenss  iter
##   &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;
## 1  241.         39.6      202.     2</code></pre>
<p>Let’s calculate the total within-cluster sum of squares for our data for a variety of K’s (say 1 - 9) and then plot them against K. To do this we will create a data frame with a column named <code>k</code>, for each of the K’s we want to try our clustering with. Then we use <code>map</code> to apply the <code>kmeans</code> function to each K. We also use <code>map</code> to then apply <code>glance</code> to each of the clustering models we performed (one for each K). In the end we end up with a complex data frame with 3 columns, one for K, one for the models, and one for the model statistics (output of <code>glance</code>, which is a data frame):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">marketing_clust_ks &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">k =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">9</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">marketing_clusts =</span> <span class="kw">map</span>(k, <span class="op">~</span><span class="kw">kmeans</span>(marketing_data, .x)),
         <span class="dt">glanced =</span> <span class="kw">map</span>(marketing_clusts, glance)) 
<span class="kw">head</span>(marketing_clust_ks)</code></pre></div>
<pre><code>## # A tibble: 6 x 3
##       k marketing_clusts glanced         
##   &lt;int&gt; &lt;list&gt;           &lt;list&gt;          
## 1     1 &lt;kmeans&gt;         &lt;tibble [1 × 4]&gt;
## 2     2 &lt;kmeans&gt;         &lt;tibble [1 × 4]&gt;
## 3     3 &lt;kmeans&gt;         &lt;tibble [1 × 4]&gt;
## 4     4 &lt;kmeans&gt;         &lt;tibble [1 × 4]&gt;
## 5     5 &lt;kmeans&gt;         &lt;tibble [1 × 4]&gt;
## 6     6 &lt;kmeans&gt;         &lt;tibble [1 × 4]&gt;</code></pre>
<p>What we need to do next, is get the value for the total within-cluster sum of squares (<code>tot.withinss</code>) from the <code>glanced</code> column. Given that each item in this column is a data frame, we will need to use the <code>unnest</code> function to unpack the data frames in the <code>glanced</code> column.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clustering_statistics &lt;-<span class="st"> </span>marketing_clust_ks <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest</span>(glanced)

<span class="kw">head</span>(clustering_statistics)</code></pre></div>
<pre><code>## # A tibble: 6 x 6
##       k marketing_clusts totss tot.withinss betweenss  iter
##   &lt;int&gt; &lt;list&gt;           &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;
## 1     1 &lt;kmeans&gt;          241.        241.         0      1
## 2     2 &lt;kmeans&gt;          241.        110.       132.     1
## 3     3 &lt;kmeans&gt;          241.         39.6      202.     1
## 4     4 &lt;kmeans&gt;          241.         24.0      217.     2
## 5     5 &lt;kmeans&gt;          241.         18.3      223.     2
## 6     6 &lt;kmeans&gt;          241.         32.2      209.     1</code></pre>
<p>Now that we have <code>tot.withinss</code> and <code>k</code> as columns in a data frame, we can make a plot to choose K:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">elbow_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(clustering_statistics, <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> tot.withinss)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;K&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Total within-cluster sum of squares&quot;</span>)
elbow_plot</code></pre></div>
<p><img src="_main_files/figure-html/10-plot-choose-k-1.png" width="417.6" /></p>
<p>We call the plot above an “elbow plot” and we look for the “elbow” in total within-cluster sum of squares, the point where afterwards increasing K doesn’t have as much impact reducing the total within-cluster sum of squares. Here we would choose K = 3.</p>
</div>
<div id="additional-readings" class="section level2">
<h2><span class="header-section-number">11.7</span> Additional readings:</h2>
<ul>
<li>Pages 385-390 and 404-405 of <a href="http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf">Introduction to Statistical Learning with Applications in R</a> by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani and the companion video linked to below:</li>
</ul>
<iframe width="840" height="473" src="https://www.youtube.com/embed/aIybuNt9ps4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression3.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-clustering.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
